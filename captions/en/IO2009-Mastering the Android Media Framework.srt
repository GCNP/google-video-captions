1
00:00:01,167 --> 00:00:03,300
Sparks: Good afternoon.
My name's Dave Sparks.

2
00:00:03,300 --> 00:00:06,167
I'm on the Android team.

3
00:00:06,167 --> 00:00:09,801
And I'm the technical lead
for the multimedia framework.

4
00:00:09,801 --> 00:00:15,567
I've been working on Android
since October of 2007.

5
00:00:15,567 --> 00:00:18,334
But actually, technically,
I started before that,

6
00:00:18,334 --> 00:00:21,100
because I worked on the MIDI
engine that we're using.

7
00:00:21,100 --> 00:00:24,667
So I kind of have
a long, vested interest

8
00:00:24,667 --> 00:00:26,100
in the project.

9
00:00:26,100 --> 00:00:30,200
So today, we have kind of
an ambitious title,

10
00:00:30,200 --> 00:00:32,801
called "Mastering
the Media Framework."

11
00:00:32,801 --> 00:00:36,367
I think the reality is
that if you believe that--

12
00:00:36,367 --> 00:00:38,567
that we're going
to do that in an hour,

13
00:00:38,567 --> 00:00:40,734
it's probably pretty ambitious.

14
00:00:40,734 --> 00:00:42,868
And if you do believe that,

15
00:00:42,868 --> 00:00:45,200
I have a bridge
just north of here

16
00:00:45,200 --> 00:00:47,634
that you might be interested in.

17
00:00:47,634 --> 00:00:50,534
But I think we actually will
be able to cover

18
00:00:50,534 --> 00:00:52,434
a few kind of
interesting things.

19
00:00:52,434 --> 00:00:54,701
In thinking
about this topic,

20
00:00:54,701 --> 00:00:58,267
I wanted to cover stuff
that wasn't really available

21
00:00:58,267 --> 00:01:00,801
in the SDK,
so we're really going to del--

22
00:01:00,801 --> 00:01:04,501
delve into the lower parts
of the framework,

23
00:01:04,501 --> 00:01:06,334
the infrastructure
that basically

24
00:01:06,334 --> 00:01:07,534
everything's built on.

25
00:01:07,534 --> 00:01:11,167
Kind of explain
some of the design philosophy.

26
00:01:11,167 --> 00:01:13,434
So...

27
00:01:13,434 --> 00:01:15,100
Oh, I guess I should have
put that up first.

28
00:01:15,100 --> 00:01:17,100
Here we go.

29
00:01:17,100 --> 00:01:19,901
So on the agenda,

30
00:01:19,901 --> 00:01:22,868
in the cutesy fashion
of the thing,

31
00:01:22,868 --> 00:01:26,501
we're talking
about the architecture--

32
00:01:26,501 --> 00:01:28,501
Frank Lloyd Android.

33
00:01:28,501 --> 00:01:31,133
What's new
in our Cupcake release,

34
00:01:31,133 --> 00:01:33,734
which just came out recently.

35
00:01:33,734 --> 00:01:36,767
And those of you
who have the phone,

36
00:01:36,767 --> 00:01:39,234
you're running that
on your device today.

37
00:01:39,234 --> 00:01:41,667
And then a few common problems
that people run into

38
00:01:41,667 --> 00:01:44,934
when they're writing
applications for the framework.

39
00:01:44,934 --> 00:01:46,901
And then
there probably will be

40
00:01:46,901 --> 00:01:48,067
a little bit of time
left over at the end

41
00:01:48,067 --> 00:01:51,901
for anybody who has questions.

42
00:01:51,901 --> 00:01:53,200
So moving along,

43
00:01:53,200 --> 00:01:56,667
we'll start
with the architecture.

44
00:01:56,667 --> 00:02:00,067
So when we first started
designing the architecture,

45
00:02:00,067 --> 00:02:02,400
we had some goals in mind.

46
00:02:02,400 --> 00:02:05,033
One of the things
was to make development

47
00:02:05,033 --> 00:02:08,467
of applications that use media,
rich media applications,

48
00:02:08,467 --> 00:02:10,200
very easy to develop.

49
00:02:10,200 --> 00:02:13,000
And so that was one
of the key goals

50
00:02:13,000 --> 00:02:15,334
that we wanted to accomplish
in this.

51
00:02:15,334 --> 00:02:17,100
And I think you'll see it
as we look at the framework.

52
00:02:17,100 --> 00:02:19,434
It's really simple
to play audio,

53
00:02:19,434 --> 00:02:22,767
to display a video,
and things like that.

54
00:02:22,767 --> 00:02:25,434
One of the key things,
because this is

55
00:02:25,434 --> 00:02:27,968
a multi-tasking
operating system,

56
00:02:27,968 --> 00:02:30,968
is we have--
you could potentially have

57
00:02:30,968 --> 00:02:32,200
things happening
in the background.

58
00:02:32,200 --> 00:02:34,634
For example, you could have
a music player

59
00:02:34,634 --> 00:02:35,801
playing in the background.

60
00:02:35,801 --> 00:02:37,734
We need the ability
to share resources

61
00:02:37,734 --> 00:02:39,567
among all these applications,

62
00:02:39,567 --> 00:02:41,234
and so that's one
of the key things,

63
00:02:41,234 --> 00:02:42,634
was to design an architecture

64
00:02:42,634 --> 00:02:44,934
that could easily
share resources.

65
00:02:44,934 --> 00:02:47,434
And the other thing is,
you know,

66
00:02:47,434 --> 00:02:50,634
paramount in Android
is the security model.

67
00:02:50,634 --> 00:02:54,067
And if you've looked over
the security stuff--

68
00:02:54,067 --> 00:02:55,701
I'm not sure we had a talk today
on security.

69
00:02:55,701 --> 00:02:58,400
But security is really important
to us.

70
00:02:58,400 --> 00:03:01,734
And so we needed a way
to be able to sandbox

71
00:03:01,734 --> 00:03:03,033
parts of the application
that are--

72
00:03:03,033 --> 00:03:04,300
that are particularly
vulnerable,

73
00:03:04,300 --> 00:03:06,067
and I think you'll see
as we look at the--

74
00:03:06,067 --> 00:03:08,701
the framework,
that it's designed

75
00:03:08,701 --> 00:03:10,534
to isolate parts of the system

76
00:03:10,534 --> 00:03:14,133
that are particularly vulnerable
to hacking.

77
00:03:14,133 --> 00:03:15,934
And then, you know,
providing a way

78
00:03:15,934 --> 00:03:18,868
to add features in the future

79
00:03:18,868 --> 00:03:20,200
that are backwards compatible.

80
00:03:20,200 --> 00:03:24,234
So that's the--
the room for future growth.

81
00:03:24,234 --> 00:03:27,300
So here's kind of
a 30,000-foot view

82
00:03:27,300 --> 00:03:30,400
of the way
the media framework works.

83
00:03:30,400 --> 00:03:33,634
So on the left side,
you'll notice

84
00:03:33,634 --> 00:03:36,234
that there is the application.

85
00:03:36,234 --> 00:03:38,634
And the red line--
red dashed line there--

86
00:03:38,634 --> 00:03:41,400
is denoting
the process boundary.

87
00:03:41,400 --> 00:03:44,501
So applications run
in one process.

88
00:03:44,501 --> 00:03:46,133
And the media server
actually runs

89
00:03:46,133 --> 00:03:48,667
in its own process
that's actually booted up--

90
00:03:48,667 --> 00:03:50,601
brought up during boot time.

91
00:03:50,601 --> 00:03:53,701
And so the codecs

92
00:03:53,701 --> 00:03:57,400
and the file parsers
and the network stack

93
00:03:57,400 --> 00:03:59,033
and everything that has to do
with playing media

94
00:03:59,033 --> 00:04:01,834
is actually sitting
in a separate process.

95
00:04:01,834 --> 00:04:05,133
And then underneath that
are the hardware abstractions

96
00:04:05,133 --> 00:04:06,767
for the audio and video pass.

97
00:04:06,767 --> 00:04:09,868
So Surface Flingers are
an abstraction for video

98
00:04:09,868 --> 00:04:11,734
and graphics.

99
00:04:11,734 --> 00:04:16,734
And Audio Flinger's
the abstraction for audio.

100
00:04:16,734 --> 00:04:20,767
So looking at a typical
media function,

101
00:04:20,767 --> 00:04:22,467
there's a lot of stuff--

102
00:04:22,467 --> 00:04:24,934
because of this inner process
communication that's going on,

103
00:04:24,934 --> 00:04:25,968
there's a lot of things
that are involved

104
00:04:25,968 --> 00:04:28,133
in moving a call
down the stack.

105
00:04:28,133 --> 00:04:29,667
So I wanted to give you
an idea--

106
00:04:29,667 --> 00:04:31,434
for those of you who've looked
at the source code,

107
00:04:31,434 --> 00:04:35,267
it's sometimes hard to follow,
you know, how is a call--

108
00:04:35,267 --> 00:04:37,067
A question that comes up
quite frequently

109
00:04:37,067 --> 00:04:39,434
is how does a function call,
like, you know,

110
00:04:39,434 --> 00:04:40,501
prepare or make its way

111
00:04:40,501 --> 00:04:42,067
all the way down
to the framework

112
00:04:42,067 --> 00:04:44,133
and into the--
the media engine?

113
00:04:44,133 --> 00:04:46,467
So this is kind of
a top-level view

114
00:04:46,467 --> 00:04:48,434
of what a stack might look like.

115
00:04:48,434 --> 00:04:52,100
At the very top
is the Dalvik VM proxy.

116
00:04:52,100 --> 00:04:55,267
So that's the Java object
that you're actually talking to.

117
00:04:55,267 --> 00:04:57,100
So, for example,
for a media player,

118
00:04:57,100 --> 00:04:58,868
there's a media player object.

119
00:04:58,868 --> 00:05:00,968
If you look at
the media player definition,

120
00:05:00,968 --> 00:05:02,267
it's a pretty--
I mean,

121
00:05:02,267 --> 00:05:03,300
there's not a lot of code
in Java.

122
00:05:03,300 --> 00:05:04,601
It's pretty simple.

123
00:05:04,601 --> 00:05:07,968
And basically,
it's a proxy for--

124
00:05:07,968 --> 00:05:10,133
in this case, actually,
the native proxy,

125
00:05:10,133 --> 00:05:11,868
which it's underneath,
and then eventually,

126
00:05:11,868 --> 00:05:13,667
the actual implementation.

127
00:05:13,667 --> 00:05:16,734
So from that,
we go through JNI,

128
00:05:16,734 --> 00:05:18,834
which is
the Java Native Interface.

129
00:05:18,834 --> 00:05:21,100
And that is just
a little shim layer

130
00:05:21,100 --> 00:05:22,567
that's static bindings

131
00:05:22,567 --> 00:05:25,200
to an actual
MediaPlayer object.

132
00:05:25,200 --> 00:05:28,400
So when you create
a MediaPlayer in Java,

133
00:05:28,400 --> 00:05:30,801
what you're actually doing
is making a call

134
00:05:30,801 --> 00:05:32,534
through this JNI layer

135
00:05:32,534 --> 00:05:34,734
to instantiate a C++ object.

136
00:05:34,734 --> 00:05:37,400
That's actually
the MediaPlayer.

137
00:05:37,400 --> 00:05:40,968
And there's a reference to that
that's held in the Java object.

138
00:05:40,968 --> 00:05:42,467
And then some tricky stuff--

139
00:05:42,467 --> 00:05:45,501
weak references
to garbage collection

140
00:05:45,501 --> 00:05:47,534
and stuff like that,
which is a little bit too deep

141
00:05:47,534 --> 00:05:49,067
for the talk today.

142
00:05:49,067 --> 00:05:51,167
Like I said, you're not going
to master the framework today,

143
00:05:51,167 --> 00:05:53,501
but at least get an idea
of what's there.

144
00:05:53,501 --> 00:05:56,033
So in the native proxy,

145
00:05:56,033 --> 00:05:59,968
this is actually
a proxy object for the service.

146
00:05:59,968 --> 00:06:03,100
So there is a little bit of code
in the native code.

147
00:06:03,100 --> 00:06:05,434
You know, a little bit of logic
in the native code.

148
00:06:05,434 --> 00:06:07,434
But primarily,
most of the implementation

149
00:06:07,434 --> 00:06:10,067
is actually sitting down
in this media server process.

150
00:06:10,067 --> 00:06:13,033
So the native proxy is actually
the C++ object

151
00:06:13,033 --> 00:06:17,567
that talks through
this binder interface.

152
00:06:17,567 --> 00:06:19,634
The reason we have
a native proxy

153
00:06:19,634 --> 00:06:21,534
instead of going directly
through JNI

154
00:06:21,534 --> 00:06:23,834
is a lot of the other pieces
of the framework does.

155
00:06:23,834 --> 00:06:26,033
So we wanted to be able
to provide

156
00:06:26,033 --> 00:06:28,434
access to native applications
in the future

157
00:06:28,434 --> 00:06:30,501
to use MediaPlayer objects.

158
00:06:30,501 --> 00:06:32,868
So it makes it
relatively easy,

159
00:06:32,868 --> 00:06:34,901
because that's something
you'd probably want to do

160
00:06:34,901 --> 00:06:36,300
with games
and things like that

161
00:06:36,300 --> 00:06:40,734
that are kind of more natural
to write in native code.

162
00:06:40,734 --> 00:06:44,367
We wanted to provide
the ability to do that.

163
00:06:44,367 --> 00:06:46,567
So that's why the native proxy
sits there

164
00:06:46,567 --> 00:06:49,701
and then the Java layer
just sits on top of that.

165
00:06:49,701 --> 00:06:52,634
So the binder proxy
and the binder native piece--

166
00:06:52,634 --> 00:06:57,501
Binder is our abstraction
for inter-process communication.

167
00:06:57,501 --> 00:06:59,767
Binder, basically,
what it does,

168
00:06:59,767 --> 00:07:02,234
is it marshals objects across
this process boundary

169
00:07:02,234 --> 00:07:03,767
through a special kernel driver.

170
00:07:03,767 --> 00:07:06,801
And through that, we can
do things like move data,

171
00:07:06,801 --> 00:07:10,100
move file descriptors
that are duped across processes

172
00:07:10,100 --> 00:07:14,200
so that they can be accessed
by different processes.

173
00:07:14,200 --> 00:07:17,901
And we can also do something
which--we can share memory

174
00:07:17,901 --> 00:07:19,334
between processes.

175
00:07:19,334 --> 00:07:21,801
And this is a really efficient
way of moving data

176
00:07:21,801 --> 00:07:23,367
back and forth
between the application

177
00:07:23,367 --> 00:07:25,634
and the media server.

178
00:07:25,634 --> 00:07:27,767
And this is used extensively

179
00:07:27,767 --> 00:07:30,567
in Audio Flinger
and Surface Flinger.

180
00:07:30,567 --> 00:07:33,868
So the binder proxy is basically
the marshalling code

181
00:07:33,868 --> 00:07:35,701
on the applications side.

182
00:07:35,701 --> 00:07:40,000
And the binder native code
is the marshalling code

183
00:07:40,000 --> 00:07:42,901
for the server side
of the process.

184
00:07:42,901 --> 00:07:45,434
And if you're looking
at all the pieces

185
00:07:45,434 --> 00:07:47,267
of the framework--
they start with

186
00:07:47,267 --> 00:07:49,100
mediaplayer.java,
for example--

187
00:07:49,100 --> 00:07:51,834
there's an android_media...

188
00:07:51,834 --> 00:07:54,000
_mediaplayer.cpp,

189
00:07:54,000 --> 00:07:55,467
which is the JNI piece.

190
00:07:55,467 --> 00:07:57,801
There's a mediaplayer.cpp,

191
00:07:57,801 --> 00:08:00,567
which is
the native proxy object.

192
00:08:00,567 --> 00:08:03,801
Then there's an
imediaplayer.cpp,

193
00:08:03,801 --> 00:08:06,901
which is actually a--
a binder proxy

194
00:08:06,901 --> 00:08:10,601
and the binder native code
in one chunk.

195
00:08:10,601 --> 00:08:12,400
So you actually see
the marshalling code

196
00:08:12,400 --> 00:08:14,801
for both pieces
in that one file.

197
00:08:14,801 --> 00:08:18,934
And one is called
bpmediaplayer.cpp--

198
00:08:18,934 --> 00:08:21,467
or, sorry,
BP MediaPlayer object.

199
00:08:21,467 --> 00:08:23,901
And a BN MediaPlayer object.

200
00:08:23,901 --> 00:08:25,334
So when you're looking
at that code,

201
00:08:25,334 --> 00:08:27,834
you can see the piece
that's on the native side--

202
00:08:27,834 --> 00:08:31,100
the server side
and the proxy.

203
00:08:31,100 --> 00:08:34,767
And then the final piece
of the puzzle

204
00:08:34,767 --> 00:08:36,801
is the actual implementation
itself.

205
00:08:36,801 --> 00:08:39,801
So in the case
of the media server--

206
00:08:39,801 --> 00:08:42,267
sorry, the MediaPlayer--
there's a MediaPlayer service

207
00:08:42,267 --> 00:08:45,534
which instantiates
a MediaPlayer object

208
00:08:45,534 --> 00:08:49,434
in the service that's,
you know, proxied

209
00:08:49,434 --> 00:08:52,300
in the application by this
other MediaPlayer object.

210
00:08:52,300 --> 00:08:54,834
That's basically--
each one of the calls

211
00:08:54,834 --> 00:08:56,234
goes through this stack.

212
00:08:56,234 --> 00:09:00,834
Now, because the stack is,
you know, fairly lightweight

213
00:09:00,834 --> 00:09:03,601
in terms of we don't make
a lot of calls through it,

214
00:09:03,601 --> 00:09:05,467
we can afford a little bit
of overhead here.

215
00:09:05,467 --> 00:09:08,067
So there's a bit of code
that you go through

216
00:09:08,067 --> 00:09:10,934
to get to this place,
but once you've started playing,

217
00:09:10,934 --> 00:09:12,834
and you'll see this
later in the slides,

218
00:09:12,834 --> 00:09:14,801
you don't have to do
a lot of calls

219
00:09:14,801 --> 00:09:18,968
to maintain
the application playing.

220
00:09:18,968 --> 00:09:22,501
So this is actually kind of
a top-level diagram

221
00:09:22,501 --> 00:09:24,734
of what the media server
process looks like.

222
00:09:24,734 --> 00:09:26,868
So I've got this media player
service.

223
00:09:26,868 --> 00:09:30,968
And it can instantiate a number 
of different players.

224
00:09:30,968 --> 00:09:34,868
So on the left-hand side,
you'll see, bottom,

225
00:09:34,868 --> 00:09:36,634
we have OpenCORE, Vorbis,
and MIDI.

226
00:09:36,634 --> 00:09:40,667
And these are three different
media player types.

227
00:09:40,667 --> 00:09:45,701
So going from the simplest one,
which is the Vorbis player--

228
00:09:45,701 --> 00:09:48,534
Vorbis basically just plays
Ogg Vorbis files,

229
00:09:48,534 --> 00:09:50,834
which is a--
we'll get into the specifics

230
00:09:50,834 --> 00:09:53,901
of the codec, but it's
a psycho-acoustic codec

231
00:09:53,901 --> 00:09:55,267
that's open sourced.

232
00:09:55,267 --> 00:09:59,234
We use this for a lot
of our internal sounds,

233
00:09:59,234 --> 00:10:01,100
because it's very lightweight.

234
00:10:01,100 --> 00:10:02,934
It's pretty efficient.

235
00:10:02,934 --> 00:10:06,334
And so we use that
for our ringtones

236
00:10:06,334 --> 00:10:09,100
and for our application sounds.

237
00:10:09,100 --> 00:10:11,734
The MIDI player,
a little more complex.

238
00:10:11,734 --> 00:10:14,267
But basically, it's just
another instantiation

239
00:10:14,267 --> 00:10:15,434
of a media player.

240
00:10:15,434 --> 00:10:17,767
These all share
a common interface,

241
00:10:17,767 --> 00:10:21,067
so if you look at
the MediaPlayer.java interface,

242
00:10:21,067 --> 00:10:23,467
there's almost, you know,
one-for-one correspondence

243
00:10:23,467 --> 00:10:25,567
between what you see there
and what's actually happening

244
00:10:25,567 --> 00:10:27,634
in the players themselves.

245
00:10:27,634 --> 00:10:29,868
And then the final one
is OpenCORE.

246
00:10:29,868 --> 00:10:34,501
So anything that isn't
an Ogg file or a MIDI file

247
00:10:34,501 --> 00:10:37,167
is routed over
to OpenCORE.

248
00:10:37,167 --> 00:10:39,934
And OpenCORE is basically the--
the bulk of the framework.

249
00:10:39,934 --> 00:10:42,200
It consists of all
of the major codecs,

250
00:10:42,200 --> 00:10:45,667
like, you know,
MP3 and AAC and AMR

251
00:10:45,667 --> 00:10:50,734
and the video codecs,
H.263 and H.264 and AVC.

252
00:10:50,734 --> 00:10:54,434
So any file that's not
specifically one of those two

253
00:10:54,434 --> 00:10:56,467
ends up going to OpenCORE
to be played.

254
00:10:56,467 --> 00:10:58,734
Now, this provides
some extensibility.

255
00:10:58,734 --> 00:11:00,167
The media player service
is smart enough

256
00:11:00,167 --> 00:11:02,734
to sort of recognize
these file types.

257
00:11:02,734 --> 00:11:05,234
And we have a media scanner
that runs at boot time--

258
00:11:05,234 --> 00:11:06,634
that goes out,
looks at the files,

259
00:11:06,634 --> 00:11:08,367
figures out what they are.

260
00:11:08,367 --> 00:11:11,901
And so we can actually,
you know, replace or add

261
00:11:11,901 --> 00:11:14,534
new player types by just
instantiating

262
00:11:14,534 --> 00:11:16,000
a new type of player.

263
00:11:16,000 --> 00:11:19,801
In fact, there are
some projects out there

264
00:11:19,801 --> 00:11:22,701
where they've replaced OpenCORE
with GStreamer

265
00:11:22,701 --> 00:11:24,467
or other media frameworks.

266
00:11:24,467 --> 00:11:27,734
And we're talking
to some other--

267
00:11:27,734 --> 00:11:31,667
some different types
of player applications

268
00:11:31,667 --> 00:11:34,167
that might have new codecs
and new file types,

269
00:11:34,167 --> 00:11:35,467
and that's one way of doing it.

270
00:11:35,467 --> 00:11:36,968
The other way of doing it
is you--

271
00:11:36,968 --> 00:11:38,334
if you wanted
to add a new file type,

272
00:11:38,334 --> 00:11:42,734
you could actually implement it
inside of OpenCORE.

273
00:11:42,734 --> 00:11:45,167
And then on the right-hand side,

274
00:11:45,167 --> 00:11:48,200
we have
the media recorder service.

275
00:11:48,200 --> 00:11:52,434
Prior to--
in the 1.0, 1.1 releases,

276
00:11:52,434 --> 00:11:54,734
that was basically just
an audio record path.

277
00:11:54,734 --> 00:11:56,868
In Cupcake, we've added
video recording.

278
00:11:56,868 --> 00:11:59,601
So this is now integrated
with a camera service.

279
00:11:59,601 --> 00:12:03,734
And so the media recorder--
again, it's sort of a proxy.

280
00:12:03,734 --> 00:12:05,868
There's a proxy, um--

281
00:12:05,868 --> 00:12:08,267
it uses the same sort
of type of thing,

282
00:12:08,267 --> 00:12:10,334
where there's a media recorder--
media recorder object

283
00:12:10,334 --> 00:12:11,868
in the Java layer.

284
00:12:11,868 --> 00:12:15,133
And there's
a media recorder service

285
00:12:15,133 --> 00:12:18,200
that actually does
the recording.

286
00:12:18,200 --> 00:12:20,868
And for the actual
authoring engine,

287
00:12:20,868 --> 00:12:22,467
we're using OpenCORE.

288
00:12:22,467 --> 00:12:25,234
And it has the--
the encoder side.

289
00:12:25,234 --> 00:12:27,000
So we've talked about
the decoders,

290
00:12:27,000 --> 00:12:34,334
and the encoders would be
H.263, H.264, and also AVC.

291
00:12:34,334 --> 00:12:36,367
Sorry, and MPEG-4 SP.

292
00:12:36,367 --> 00:12:39,501
And then,
the audio codecs.

293
00:12:39,501 --> 00:12:42,300
So all those sit
inside of OpenCORE.

294
00:12:42,300 --> 00:12:45,501
And then the camera service
both operates

295
00:12:45,501 --> 00:12:47,000
in conjunction
with the media recorder

296
00:12:47,000 --> 00:12:49,501
and also independently
for still images.

297
00:12:49,501 --> 00:12:51,234
So if your application wants
to take a still image,

298
00:12:51,234 --> 00:12:53,434
you instantiate
a camera object,

299
00:12:53,434 --> 00:12:56,300
which again is just a proxy
for this camera service.

300
00:12:56,300 --> 00:12:59,501
The camera surface takes care
of handling preview for you,

301
00:12:59,501 --> 00:13:03,734
so again, we wanted to limit
the amount of traffic

302
00:13:03,734 --> 00:13:07,067
between the application
and the hardware.

303
00:13:07,067 --> 00:13:10,167
So this actually provides a way
for the preview frames

304
00:13:10,167 --> 00:13:11,934
to go directly out
to the display.

305
00:13:11,934 --> 00:13:14,634
Your application doesn't have
to worry about it,

306
00:13:14,634 --> 00:13:16,734
it just happens.

307
00:13:16,734 --> 00:13:18,868
And then in the case
where the media recorder

308
00:13:18,868 --> 00:13:21,667
is actually doing
video record,

309
00:13:21,667 --> 00:13:24,400
we take those frames
into the OpenCORE

310
00:13:24,400 --> 00:13:28,767
and it does the encoding there.

311
00:13:28,767 --> 00:13:33,634
So kind of looking at what
a media playback session

312
00:13:33,634 --> 00:13:35,200
would look like.

313
00:13:35,200 --> 00:13:39,868
The application provides
three main pieces of data.

314
00:13:39,868 --> 00:13:42,334
It's going to provide
the source URI.

315
00:13:42,334 --> 00:13:44,801
The "where is this file
coming from."

316
00:13:44,801 --> 00:13:47,434
It'll either come from
a local file that's on the--

317
00:13:47,434 --> 00:13:49,100
you know, on the SD card.

318
00:13:49,100 --> 00:13:51,133
It could come from a resource

319
00:13:51,133 --> 00:13:53,267
that's in the application,
the .apk,

320
00:13:53,267 --> 00:13:56,067
or it could come
from a network stream.

321
00:13:56,067 --> 00:13:58,968
And so the application provides
that information.

322
00:13:58,968 --> 00:14:02,167
It provides a surface
that basically,

323
00:14:02,167 --> 00:14:04,334
at the application level,
called a surface view.

324
00:14:04,334 --> 00:14:07,667
This, at the binder level,
is an ISurface interface,

325
00:14:07,667 --> 00:14:12,400
which is an abstraction
for the--the view that you see.

326
00:14:12,400 --> 00:14:14,534
And then it also provides
the audio types,

327
00:14:14,534 --> 00:14:18,934
so that the hardware knows
where to route the audio.

328
00:14:18,934 --> 00:14:22,434
So once those
have been established,

329
00:14:22,434 --> 00:14:24,567
the media server basically
takes care of everything

330
00:14:24,567 --> 00:14:25,968
from that point on.

331
00:14:25,968 --> 00:14:29,734
So you--once you have called
the prepare function

332
00:14:29,734 --> 00:14:31,133
and the start function,

333
00:14:31,133 --> 00:14:34,400
the frames--video frames,
audio frames, whatever, are--

334
00:14:34,400 --> 00:14:37,801
they're going to be decoded
inside the media server process.

335
00:14:37,801 --> 00:14:40,534
And they get output directly
to either Audio Flinger

336
00:14:40,534 --> 00:14:41,968
or Surface Flinger,
depending on whether

337
00:14:41,968 --> 00:14:43,868
it's an audio stream
or a video stream.

338
00:14:43,868 --> 00:14:46,901
And all the synchronization is
handled for you automatically.

339
00:14:46,901 --> 00:14:48,467
Again, it's a very low overhead.

340
00:14:48,467 --> 00:14:51,234
There's no data that's flowing
back up to the application

341
00:14:51,234 --> 00:14:54,400
at this point--it's all
happening inside the hardware.

342
00:14:54,400 --> 00:14:56,901
One other reason
for doing that

343
00:14:56,901 --> 00:14:59,434
we mentioned earlier
is that in the case--

344
00:14:59,434 --> 00:15:02,601
in many cases, for example
the G1 and the Sapphire,

345
00:15:02,601 --> 00:15:05,400
the device that you guys
got today--

346
00:15:05,400 --> 00:15:07,868
those devices actually have
hardware codecs.

347
00:15:07,868 --> 00:15:09,567
And so we're able
to take advantage

348
00:15:09,567 --> 00:15:12,767
of a DSP that's in the device
to accelerate.

349
00:15:12,767 --> 00:15:16,968
In the case of,
for example, H.264,

350
00:15:16,968 --> 00:15:19,734
we can accelerate
the decoded video in there

351
00:15:19,734 --> 00:15:22,801
and offload some of that
from the main processor.

352
00:15:22,801 --> 00:15:26,467
And that frees the processor
up to do other things,

353
00:15:26,467 --> 00:15:29,234
either, you know,
doing sync in the background,

354
00:15:29,234 --> 00:15:32,033
or just all sorts of things
that it might need--

355
00:15:32,033 --> 00:15:34,501
you might need
those cycles for.

356
00:15:34,501 --> 00:15:37,934
So again, that's--
all that is happening

357
00:15:37,934 --> 00:15:40,534
inside the media server process.

358
00:15:40,534 --> 00:15:43,534
We don't want to give
applications direct access

359
00:15:43,534 --> 00:15:45,100
to the hardware,
so it's another good reason

360
00:15:45,100 --> 00:15:50,701
for putting this inside
the media server process.

361
00:15:50,701 --> 00:15:52,334
So in the media recorder side,

362
00:15:52,334 --> 00:15:54,000
we have a similar sort of thing.

363
00:15:54,000 --> 00:15:55,667
It's a little more complex.

364
00:15:55,667 --> 00:16:00,033
The application
can either,

365
00:16:00,033 --> 00:16:02,033
in the case of--

366
00:16:02,033 --> 00:16:03,968
it can actually create
its own camera

367
00:16:03,968 --> 00:16:06,767
and then pass that
to the media server

368
00:16:06,767 --> 00:16:09,300
or it can let the media server
create a camera for it.

369
00:16:09,300 --> 00:16:11,901
And then the frames
from the camera go directly

370
00:16:11,901 --> 00:16:14,000
into the encoders.

371
00:16:14,000 --> 00:16:16,300
It again is going to provide
a surface for the preview,

372
00:16:16,300 --> 00:16:19,501
so as you're taking your video,
the preview frames are going

373
00:16:19,501 --> 00:16:21,534
directly to the--
to the display surface

374
00:16:21,534 --> 00:16:23,601
so you can see
what you're recording.

375
00:16:23,601 --> 00:16:25,834
And then you can select
an audio source.

376
00:16:25,834 --> 00:16:29,601
Right now that's just
the microphone input,

377
00:16:29,601 --> 00:16:32,033
but in the future,
it could be other sources.

378
00:16:32,033 --> 00:16:34,067
You know, potentially
you could be recording

379
00:16:34,067 --> 00:16:38,000
from, you know, TV or some--
some other hardware device

380
00:16:38,000 --> 00:16:40,701
that's on the device.

381
00:16:40,701 --> 00:16:42,868
And then--so once
you've established that,

382
00:16:42,868 --> 00:16:47,534
the camera service
will then start feeding frames

383
00:16:47,534 --> 00:16:50,300
through the camera service
up to the media server

384
00:16:50,300 --> 00:16:53,100
and then they're pushed out
to the Surface Flinger

385
00:16:53,100 --> 00:16:57,567
and they're also pushed out
into OpenCORE for encoding.

386
00:16:57,567 --> 00:17:02,067
And then there's
a file authoring piece

387
00:17:02,067 --> 00:17:04,534
that actually takes the frames
from audio and video,

388
00:17:04,534 --> 00:17:07,634
boxes them together,
and writes them out to a file.

389
00:17:11,400 --> 00:17:15,701
So, get into a little more
detail about the codecs.

390
00:17:15,701 --> 00:17:18,133
We have a number
of different--

391
00:17:18,133 --> 00:17:20,400
we have three different
video codecs.

392
00:17:20,400 --> 00:17:22,367
So one of the questions
that comes a lot--

393
00:17:22,367 --> 00:17:25,167
comes up a lot
from the forums

394
00:17:25,167 --> 00:17:27,467
is what kind of codecs
are available,

395
00:17:27,467 --> 00:17:30,467
what should they be used for,
and things like that.

396
00:17:30,467 --> 00:17:31,701
So just kind of a little bit
of history

397
00:17:31,701 --> 00:17:33,033
about the different codecs.

398
00:17:33,033 --> 00:17:35,868
So H.263 is a codec from--
I think it was--

399
00:17:35,868 --> 00:17:39,767
came out about 1996,
was when it was standardized.

400
00:17:39,767 --> 00:17:43,133
It was originally intended
for video conferencing,

401
00:17:43,133 --> 00:17:45,200
so it's really
low bit-rate stuff.

402
00:17:45,200 --> 00:17:48,200
You know, designed to go over
an ISDN line

403
00:17:48,200 --> 00:17:50,267
or something like that.

404
00:17:50,267 --> 00:17:54,067
So it's actually worked out
pretty well for mobile devices,

405
00:17:54,067 --> 00:17:56,767
and a lot of mobile devices
support H.263.

406
00:17:56,767 --> 00:17:59,400
The encoder is pretty simple.

407
00:17:59,400 --> 00:18:01,167
The decoder
is pretty simple.

408
00:18:01,167 --> 00:18:05,167
So it's a lightweight kind
of codec for an embedded device.

409
00:18:05,167 --> 00:18:07,701
It's part of the 3GPP standard.

410
00:18:07,701 --> 00:18:11,868
So it's adopted by a number
of different manufacturers.

411
00:18:11,868 --> 00:18:14,968
And it's actually used
by a number of existing

412
00:18:14,968 --> 00:18:18,033
video sites--
of websites--

413
00:18:18,033 --> 00:18:19,501
for their encode.

414
00:18:19,501 --> 00:18:22,300
For example, YouTube--
if you go to, like,

415
00:18:22,300 --> 00:18:23,901
the m.youtube.com,

416
00:18:23,901 --> 00:18:27,801
typically you'll end up
at an H.263 stream.

417
00:18:27,801 --> 00:18:33,934
Because it's supported
on most mobile devices.

418
00:18:33,934 --> 00:18:38,334
So MPEG-4 SP
was originally designed

419
00:18:38,334 --> 00:18:40,367
as a replacement
for MPEG-1 and MPEG-2.

420
00:18:40,367 --> 00:18:45,067
MPEG-1, MPEG-2--fairly early
standardized codecs.

421
00:18:45,067 --> 00:18:47,567
They wanted to do
something better.

422
00:18:47,567 --> 00:18:52,434
Again, it has a very simple
encoder model, similar to H.263.

423
00:18:52,434 --> 00:18:57,968
There's just single frame
references.

424
00:18:57,968 --> 00:19:00,634
And there's some question
about whether

425
00:19:00,634 --> 00:19:04,400
it's actually a better codec
or not than H.263,

426
00:19:04,400 --> 00:19:05,467
even though they're--

427
00:19:05,467 --> 00:19:07,801
they came out
very close together.

428
00:19:07,801 --> 00:19:11,868
It's missing
the deblocking filter, so--

429
00:19:11,868 --> 00:19:13,100
I didn't mention that before.

430
00:19:13,100 --> 00:19:15,133
H.263 has a deblocking filter.

431
00:19:15,133 --> 00:19:17,234
If you've ever looked
at video,

432
00:19:17,234 --> 00:19:21,567
it typically comes out
in, like, 8x8 pixel blocks.

433
00:19:21,567 --> 00:19:23,801
And you get kind of
a blockiness.

434
00:19:23,801 --> 00:19:28,033
So there's an in-loop
deblocking filter in H.263,

435
00:19:28,033 --> 00:19:30,501
which basically smooths
some of those edges out.

436
00:19:30,501 --> 00:19:34,167
The MPEG-4 SP,
in its basic profile,

437
00:19:34,167 --> 00:19:35,868
is missing that.

438
00:19:35,868 --> 00:19:38,100
So it--the quality of MPEG-4,

439
00:19:38,100 --> 00:19:40,234
some people don't think
it's quite as good,

440
00:19:40,234 --> 00:19:45,701
even though it came out
at roughly the same time.

441
00:19:45,701 --> 00:19:49,367
Then the final codec
we support

442
00:19:49,367 --> 00:19:51,133
is a fairly recent development.

443
00:19:51,133 --> 00:19:53,734
I think it's a 2003,
or something like that.

444
00:19:53,734 --> 00:19:56,167
The H.264 AVC codec came out.

445
00:19:56,167 --> 00:20:01,200
Compression's much better.

446
00:20:01,200 --> 00:20:03,033
It includes the ability

447
00:20:03,033 --> 00:20:04,400
to have
multiple reference frames,

448
00:20:04,400 --> 00:20:06,400
although
on our current platforms,

449
00:20:06,400 --> 00:20:08,868
we don't actually support that.

450
00:20:08,868 --> 00:20:12,634
But theoretically, you could get
better compression

451
00:20:12,634 --> 00:20:14,234
in the main--
what's called the main profile.

452
00:20:14,234 --> 00:20:16,467
We support base profile.

453
00:20:16,467 --> 00:20:20,501
It has this mandatory
in-loop deblocking filter

454
00:20:20,501 --> 00:20:21,734
that I mentioned before,

455
00:20:21,734 --> 00:20:25,734
which gets rid of the blockiness
in the frames.

456
00:20:25,734 --> 00:20:27,100
One of the really nice things

457
00:20:27,100 --> 00:20:29,067
is it has a number
of different profiles.

458
00:20:29,067 --> 00:20:31,801
And so different devices
support different levels

459
00:20:31,801 --> 00:20:33,834
of--of profiles.

460
00:20:33,834 --> 00:20:37,334
It specifies things like
frame sizes, bit rates,

461
00:20:37,334 --> 00:20:40,300
the--the types
of advanced features

462
00:20:40,300 --> 00:20:41,701
that it has to support.

463
00:20:41,701 --> 00:20:43,801
And there's a number
of optional features in there.

464
00:20:43,801 --> 00:20:45,300
And basically,
each of those levels

465
00:20:45,300 --> 00:20:49,367
and profiles defines
what's in those codecs.

466
00:20:49,367 --> 00:20:53,033
It's actually used in a pretty
wide range of things.

467
00:20:53,033 --> 00:20:57,133
Everything from digital cinema,
now, HDTV broadcasts,

468
00:20:57,133 --> 00:21:01,133
and we're starting to see it
on mobile devices like the G1.

469
00:21:01,133 --> 00:21:06,534
When you do a--if you're using
the device itself today,

470
00:21:06,534 --> 00:21:08,033
and you do a YouTube playback,

471
00:21:08,033 --> 00:21:09,868
you're actually--
on Wi-Fi,

472
00:21:09,868 --> 00:21:12,334
you're actually getting
a H.264 stream,

473
00:21:12,334 --> 00:21:15,834
which is why
it's so much better quality.

474
00:21:15,834 --> 00:21:19,367
On the downside, it's a lot
more complex than H.263

475
00:21:19,367 --> 00:21:23,234
because it has these
advanced features in it.

476
00:21:23,234 --> 00:21:26,033
So it takes a lot more CPU.

477
00:21:26,033 --> 00:21:29,467
And in the case of the G1,
for example,

478
00:21:29,467 --> 00:21:31,267
that particular hardware,

479
00:21:31,267 --> 00:21:33,367
some of the acceleration
happens in the DSP,

480
00:21:33,367 --> 00:21:35,400
but there's still some stuff
that has to go

481
00:21:35,400 --> 00:21:39,767
on the application processor.

482
00:21:39,767 --> 00:21:43,501
On the audio side,
MP3 is pretty--

483
00:21:43,501 --> 00:21:45,067
everybody's
pretty familiar with.

484
00:21:45,067 --> 00:21:48,234
It uses what's called
a psycho-acoustic model,

485
00:21:48,234 --> 00:21:51,067
which is why we get better
compression than a typical,

486
00:21:51,067 --> 00:21:54,167
you know, straight
compression algorithm.

487
00:21:54,167 --> 00:21:58,400
So psycho-acoustic means you
look for things in the--

488
00:21:58,400 --> 00:22:01,267
that are hidden
within the audio.

489
00:22:01,267 --> 00:22:02,434
There are certain sounds

490
00:22:02,434 --> 00:22:04,100
that are going to be masked
by other sounds.

491
00:22:04,100 --> 00:22:06,367
And so the psycho-acoustic model

492
00:22:06,367 --> 00:22:08,133
will try to pick out
those things,

493
00:22:08,133 --> 00:22:10,601
get rid of them,
and you get better--

494
00:22:10,601 --> 00:22:12,601
much better compression there.

495
00:22:12,601 --> 00:22:14,467
You get approximately
10:1 compression

496
00:22:14,467 --> 00:22:19,100
over a straight linear PCM
at 128kbits per second,

497
00:22:19,100 --> 00:22:23,067
which is pretty reasonable,
especially for a mobile device.

498
00:22:23,067 --> 00:22:26,534
And then if you want to,
you know, be a purist,

499
00:22:26,534 --> 00:22:30,734
most people figure
you get full sonic transparency

500
00:22:30,734 --> 00:22:33,133
at about 192kbits per second.

501
00:22:33,133 --> 00:22:36,601
So that's where most people
won't be able to hear

502
00:22:36,601 --> 00:22:37,868
the difference between
the original

503
00:22:37,868 --> 00:22:42,567
and the compressed version.

504
00:22:42,567 --> 00:22:46,033
For a more advanced codec,

505
00:22:46,033 --> 00:22:49,033
AAC came out
sometime after MP3.

506
00:22:49,033 --> 00:22:51,767
It's built on
the same basic principles,

507
00:22:51,767 --> 00:22:57,267
but it has
much better compression ratios.

508
00:22:57,267 --> 00:23:02,367
You get sonic transparency
at roughly 128kbits persecond.

509
00:23:02,367 --> 00:23:07,167
So, you know,
much, much better compression.

510
00:23:07,167 --> 00:23:11,467
And another mark
that people use

511
00:23:11,467 --> 00:23:13,601
is 128kbits per second--

512
00:23:13,601 --> 00:23:17,767
MP3 is roughly equivalent
to 96kbits per second AAC.

513
00:23:17,767 --> 00:23:20,834
We also find it's--
it's used, commonly used,

514
00:23:20,834 --> 00:23:22,133
in MPEG-4 streams.

515
00:23:22,133 --> 00:23:25,701
So if you have an MPEG-4
audio--video stream,

516
00:23:25,701 --> 00:23:30,067
you're likely to find
an AAC codec with it.

517
00:23:30,067 --> 00:23:33,501
In the case of our high-quality
YouTube streams,

518
00:23:33,501 --> 00:23:38,501
they're typically
a 96 kilohertz AAC format.

519
00:23:42,000 --> 00:23:44,734
And then finally, Ogg Vorbis,
which I'd mentioned earlier,

520
00:23:44,734 --> 00:23:46,400
we're using
for a lot of our sounds.

521
00:23:46,400 --> 00:23:48,534
Again, it's another
psycho-acoustic model.

522
00:23:48,534 --> 00:23:50,934
It's an open source codec,

523
00:23:50,934 --> 00:23:52,667
so it doesn't have
any patent,

524
00:23:52,667 --> 00:23:56,968
you know, issues
in terms of licensing--

525
00:23:56,968 --> 00:24:01,067
whereas any of the other codecs,
if you're selling a device,

526
00:24:01,067 --> 00:24:02,133
you need to go, you know,

527
00:24:02,133 --> 00:24:04,734
get the appropriate
patent licenses.

528
00:24:04,734 --> 00:24:07,133
Or I probably shouldn't
say that,

529
00:24:07,133 --> 00:24:08,200
because I'm not a lawyer,

530
00:24:08,200 --> 00:24:12,834
but you should probably
see your lawyer.

531
00:24:12,834 --> 00:24:15,734
From our perspective,
it's very low overhead.

532
00:24:15,734 --> 00:24:19,133
It doesn't bring in all
of the OpenCORE framework,

533
00:24:19,133 --> 00:24:21,334
'cause it's just
an audio codec.

534
00:24:21,334 --> 00:24:23,901
So it uses--
it's very lightweight

535
00:24:23,901 --> 00:24:26,167
in terms of the amount
of memory usage it uses

536
00:24:26,167 --> 00:24:27,601
and also the amount
of code space

537
00:24:27,601 --> 00:24:29,834
that it has to load in
in order to play a file.

538
00:24:29,834 --> 00:24:33,200
So that's why we use it
for things like ringtones

539
00:24:33,200 --> 00:24:35,434
and other things that need
fairly low latency

540
00:24:35,434 --> 00:24:38,267
and we know we're gonna
use it a lot.

541
00:24:38,267 --> 00:24:41,367
The other thing is that,
unlike MP3--

542
00:24:41,367 --> 00:24:46,868
MP3 doesn't have a native way
of specifying a seamless loop.

543
00:24:46,868 --> 00:24:49,801
For those of you
who aren't audio guy--

544
00:24:49,801 --> 00:24:52,367
audio experts, "seamless loop"
basically means

545
00:24:52,367 --> 00:24:55,868
you can play the whole thing
as one seamless,

546
00:24:55,868 --> 00:24:59,868
no clips, no pops loop
to play over and over again.

547
00:24:59,868 --> 00:25:02,300
A typical application for that
would be a ringtone,

548
00:25:02,300 --> 00:25:04,834
where you want it
to continue playing

549
00:25:04,834 --> 00:25:07,133
the same sound
over and over again

550
00:25:07,133 --> 00:25:09,534
without--without
the pops and clicks.

551
00:25:09,534 --> 00:25:12,534
MP3 doesn't have a way to
specify that accurately enough

552
00:25:12,534 --> 00:25:16,167
that you can actually do that
without having some sort of gap.

553
00:25:16,167 --> 00:25:20,033
There are people that have added
things in the ID3 tags

554
00:25:20,033 --> 00:25:21,434
to get around that,
but there isn't

555
00:25:21,434 --> 00:25:23,267
any standardized way to do it.

556
00:25:23,267 --> 00:25:26,334
Ogg does it--
actually, both Ogg and AAC

557
00:25:26,334 --> 00:25:29,934
have conventions for specifying
a seamless loop.

558
00:25:29,934 --> 00:25:31,868
So that's another reason
why we use Ogg

559
00:25:31,868 --> 00:25:34,100
is that we can get
that nice seamless loop.

560
00:25:34,100 --> 00:25:36,734
So if you're doing anything
in a game application

561
00:25:36,734 --> 00:25:39,734
where you want to get,
you know, some sort of--

562
00:25:39,734 --> 00:25:41,868
a typical thing would be like
an ambient sound

563
00:25:41,868 --> 00:25:43,601
that's playing over and over
in the background.

564
00:25:43,601 --> 00:25:47,501
You know, the factory sound
or, you know,

565
00:25:47,501 --> 00:25:49,300
some eerie swamp noises
or whatever.

566
00:25:49,300 --> 00:25:52,267
That's the way to do it
is to use the Ogg file.

567
00:25:52,267 --> 00:25:54,200
You'll get pretty good
compression.

568
00:25:54,200 --> 00:25:56,534
It's pretty low overhead
for decoding it.

569
00:25:56,534 --> 00:26:02,167
And you can get those loops
that won't click.

570
00:26:02,167 --> 00:26:05,567
And then finally,
the last codecs

571
00:26:05,567 --> 00:26:07,000
we're going to talk about
in terms of audio

572
00:26:07,000 --> 00:26:08,968
are the AMR codecs.

573
00:26:08,968 --> 00:26:12,501
AMR is a speech codec,

574
00:26:12,501 --> 00:26:15,267
so it doesn't get
the full bandwidth.

575
00:26:15,267 --> 00:26:19,968
If you ever try to encode one
with music on it,

576
00:26:19,968 --> 00:26:21,634
it will sound pretty crappy.

577
00:26:21,634 --> 00:26:24,501
That's because it--
it wants to kind of focus in

578
00:26:24,501 --> 00:26:26,267
on one central tone.

579
00:26:26,267 --> 00:26:28,634
That's how it gets
its high compression rate.

580
00:26:28,634 --> 00:26:31,634
But at the same time,
it throws away a lot of audio.

581
00:26:31,634 --> 00:26:34,767
So it's typically used
for video codecs.

582
00:26:34,767 --> 00:26:38,300
And in fact,
GSM basically is based

583
00:26:38,300 --> 00:26:41,367
on AMR-type codecs.

584
00:26:41,367 --> 00:26:44,234
It's--the input is,

585
00:26:44,234 --> 00:26:46,734
for the AMR narrow band,
is 8 kilohertz.

586
00:26:46,734 --> 00:26:49,734
So going back to Nyquist,
that basically means

587
00:26:49,734 --> 00:26:51,534
your highest frequency
you can represent

588
00:26:51,534 --> 00:26:54,434
is just shy of 4 kilohertz.

589
00:26:54,434 --> 00:26:57,934
And the output bit-rates
are, you know,

590
00:26:57,934 --> 00:27:03,434
anywhere from just under
5kbits per second up to 12.2.

591
00:27:03,434 --> 00:27:07,701
AMR wide band is a little bit
better quality.

592
00:27:07,701 --> 00:27:10,868
It's got a 16 kilohertz input,
and slightly higher bandwidths.

593
00:27:10,868 --> 00:27:14,267
But again,
it's a speech codec primarily,

594
00:27:14,267 --> 00:27:17,667
and so you're not going to get
great audio out of it.

595
00:27:17,667 --> 00:27:21,567
We do use these,
because in the package,

596
00:27:21,567 --> 00:27:25,100
the OpenCORE package,
the AMR narrow band codec

597
00:27:25,100 --> 00:27:26,701
is the only audio encoder--

598
00:27:26,701 --> 00:27:28,701
native audio encoder
we have in software.

599
00:27:28,701 --> 00:27:32,467
So if your hardware platform
doesn't have an encoder,

600
00:27:32,467 --> 00:27:35,133
that's kind of
the fallback codec.

601
00:27:35,133 --> 00:27:39,501
And in fact, if you use
the audio recorder application

602
00:27:39,501 --> 00:27:41,734
like MMS,
and attach an audio,

603
00:27:41,734 --> 00:27:43,467
this is the codec
you're going to get.

604
00:27:43,467 --> 00:27:45,133
If you do a video record
today,

605
00:27:45,133 --> 00:27:46,834
that's the codec
you're going to get.

606
00:27:46,834 --> 00:27:50,167
We're expecting that future
hardware platforms

607
00:27:50,167 --> 00:27:53,601
will provide, you know,
native encoders for AAC.

608
00:27:53,601 --> 00:27:55,968
It's a little too heavy
to do AAC

609
00:27:55,968 --> 00:27:57,501
on the application processor

610
00:27:57,501 --> 00:27:59,667
while you're doing video record
and everything else.

611
00:27:59,667 --> 00:28:01,834
So we really need
the acceleration

612
00:28:01,834 --> 00:28:03,534
in order to do it.

613
00:28:03,534 --> 00:28:08,167
AMR is specified
in 3GPP streams.

614
00:28:08,167 --> 00:28:13,501
So most phones
that will decode an H.263

615
00:28:13,501 --> 00:28:14,834
will also decode the AMR.

616
00:28:14,834 --> 00:28:16,634
So it's a fairly compatible
format.

617
00:28:16,634 --> 00:28:19,634
If you look at the--the other
phones that are out there

618
00:28:19,634 --> 00:28:21,501
that support, you know,
video playback,

619
00:28:21,501 --> 00:28:24,100
they typically
will support AMR as well.

620
00:28:27,567 --> 00:28:30,968
So we've talked about codecs.

621
00:28:30,968 --> 00:28:32,734
Both audio and video codecs.

622
00:28:32,734 --> 00:28:35,567
The other piece of it,
when you're doing a stream,

623
00:28:35,567 --> 00:28:38,434
is what's the container format?

624
00:28:38,434 --> 00:28:41,767
And so I'm going to talk
a little bit about that.

625
00:28:41,767 --> 00:28:45,834
So 3GPP is the stream
that's defined

626
00:28:45,834 --> 00:28:47,734
by the 3GPP organization.

627
00:28:47,734 --> 00:28:49,834
These are phones that support
that standard

628
00:28:49,834 --> 00:28:51,801
and are going to support
these types of files.

629
00:28:51,801 --> 00:28:55,501
3GPP is actually
an MPEG-4 file format.

630
00:28:55,501 --> 00:28:58,534
But it's--very, very
restricted set of--

631
00:28:58,534 --> 00:29:02,834
of things that
you can put into that file,

632
00:29:02,834 --> 00:29:05,534
designed for compatibility
with these embedded devices.

633
00:29:05,534 --> 00:29:09,701
So you really want to use
a H.263 video codec

634
00:29:09,701 --> 00:29:14,400
for--for broad compatibility
across a number of phones.

635
00:29:14,400 --> 00:29:17,467
You probably want to use
a low bit rate for the video,

636
00:29:17,467 --> 00:29:20,300
typically like 192kbits
per second.

637
00:29:20,300 --> 00:29:23,868
And you also want to use
the AMR narrow band codec.

638
00:29:27,400 --> 00:29:32,200
For MPEG-4 streams,
which we also support,

639
00:29:32,200 --> 00:29:34,000
they're typically
higher quality.

640
00:29:34,000 --> 00:29:36,067
They typically
are going to use

641
00:29:36,067 --> 00:29:43,534
either an H.264 or a higher--
bigger size H.263 format.

642
00:29:43,534 --> 00:29:45,801
Usually they use
an AAC codec.

643
00:29:45,801 --> 00:29:48,000
And then
on our particular devices,

644
00:29:48,000 --> 00:29:52,534
the G1 and the device
that you just received today--

645
00:29:52,534 --> 00:29:54,501
I'm not even sure
what we're calling it--

646
00:29:54,501 --> 00:29:55,868
I--

647
00:29:55,868 --> 00:30:00,200
is capable of
up to 500kbits per second

648
00:30:00,200 --> 00:30:02,100
on the video side

649
00:30:02,100 --> 00:30:04,234
and 96kbits per second.

650
00:30:04,234 --> 00:30:06,901
So a total of about
600kbits per second,

651
00:30:06,901 --> 00:30:08,868
sustained.

652
00:30:08,868 --> 00:30:10,834
If you do your encoding well,

653
00:30:10,834 --> 00:30:13,667
you're going to actually
get more than that out of it.

654
00:30:13,667 --> 00:30:15,334
We've actually been able
to do better

655
00:30:15,334 --> 00:30:17,501
than 1 megabit per second,
but you have to be--

656
00:30:17,501 --> 00:30:19,300
have a really good encoder.

657
00:30:19,300 --> 00:30:21,801
If it gets "burst-y,"
it will interfere

658
00:30:21,801 --> 00:30:24,801
with the performance
of the codec.

659
00:30:28,801 --> 00:30:32,234
So one question that comes up
a lot on the forums

660
00:30:32,234 --> 00:30:34,634
is what container
should I use

661
00:30:34,634 --> 00:30:38,634
if I'm either authoring
or if I'm doing video recording?

662
00:30:38,634 --> 00:30:41,334
So for authoring
for our Android device,

663
00:30:41,334 --> 00:30:43,067
if you want
the best quality--

664
00:30:43,067 --> 00:30:45,868
the most bang for your bits,
so to speak--

665
00:30:45,868 --> 00:30:48,200
you want to use
an MPEG-4 codec--

666
00:30:48,200 --> 00:30:53,267
er, container file
with an H.264 encoded stream.

667
00:30:53,267 --> 00:30:57,267
It needs to be,
for these devices today,

668
00:30:57,267 --> 00:31:01,634
a baseline profile roughly,
as I was saying before,

669
00:31:01,634 --> 00:31:06,067
at 500kbits per second HVGA
or smaller,

670
00:31:06,067 --> 00:31:09,501
and AAC codec
up to 96kbits per second.

671
00:31:09,501 --> 00:31:11,334
That will get you
a pretty high quality--

672
00:31:11,334 --> 00:31:12,968
that's basically
the screen resolution.

673
00:31:12,968 --> 00:31:19,200
So it looks really good on--
on the display.

674
00:31:19,200 --> 00:31:22,334
For other--

675
00:31:22,334 --> 00:31:25,634
you're going to create content
on an Android device,

676
00:31:25,634 --> 00:31:28,534
so you have a video record
application, for example.

677
00:31:28,534 --> 00:31:31,934
And you want to be able
to send that via MMS

678
00:31:31,934 --> 00:31:35,267
or some other email or whatever
to another phone,

679
00:31:35,267 --> 00:31:37,767
you probably want to stick
to a 3GPP format,

680
00:31:37,767 --> 00:31:41,200
because not all phones
will support an MPEG-4 stream,

681
00:31:41,200 --> 00:31:43,567
particularly
the advanced codecs.

682
00:31:43,567 --> 00:31:49,567
So in that case
we recommend...

683
00:31:49,567 --> 00:31:51,701
I'm getting
ahead of myself here.

684
00:31:51,701 --> 00:31:54,968
So in that case we recommend
using the QCIF format.

685
00:31:54,968 --> 00:31:59,200
That's 192kbits per second.

686
00:31:59,200 --> 00:32:02,267
Now, if you're
creating content

687
00:32:02,267 --> 00:32:04,467
on the Android device itself,

688
00:32:04,467 --> 00:32:06,868
intended for another
Android device,

689
00:32:06,868 --> 00:32:09,667
we have an H.263 encoder.

690
00:32:09,667 --> 00:32:12,501
We don't have an H.264 encoder,

691
00:32:12,501 --> 00:32:14,701
so you're restricted to H.263.

692
00:32:14,701 --> 00:32:16,501
And for the same reason
I've discussed before,

693
00:32:16,501 --> 00:32:17,901
we won't have an AAC encoder,

694
00:32:17,901 --> 00:32:20,267
so you're going to use
an AMR narrow band encoder,

695
00:32:20,267 --> 00:32:23,467
at least on the current range
of devices.

696
00:32:23,467 --> 00:32:25,801
So those are kind of
the critical things

697
00:32:25,801 --> 00:32:30,033
in terms of inter-operability
with other devices.

698
00:32:30,033 --> 00:32:32,501
And then the other thing is--
a question that comes up a lot

699
00:32:32,501 --> 00:32:35,834
is if I want to stream
to an Android device,

700
00:32:35,834 --> 00:32:38,000
what do I need to do
to make that work?

701
00:32:38,000 --> 00:32:41,934
The thing where most people
fail on that

702
00:32:41,934 --> 00:32:46,467
is the "moov" atom,
which is the index of frames

703
00:32:46,467 --> 00:32:49,100
that tells--basically tells
the organization of the file,

704
00:32:49,100 --> 00:32:54,234
needs to precede the data--
the movie data atom.

705
00:32:54,234 --> 00:32:59,534
And...the...

706
00:32:59,534 --> 00:33:01,934
Most applications
will not do that naturally.

707
00:33:01,934 --> 00:33:04,501
I mean, it's more--
it's easier for a programmer

708
00:33:04,501 --> 00:33:07,234
to write something that builds
that index afterwards.

709
00:33:07,234 --> 00:33:08,467
So you have--
you typically have

710
00:33:08,467 --> 00:33:11,534
to give it a specific--
you know,

711
00:33:11,534 --> 00:33:12,901
turn something on,

712
00:33:12,901 --> 00:33:14,267
depending on what
the application is,

713
00:33:14,267 --> 00:33:15,934
or if you're using FFmpeg,

714
00:33:15,934 --> 00:33:18,367
you have to give it
a command line option

715
00:33:18,367 --> 00:33:20,267
that tell it to--
to put that atom

716
00:33:20,267 --> 00:33:22,601
at the beginning
instead of the end.

717
00:33:26,868 --> 00:33:30,267
So...

718
00:33:30,267 --> 00:33:33,901
For--we just recently came out
with what we've been calling

719
00:33:33,901 --> 00:33:36,534
the Cupcake release,
or the 1.5 release.

720
00:33:36,534 --> 00:33:39,200
That's the release
that's on the phones

721
00:33:39,200 --> 00:33:41,067
you just received today.

722
00:33:41,067 --> 00:33:45,033
Some of the new features
we added in the media framework.

723
00:33:45,033 --> 00:33:47,968
We talked about
video recording before.

724
00:33:47,968 --> 00:33:52,367
We added
an AudioTrack interface

725
00:33:52,367 --> 00:33:54,868
and an AudioRecord interface
in Java,

726
00:33:54,868 --> 00:33:57,501
which allows direct access
to raw audio.

727
00:33:57,501 --> 00:34:00,133
And we added the JET
interactive MIDI engine.

728
00:34:00,133 --> 00:34:02,133
These are kind of the--
the highlights

729
00:34:02,133 --> 00:34:03,968
in the media framework area.

730
00:34:03,968 --> 00:34:08,434
So kind of digging
into the specifics here...

731
00:34:08,434 --> 00:34:11,467
AudioTrack--
we've had a lot of requests

732
00:34:11,467 --> 00:34:15,467
for getting
direct access to audio.

733
00:34:15,467 --> 00:34:18,300
And...so what AudioTrack does
is allow you

734
00:34:18,300 --> 00:34:21,367
to write a raw stream
from Java

735
00:34:21,367 --> 00:34:25,000
directly to the Audio Flinger
mixer engine.

736
00:34:25,000 --> 00:34:28,367
Audio Flinger
is a software mixer engine

737
00:34:28,367 --> 00:34:31,634
that abstracts the hardware
interface for you.

738
00:34:31,634 --> 00:34:35,100
So it could actually--
it could mix multiple streams

739
00:34:35,100 --> 00:34:37,734
from different applications.

740
00:34:37,734 --> 00:34:39,400
To give you an example,

741
00:34:39,400 --> 00:34:41,801
you could be listening
to an MP3 file

742
00:34:41,801 --> 00:34:43,367
while the phone rings.

743
00:34:43,367 --> 00:34:45,601
And the ringtone will play

744
00:34:45,601 --> 00:34:47,834
while the MP3 file
is still playing.

745
00:34:47,834 --> 00:34:51,267
Or a game could have
multiple sound effects

746
00:34:51,267 --> 00:34:52,767
that are all playing
at the same time.

747
00:34:52,767 --> 00:34:55,100
And the mixer engine takes care
of that automatically for you.

748
00:34:55,100 --> 00:34:57,534
You don't have to write
a special mixer engine.

749
00:34:57,534 --> 00:35:00,200
It's in--
built into the device.

750
00:35:00,200 --> 00:35:03,601
Potentially could be hardware
accelerated in the future.

751
00:35:03,601 --> 00:35:07,100
And it also allows you
to...

752
00:35:07,100 --> 00:35:09,100
It does sample rate conversion
for you.

753
00:35:09,100 --> 00:35:12,100
So you can mix multiple streams
at different sample rates.

754
00:35:12,100 --> 00:35:15,300
You can modify the pitch
and so on and so forth.

755
00:35:15,300 --> 00:35:19,100
So what AudioTrack does,
it gives you direct access

756
00:35:19,100 --> 00:35:20,367
to that mixer engine.

757
00:35:20,367 --> 00:35:24,367
So you can take
a raw Java stream,

758
00:35:24,367 --> 00:35:27,200
you know, 16-bit PCM samples,
for example,

759
00:35:27,200 --> 00:35:28,567
and you can--
you can send that out

760
00:35:28,567 --> 00:35:30,234
to the mixer engine.

761
00:35:30,234 --> 00:35:32,701
Have it do the sample rate
conversion for you.

762
00:35:32,701 --> 00:35:34,701
Do volume control for you.

763
00:35:34,701 --> 00:35:37,934
It does--
has anti-zipper volume filters

764
00:35:37,934 --> 00:35:40,934
so--if anybody's ever played
with audio before,

765
00:35:40,934 --> 00:35:43,701
if you change the volume,

766
00:35:43,701 --> 00:35:46,067
it changes the volume
in discrete steps

767
00:35:46,067 --> 00:35:49,601
so you don't get
the pops or clicks

768
00:35:49,601 --> 00:35:53,167
or what we typically refer to
as zipper noise.

769
00:35:53,167 --> 00:35:56,801
And that's all done
with...

770
00:35:56,801 --> 00:36:00,234
Either you can do writes
on a thread in Java,

771
00:36:00,234 --> 00:36:05,734
or you can use the callback
engine to fill the buffer.

772
00:36:05,734 --> 00:36:10,000
Similarly, AudioRecord gives you
direct access to the microphone.

773
00:36:10,000 --> 00:36:12,300
So in the same sort of way,

774
00:36:12,300 --> 00:36:14,167
you could pull up a stream
from the microphone.

775
00:36:14,167 --> 00:36:17,033
You specify the sample rate
you want it in.

776
00:36:17,033 --> 00:36:18,501
And, you know,
with the combination

777
00:36:18,501 --> 00:36:19,734
of the two of those,

778
00:36:19,734 --> 00:36:22,734
you can now take a stream
from the microphone,

779
00:36:22,734 --> 00:36:25,601
do some processing on it,
and now put it back out

780
00:36:25,601 --> 00:36:27,267
via the...

781
00:36:27,267 --> 00:36:31,567
the AudioTrack interface too,
that mixer engine.

782
00:36:31,567 --> 00:36:34,901
And that mixer engine will go
wherever audio is routed.

783
00:36:34,901 --> 00:36:37,100
So, for example,
a question that comes up

784
00:36:37,100 --> 00:36:39,801
a lot is, well, what if
they have a Bluetooth device?

785
00:36:39,801 --> 00:36:41,701
Well, that's actually
handled for you automatically.

786
00:36:41,701 --> 00:36:44,067
There's nothing you have to do
as an application programmer.

787
00:36:44,067 --> 00:36:50,000
If there's a Bluetooth device
paired that supports A2DP,

788
00:36:50,000 --> 00:36:51,601
then that audio
is going to go directly

789
00:36:51,601 --> 00:36:54,501
to the...to the A2DP headset.

790
00:36:54,501 --> 00:36:58,801
Your...whether it's a headset
or even your car or whatever.

791
00:36:58,801 --> 00:37:02,367
And then we've got
this call mack--

792
00:37:02,367 --> 00:37:05,000
callback mechanism
so you can actually

793
00:37:05,000 --> 00:37:07,267
just set up a buffer
and just keep--

794
00:37:07,267 --> 00:37:08,834
when you get a callback,
you fill it.

795
00:37:08,834 --> 00:37:10,701
You know, if you're doing
a ping-pong buffer,

796
00:37:10,701 --> 00:37:13,334
where you have half of it
being filled

797
00:37:13,334 --> 00:37:16,734
and the other half is actually
being output to the device.

798
00:37:16,734 --> 00:37:18,901
And there's also
a static buffer mode

799
00:37:18,901 --> 00:37:21,868
where you give it a--
for example,

800
00:37:21,868 --> 00:37:23,334
a sound effect
that you want to play

801
00:37:23,334 --> 00:37:25,234
and it only does a single copy.

802
00:37:25,234 --> 00:37:27,601
And then it just
automatically mixes it,

803
00:37:27,601 --> 00:37:29,033
so each time
you trigger the sound,

804
00:37:29,033 --> 00:37:30,734
it will mix it for you,

805
00:37:30,734 --> 00:37:33,634
and you don't have to do
additional memory copies.

806
00:37:33,634 --> 00:37:35,934
So those are kind of
the big highlights

807
00:37:35,934 --> 00:37:40,067
in terms of the--
the audio pieces of it.

808
00:37:40,067 --> 00:37:44,601
Then another new piece
that's actually been in there

809
00:37:44,601 --> 00:37:47,667
for a while, but we've finally
implemented the Java support,

810
00:37:47,667 --> 00:37:50,667
is the JET Interactive
MIDI Engine.

811
00:37:50,667 --> 00:37:53,667
So JET is--

812
00:37:53,667 --> 00:37:57,834
it's based upon
the EAS MIDI engine.

813
00:37:57,834 --> 00:38:01,367
And what it does is allow you
to pre-author some content

814
00:38:01,367 --> 00:38:04,133
that is very interactive.

815
00:38:04,133 --> 00:38:06,801
So what you do
is you,

816
00:38:06,801 --> 00:38:09,868
if you're an author,
you're going to create content

817
00:38:09,868 --> 00:38:12,667
in a--
your favorite authoring tool.

818
00:38:12,667 --> 00:38:14,501
Digital authoring
workstation tool.

819
00:38:14,501 --> 00:38:17,934
It has a VST plugin,
so that you can, you know,

820
00:38:17,934 --> 00:38:20,868
basically write your--
your game code--

821
00:38:20,868 --> 00:38:23,834
your--your audio
in the tool

822
00:38:23,834 --> 00:38:28,334
and hear it back played as it
would be played on the device.

823
00:38:28,334 --> 00:38:31,701
You can take and have
multiple tracks

824
00:38:31,701 --> 00:38:35,033
that are synchronized
and mute them and unmute them

825
00:38:35,033 --> 00:38:37,234
synchronous with the segment.

826
00:38:37,234 --> 00:38:40,300
So basically, your piece
is going to be divided up into

827
00:38:40,300 --> 00:38:42,033
a bunch of little segments.

828
00:38:42,033 --> 00:38:43,901
And just as an example,

829
00:38:43,901 --> 00:38:47,234
I might have an A section,
like the intro,

830
00:38:47,234 --> 00:38:49,701
and maybe I have a verse
and I have a chorus.

831
00:38:49,701 --> 00:38:52,400
And I can interactively
get those to place

832
00:38:52,400 --> 00:38:53,934
one after another.

833
00:38:53,934 --> 00:38:58,667
So, for example,
if I have a game that, um--

834
00:38:58,667 --> 00:39:02,267
it has kind of levels,
I might start with

835
00:39:02,267 --> 00:39:05,501
a certain background noise,
and perhaps, you know,

836
00:39:05,501 --> 00:39:06,801
my character's taking damage.

837
00:39:06,801 --> 00:39:09,300
So I bring in
some little element

838
00:39:09,300 --> 00:39:12,234
that heightens the tension
in the game

839
00:39:12,234 --> 00:39:13,801
and this
is all done seamlessly.

840
00:39:13,801 --> 00:39:17,901
And it's very small content,
because it's MIDI.

841
00:39:17,901 --> 00:39:19,834
And then you can actually have
little flourishes

842
00:39:19,834 --> 00:39:22,133
that play in synchronization
with it--

843
00:39:22,133 --> 00:39:23,434
with the music
that's going on.

844
00:39:23,434 --> 00:39:27,033
So some--for example,
let's say you, you know,

845
00:39:27,033 --> 00:39:29,133
you take out an enemy.

846
00:39:29,133 --> 00:39:31,901
There's a little trumpet sound
or whatever.

847
00:39:31,901 --> 00:39:33,400
A sound effect
that's synchronized

848
00:39:33,400 --> 00:39:36,734
with the rest of the--
the audio that's playing.

849
00:39:36,734 --> 00:39:40,434
Now all this is done under--
under program control.

850
00:39:40,434 --> 00:39:42,200
In addition to that,
you also have the ability

851
00:39:42,200 --> 00:39:44,767
to have callbacks
that are synchronized.

852
00:39:44,767 --> 00:39:47,901
So a good example would be
a <i>Guitar Hero</i> type game

853
00:39:47,901 --> 00:39:51,234
where you have music
playing in the background.

854
00:39:51,234 --> 00:39:53,400
What you really want to do
is have the player

855
00:39:53,400 --> 00:39:56,701
do something in synchronization
with the rhythm of the sound.

856
00:39:56,701 --> 00:39:59,267
So you can get a callback
in your Java application

857
00:39:59,267 --> 00:40:01,734
that tells you when
a particular event occurred.

858
00:40:01,734 --> 00:40:05,634
So you could create
these tracks of--of events

859
00:40:05,634 --> 00:40:07,701
that you've been--
you know, measured--

860
00:40:07,701 --> 00:40:10,000
did they hit
before or after?

861
00:40:10,000 --> 00:40:12,267
And we actually have
a sample application

862
00:40:12,267 --> 00:40:14,567
in the SDK that shows you
how to do this.

863
00:40:14,567 --> 00:40:18,234
It's a--I think a, like,
two- or three-level game

864
00:40:18,234 --> 00:40:20,467
that with--
complete with graphics

865
00:40:20,467 --> 00:40:26,100
and sound and everything
to show you how to do it.

866
00:40:26,100 --> 00:40:28,400
The code--the code itself
is written in native code

867
00:40:28,400 --> 00:40:29,901
that's sitting on top
of the EAS engine,

868
00:40:29,901 --> 00:40:33,234
so again, in keeping
with our philosophy

869
00:40:33,234 --> 00:40:35,100
of trying to minimize the--

870
00:40:35,100 --> 00:40:37,300
the overhead
from the application,

871
00:40:37,300 --> 00:40:38,868
this is all happening
in background.

872
00:40:38,868 --> 00:40:41,100
You don't have to do anything
to keep it going

873
00:40:41,100 --> 00:40:44,100
other than
keep feeding it segments.

874
00:40:44,100 --> 00:40:45,934
So periodically,
you're going to wake up and say,

875
00:40:45,934 --> 00:40:48,968
"Oh, well, here's the next
segment of audio to play,"

876
00:40:48,968 --> 00:40:50,634
and then it will play
automatically

877
00:40:50,634 --> 00:40:53,968
for whatever the length
of that segment is.

878
00:40:53,968 --> 00:40:56,601
It's all open source.

879
00:40:56,601 --> 00:40:58,968
Not only is the--
the code itself open source,

880
00:40:58,968 --> 00:41:00,801
but the tools are open sourced,

881
00:41:00,801 --> 00:41:03,801
including the VST plugin.

882
00:41:03,801 --> 00:41:05,501
So if you are ambitious

883
00:41:05,501 --> 00:41:07,467
and you want to do something
interesting with it,

884
00:41:07,467 --> 00:41:10,968
it's all sitting out there
for you to play with.

885
00:41:10,968 --> 00:41:13,601
I think it's out there now.

886
00:41:13,601 --> 00:41:16,167
If not, it will be shortly.

887
00:41:16,167 --> 00:41:20,067
And so those are
the big highlights of the--

888
00:41:20,067 --> 00:41:25,934
the MIDI--
the MIDI engine.

889
00:41:25,934 --> 00:41:27,367
Oh, I forgot.
One more thing.

890
00:41:27,367 --> 00:41:30,601
The DLS support--
so one of the critiques

891
00:41:30,601 --> 00:41:32,934
of general MIDI,
or MIDI in general,

892
00:41:32,934 --> 00:41:34,334
is the quality
of the instruments.

893
00:41:34,334 --> 00:41:37,400
And admittedly, what we ship
with the device is pretty small.

894
00:41:37,400 --> 00:41:39,734
We try to keep
the code size down.

895
00:41:39,734 --> 00:41:42,701
But what the DLS support
does with JET

896
00:41:42,701 --> 00:41:45,667
is allow you
to load your own samples.

897
00:41:45,667 --> 00:41:48,567
So you can either
author them yourself

898
00:41:48,567 --> 00:41:50,133
or you can go
to a content provider

899
00:41:50,133 --> 00:41:51,868
and author these things.

900
00:41:51,868 --> 00:41:53,634
So if you want
a high-quality piano

901
00:41:53,634 --> 00:41:55,567
or you want, you know,
a particular drum set,

902
00:41:55,567 --> 00:41:58,100
you're going for a techno sound
or whatever,

903
00:41:58,100 --> 00:41:59,601
you can actually, you know,

904
00:41:59,601 --> 00:42:01,167
put these things
inside the game,

905
00:42:01,167 --> 00:42:02,334
use them as a resource,

906
00:42:02,334 --> 00:42:05,133
load them in and--
and your game will have

907
00:42:05,133 --> 00:42:06,834
a unique flavor
that you don't get

908
00:42:06,834 --> 00:42:08,467
from the general MIDI set.

909
00:42:13,267 --> 00:42:16,000
So...

910
00:42:16,000 --> 00:42:18,367
I wanted to talk about
a few common problems

911
00:42:18,367 --> 00:42:20,434
that people run into.

912
00:42:20,434 --> 00:42:21,801
Start with the first one here.

913
00:42:21,801 --> 00:42:24,267
This one I see a lot.

914
00:42:24,267 --> 00:42:27,701
And that is the behavior
of the application

915
00:42:27,701 --> 00:42:31,534
for the volume control is--
is inconsistent.

916
00:42:31,534 --> 00:42:34,701
So, volume control
on Android devices

917
00:42:34,701 --> 00:42:36,534
is an overloaded function.

918
00:42:36,534 --> 00:42:39,868
And as you can see
from here,

919
00:42:39,868 --> 00:42:42,868
if you're in a call,
what the volume control does

920
00:42:42,868 --> 00:42:44,434
is adjust the volume
that you're hearing

921
00:42:44,434 --> 00:42:46,067
from the other end
of the phone.

922
00:42:46,067 --> 00:42:48,834
If you're not in a call,
if it's ringing,

923
00:42:48,834 --> 00:42:52,634
pressing the volume button
mutes the--the ringer.

924
00:42:52,634 --> 00:42:53,868
Oh, panic.

925
00:42:53,868 --> 00:42:56,901
I'm in a, you know,
middle of a presentation

926
00:42:56,901 --> 00:42:58,567
and my phone goes off.

927
00:42:58,567 --> 00:43:00,934
So that's how you mute it.

928
00:43:00,934 --> 00:43:03,667
If we can detect
that a media track is active,

929
00:43:03,667 --> 00:43:07,400
then we'll adjust the volume
of whatever is playing.

930
00:43:07,400 --> 00:43:11,267
But otherwise,
it adjusts the ringtone volume.

931
00:43:11,267 --> 00:43:13,868
The issue here is that if your--
if your game is--

932
00:43:13,868 --> 00:43:17,367
or your application is just
sporadically making sounds,

933
00:43:17,367 --> 00:43:20,133
like, you know,
you just have little UI elements

934
00:43:20,133 --> 00:43:22,934
or you play a sound effect
periodically,

935
00:43:22,934 --> 00:43:26,067
you can only adjust the volume
of the application

936
00:43:26,067 --> 00:43:28,601
during that short period
that the sound is playing.

937
00:43:28,601 --> 00:43:30,200
It's because we don't
actually know

938
00:43:30,200 --> 00:43:33,667
that you're going to make sound
until that particular instant.

939
00:43:33,667 --> 00:43:36,968
So if you want
to make it work correctly,

940
00:43:36,968 --> 00:43:42,000
there's an--
there's an API you need to call.

941
00:43:42,000 --> 00:43:46,634
It's in--it's part
of the activity package.

942
00:43:46,634 --> 00:43:48,834
It's called
setVolumeControlStream.

943
00:43:48,834 --> 00:43:51,200
So you can see a little chunk
of code here.

944
00:43:51,200 --> 00:43:52,801
In your onCreate,

945
00:43:52,801 --> 00:43:55,968
you're going to call this
setVolumeControlStream

946
00:43:55,968 --> 00:43:59,300
and tell it what kind of stream
you're going to play.

947
00:43:59,300 --> 00:44:03,033
In the case of most applications
that are in the foreground,

948
00:44:03,033 --> 00:44:04,100
that are playing audio,

949
00:44:04,100 --> 00:44:05,734
you probably want
streamed music,

950
00:44:05,734 --> 00:44:08,334
which is kind of
our generic placeholder

951
00:44:08,334 --> 00:44:11,534
for, you know, audio
that's in the foreground.

952
00:44:11,534 --> 00:44:14,934
If your ringtone application,
for some--

953
00:44:14,934 --> 00:44:16,300
you know,
you're playing ringtones,

954
00:44:16,300 --> 00:44:18,200
and you would select
a different type.

955
00:44:18,200 --> 00:44:20,167
But this basically tells
the activity manager,

956
00:44:20,167 --> 00:44:22,100
when you press the audio button,

957
00:44:22,100 --> 00:44:27,634
if none of those...

958
00:44:27,634 --> 00:44:30,968
previous things are--
in other words,

959
00:44:30,968 --> 00:44:32,968
if we're not in call,
if it's not ringing,

960
00:44:32,968 --> 00:44:34,567
and if there's--
if--

961
00:44:34,567 --> 00:44:36,200
if none of these other things
are happening,

962
00:44:36,200 --> 00:44:38,934
then that's the default behavior
of the volume control.

963
00:44:38,934 --> 00:44:41,300
Without that,
you're probably going to get

964
00:44:41,300 --> 00:44:43,934
pretty inconsistent behavior
and frustrated users.

965
00:44:43,934 --> 00:44:46,501
That's probably
the number one problem

966
00:44:46,501 --> 00:44:48,968
I see with applications
in the marketplace today

967
00:44:48,968 --> 00:44:52,033
is they're not using that.

968
00:44:52,033 --> 00:44:55,601
Another common one I see
on the--in a--

969
00:44:55,601 --> 00:44:57,300
on the forums
is people saying,

970
00:44:57,300 --> 00:45:01,200
"How do I--how do I play
a file from my APK?

971
00:45:01,200 --> 00:45:03,133
"I just want to have
an audio file

972
00:45:03,133 --> 00:45:05,934
that I ship with the--
with the package,"

973
00:45:05,934 --> 00:45:07,667
and they get this wrong
for whatever reason.

974
00:45:07,667 --> 00:45:09,200
I think we have
some code out there

975
00:45:09,200 --> 00:45:11,667
from a long time ago
that looks like this.

976
00:45:11,667 --> 00:45:16,734
And so this doesn't work.

977
00:45:16,734 --> 00:45:19,567
This is the correct way
to do it.

978
00:45:19,567 --> 00:45:23,000
So there's this
AssetFileDescriptor.

979
00:45:23,000 --> 00:45:25,901
I talked a little bit earlier
about the binder object

980
00:45:25,901 --> 00:45:27,734
and how we pass things through,

981
00:45:27,734 --> 00:45:29,834
so we're going to pass
the file descriptor,

982
00:45:29,834 --> 00:45:33,200
which is a pointer
to your resource,

983
00:45:33,200 --> 00:45:37,267
through the binder
to the...

984
00:45:37,267 --> 00:45:39,067
I don't know
how that period got in there.

985
00:45:39,067 --> 00:45:40,434
It should be setDataSource.

986
00:45:40,434 --> 00:45:44,000
So it's setDataSource,
takes a FileDescriptor,

987
00:45:44,000 --> 00:45:45,467
StartOffset,
and a Length,

988
00:45:45,467 --> 00:45:48,634
and so what this will do is,
using a resource ID,

989
00:45:48,634 --> 00:45:51,167
it will find, you know,
open it,

990
00:45:51,167 --> 00:45:53,467
find the offset
where that raw--

991
00:45:53,467 --> 00:45:55,234
that resource starts.

992
00:45:55,234 --> 00:45:57,701
And it will, you know,
pass--

993
00:45:57,701 --> 00:46:01,567
set those values
so that we can tell

994
00:46:01,567 --> 00:46:03,234
the media player
where to find it,

995
00:46:03,234 --> 00:46:04,667
and the media player
will then play that

996
00:46:04,667 --> 00:46:07,601
from that offset
in the FileDescriptor.

997
00:46:14,067 --> 00:46:15,367
I had another thought there.

998
00:46:15,367 --> 00:46:17,200
Oh, yeah.
So--yeah.

999
00:46:17,200 --> 00:46:21,434
Raw resources, make sure
that when you put your file in,

1000
00:46:21,434 --> 00:46:23,601
you're putting it in
as a raw resource,

1001
00:46:23,601 --> 00:46:25,167
so it doesn't get compressed.

1002
00:46:25,167 --> 00:46:28,300
We don't compress things
like MP3 files and so on.

1003
00:46:28,300 --> 00:46:34,234
They have to be
in the raw directory.

1004
00:46:34,234 --> 00:46:36,534
Another common one
I see on the forums

1005
00:46:36,534 --> 00:46:39,267
is people running out
of MediaPlayers.

1006
00:46:39,267 --> 00:46:41,133
And this is kind of
an absurd example,

1007
00:46:41,133 --> 00:46:42,834
but, you know,
just to give you a point.

1008
00:46:42,834 --> 00:46:44,534
There is a limited amount
of resources.

1009
00:46:44,534 --> 00:46:45,834
This is an embedded device.

1010
00:46:45,834 --> 00:46:48,567
A lot of people who are
moving over from the desktop

1011
00:46:48,567 --> 00:46:50,200
don't realize that they're
working with something

1012
00:46:50,200 --> 00:46:52,934
that's, you know,
equivalent to a desktop system

1013
00:46:52,934 --> 00:46:55,033
from maybe ten years ago.

1014
00:46:55,033 --> 00:46:57,601
So don't do this.

1015
00:46:57,601 --> 00:47:01,200
If you're going to use
MediaPlayers,

1016
00:47:01,200 --> 00:47:02,367
try to recycle them.

1017
00:47:02,367 --> 00:47:06,734
So our solution is,
you know,

1018
00:47:06,734 --> 00:47:09,434
there are resources
that are actually allocated

1019
00:47:09,434 --> 00:47:10,901
when you create a MediaPlayer.

1020
00:47:10,901 --> 00:47:14,067
It's allocating memory,
it may be loading codecs.

1021
00:47:14,067 --> 00:47:16,367
It may--there may actually
be a hardware codec

1022
00:47:16,367 --> 00:47:18,701
that's been instantiated
that you're preventing

1023
00:47:18,701 --> 00:47:20,300
the rest of the system
from using.

1024
00:47:20,300 --> 00:47:21,634
So whenever
you're done with them,

1025
00:47:21,634 --> 00:47:24,100
make sure you release them.

1026
00:47:24,100 --> 00:47:25,734
So you're going to call release,

1027
00:47:25,734 --> 00:47:28,167
you set null
on the MediaPlayer object.

1028
00:47:28,167 --> 00:47:32,300
Or you can call reset and set--
do a new setDataSource,

1029
00:47:32,300 --> 00:47:35,567
which, you know, is basically
just recycling your MediaPlayer.

1030
00:47:35,567 --> 00:47:39,000
And try to keep it to, you know,
two or three maximum.

1031
00:47:39,000 --> 00:47:43,100
'Cause you are sharing with
other applications, hopefully.

1032
00:47:43,100 --> 00:47:46,467
And so if you get a little piggy
with your MediaPlayer resources,

1033
00:47:46,467 --> 00:47:49,934
somebody else can't get them.

1034
00:47:49,934 --> 00:47:53,801
And also, if you go
into the background--

1035
00:47:53,801 --> 00:47:55,234
so, and you're in--
on pause,

1036
00:47:55,234 --> 00:47:58,367
you definitely want to release
all of your MediaPlayers

1037
00:47:58,367 --> 00:48:03,367
so that other applications
can get access to them.

1038
00:48:03,367 --> 00:48:05,734
Another big one
that happens a lot

1039
00:48:05,734 --> 00:48:10,133
is the CPU...
"My CPU is saturated."

1040
00:48:10,133 --> 00:48:12,601
And you look at the logs
and you see this.

1041
00:48:12,601 --> 00:48:16,167
You know, CPU is--
is--

1042
00:48:16,167 --> 00:48:17,934
can't remember
what the message is now.

1043
00:48:17,934 --> 00:48:23,801
But it's pretty clear
that the CPU is unhappy.

1044
00:48:23,801 --> 00:48:25,434
And this is kind of
the typical thing,

1045
00:48:25,434 --> 00:48:26,767
is that you're trying to play
too many

1046
00:48:26,767 --> 00:48:29,200
different compressed streams
at a time.

1047
00:48:29,200 --> 00:48:32,868
Codecs take
a lot of CPU resources,

1048
00:48:32,868 --> 00:48:35,567
especially ones that are running
on software.

1049
00:48:35,567 --> 00:48:38,901
So, you know, a typical, say,
MP3 decode

1050
00:48:38,901 --> 00:48:43,133
of a high-quality MP3
might take 20% of the CPU.

1051
00:48:43,133 --> 00:48:44,601
You add up two or three
of those things,

1052
00:48:44,601 --> 00:48:47,234
and you're talking about
some serious CPU resources.

1053
00:48:47,234 --> 00:48:50,234
And then you wonder why your,
you know, frame rate

1054
00:48:50,234 --> 00:48:52,000
on your game is pretty bad.

1055
00:48:52,000 --> 00:48:54,033
Well, that's why.

1056
00:48:54,033 --> 00:48:57,968
So we actually have
a solution for this problem.

1057
00:48:57,968 --> 00:48:59,567
It's called SoundPool.

1058
00:48:59,567 --> 00:49:03,400
Now, SoundPool had some problems
in the 1.0, 1.1 release.

1059
00:49:03,400 --> 00:49:06,334
We fixed those problems
in Cupcake.

1060
00:49:06,334 --> 00:49:08,534
It's actually pretty useful.

1061
00:49:08,534 --> 00:49:12,067
So what it allows you to do
is take resources

1062
00:49:12,067 --> 00:49:16,901
that are encoded in MP3 or AAC
or Ogg Vorbis,

1063
00:49:16,901 --> 00:49:19,701
whatever
your preferred audio format is.

1064
00:49:19,701 --> 00:49:22,267
It decodes them and loads them
into memory

1065
00:49:22,267 --> 00:49:23,534
so they're ready to play,

1066
00:49:23,534 --> 00:49:26,234
and then uses
the AudioTrack interface

1067
00:49:26,234 --> 00:49:29,334
to play them out
through the mixer engine

1068
00:49:29,334 --> 00:49:30,901
just like
we were talking about before.

1069
00:49:30,901 --> 00:49:34,267
And so you can get
much lower overhead.

1070
00:49:34,267 --> 00:49:37,934
You know, some are in the order
of about 5% per stream

1071
00:49:37,934 --> 00:49:42,067
as compared to these, you know,
20% or 30%.

1072
00:49:42,067 --> 00:49:44,167
Depending on what
the audio codec is.

1073
00:49:44,167 --> 00:49:46,734
So it gives you
the same sort of flexibility.

1074
00:49:46,734 --> 00:49:49,334
You can modify--in fact,
it actually gives you

1075
00:49:49,334 --> 00:49:52,901
a little more flexibility,
because you can set the rates.

1076
00:49:52,901 --> 00:49:55,334
It can--
will manage streams for you.

1077
00:49:55,334 --> 00:49:57,100
So if you want to limit
the number of streams

1078
00:49:57,100 --> 00:49:59,267
that are playing,
you tell it upfront,

1079
00:49:59,267 --> 00:50:02,667
"I want," let's say,
"eight streams maximum."

1080
00:50:02,667 --> 00:50:04,868
If you exceed that,
it will automatically,

1081
00:50:04,868 --> 00:50:09,067
based on the priority, you know,
select the least priority,

1082
00:50:09,067 --> 00:50:11,133
get rid of that one,
and start the new sound.

1083
00:50:11,133 --> 00:50:14,667
So it's kind of managing
resources for you.

1084
00:50:14,667 --> 00:50:18,200
And then you can do things
like pan in real time.

1085
00:50:18,200 --> 00:50:20,234
You can change the pitch.

1086
00:50:20,234 --> 00:50:21,667
So if you want to get
a Doppler effect

1087
00:50:21,667 --> 00:50:24,334
or something like that,
this is the way to do it.

1088
00:50:26,634 --> 00:50:29,033
So that's pretty much it.

1089
00:50:29,033 --> 00:50:31,400
We have about ten minutes left
for questions,

1090
00:50:31,400 --> 00:50:34,501
if anybody wants to go up
to a microphone.

1091
00:50:34,501 --> 00:50:35,567
[applause]

1092
00:50:35,567 --> 00:50:37,100
Thank you.

1093
00:50:42,100 --> 00:50:44,000
man: Hi, thank you.
That was a great talk.

1094
00:50:44,000 --> 00:50:47,734
Is setting the
streamed music,

1095
00:50:47,734 --> 00:50:49,701
so you can respond
to the volume control--

1096
00:50:49,701 --> 00:50:51,868
do you have to do that every
time you create a new activity,

1097
00:50:51,868 --> 00:50:53,968
or is it sticky
for the life of the app?

1098
00:50:53,968 --> 00:50:55,968
Sparks: It's sticky--

1099
00:50:55,968 --> 00:50:59,501
you're going to call it
in your onCreate function.

1100
00:50:59,501 --> 00:51:00,868
man: But in
every single activity?

1101
00:51:00,868 --> 00:51:02,334
Sparks: Yeah, yeah.
man: Okay.

1102
00:51:05,801 --> 00:51:09,501
man: Hi, my first question
is that currently,

1103
00:51:09,501 --> 00:51:12,234
Android using the OpenCORE

1104
00:51:12,234 --> 00:51:14,834
for the multimedia framework.

1105
00:51:14,834 --> 00:51:18,434
And my question is that
does Google has any plan

1106
00:51:18,434 --> 00:51:21,000
to support any other middleware,

1107
00:51:21,000 --> 00:51:23,400
such as GStreamer
or anything else?

1108
00:51:23,400 --> 00:51:25,367
Sparks: Not at this time.

1109
00:51:25,367 --> 00:51:27,033
We don't have any plans
to support anything else.

1110
00:51:27,033 --> 00:51:28,200
man: Okay.

1111
00:51:28,200 --> 00:51:29,901
What's the strategy of Google

1112
00:51:29,901 --> 00:51:31,634
for supporting other pioneers

1113
00:51:31,634 --> 00:51:34,801
providing this
multimedia middleware?

1114
00:51:34,801 --> 00:51:38,133
Sparks: Well, so,
because of the flexibility

1115
00:51:38,133 --> 00:51:41,234
of the MediaPlayer service,
you could easily add

1116
00:51:41,234 --> 00:51:45,267
another code--another media
framework engine in there

1117
00:51:45,267 --> 00:51:46,634
and replace OpenCORE.

1118
00:51:46,634 --> 00:51:47,767
man: Okay.

1119
00:51:47,767 --> 00:51:50,167
So my second question
is that, um--

1120
00:51:50,167 --> 00:51:51,234
[coughs]

1121
00:51:51,234 --> 00:51:53,334
that currently--

1122
00:51:53,334 --> 00:51:57,501
Google, you mentioned
implementing the MediaPlayer

1123
00:51:57,501 --> 00:51:58,968
and the recording service.

1124
00:51:58,968 --> 00:52:02,901
Is there any plan to support
the mobile TV and other,

1125
00:52:02,901 --> 00:52:06,033
such as video conference,
in frameworks?

1126
00:52:06,033 --> 00:52:09,133
Sparks: We're--we're looking
at video conferencing.

1127
00:52:09,133 --> 00:52:12,133
Digital TV is probably
a little bit farther out.

1128
00:52:12,133 --> 00:52:15,667
We kind of need a platform
to do the development on.

1129
00:52:15,667 --> 00:52:17,868
So we'll be working
with partners.

1130
00:52:17,868 --> 00:52:20,033
Basically, if there's
a partner that's interested

1131
00:52:20,033 --> 00:52:22,901
in something that isn't there,

1132
00:52:22,901 --> 00:52:25,200
we will--we can
work with you on it.

1133
00:52:25,200 --> 00:52:27,968
man: Okay, thank you.

1134
00:52:27,968 --> 00:52:31,934
man: Does the media framework
support RTSP control?

1135
00:52:31,934 --> 00:52:33,501
Sparks: Yes.

1136
00:52:33,501 --> 00:52:37,634
So RTSP support is not as good
as we'd like it to be.

1137
00:52:37,634 --> 00:52:39,834
It's getting better
with every release.

1138
00:52:39,834 --> 00:52:42,033
And we're expecting
to make some more strides

1139
00:52:42,033 --> 00:52:43,601
in the next release
after this.

1140
00:52:43,601 --> 00:52:44,767
But Cupcake is slightly better.

1141
00:52:44,767 --> 00:52:47,601
man: And that's specified by...

1142
00:52:47,601 --> 00:52:49,467
in the URL, by specifying
the RTSP?

1143
00:52:49,467 --> 00:52:50,934
Sparks: Yeah. Right.
man: Okay.

1144
00:52:50,934 --> 00:52:55,634
And you mentioned, like,
500 kilobits per second

1145
00:52:55,634 --> 00:52:58,067
being the maximum, or--

1146
00:52:58,067 --> 00:52:59,534
What if you tried
to play something

1147
00:52:59,534 --> 00:53:00,834
that is larger than that?

1148
00:53:00,834 --> 00:53:04,000
Sparks: Well, the codec
may fall behind.

1149
00:53:04,000 --> 00:53:08,200
What will typically happen
is that you'll get a--

1150
00:53:08,200 --> 00:53:11,834
if you're using our MovieView,
you'll get an error message

1151
00:53:11,834 --> 00:53:13,501
that says that
it can't keep up.

1152
00:53:13,501 --> 00:53:15,968
man: Mm-hmm. So it will try,
but it will--

1153
00:53:15,968 --> 00:53:17,534
It might fall behind.
Sparks: Yeah.

1154
00:53:17,534 --> 00:53:19,300
man: Thank you.

1155
00:53:19,300 --> 00:53:21,734
man: My question is ask--

1156
00:53:21,734 --> 00:53:24,701
how about--
how much flexibility we have

1157
00:53:24,701 --> 00:53:26,467
to control the camera services?

1158
00:53:26,467 --> 00:53:29,801
For example,
can I control the frame rate,

1159
00:53:29,801 --> 00:53:33,834
and the color tunings,
and et cetera?

1160
00:53:33,834 --> 00:53:36,334
Sparks: Yeah, some of that's
going to depend on the--

1161
00:53:36,334 --> 00:53:38,234
on the device.

1162
00:53:38,234 --> 00:53:40,100
We're still kind of struggling

1163
00:53:40,100 --> 00:53:42,968
with some
of the device-specific things,

1164
00:53:42,968 --> 00:53:44,334
but in the case of the camera,

1165
00:53:44,334 --> 00:53:46,100
there's a setParameters
interface.

1166
00:53:46,100 --> 00:53:49,033
And there's access,
depending on the device,

1167
00:53:49,033 --> 00:53:51,033
to some of those parameters.

1168
00:53:51,033 --> 00:53:53,267
The way you know that is,
you do a setParameter.

1169
00:53:53,267 --> 00:53:55,901
Let's say you ask
for a certain frame rate.

1170
00:53:55,901 --> 00:53:57,400
You--you do a getParameter.

1171
00:53:57,400 --> 00:53:59,767
You find out if it accepted
your frame rate or not.

1172
00:53:59,767 --> 00:54:01,200
Because there's a number
of parameters.

1173
00:54:01,200 --> 00:54:04,567
man: Yeah, but also, in the--
for example, the low light.

1174
00:54:04,567 --> 00:54:07,734
So you want--not only you want
to slow the frame rate,

1175
00:54:07,734 --> 00:54:09,968
but also you want to increase
the integration time.

1176
00:54:09,968 --> 00:54:11,067
Sparks: Right.

1177
00:54:11,067 --> 00:54:13,234
man: So in the--
sometimes you want,

1178
00:54:13,234 --> 00:54:14,334
even in the low light,

1179
00:54:14,334 --> 00:54:16,167
but you want
to slow the frame rate.

1180
00:54:16,167 --> 00:54:20,868
But you still want to keep
the normal integration time.

1181
00:54:20,868 --> 00:54:24,133
So how you--do you have those
kind of flexibility to control?

1182
00:54:24,133 --> 00:54:25,801
Sparks: Well,
so that's going to depend

1183
00:54:25,801 --> 00:54:27,801
on whether the hardware
supports it or not.

1184
00:54:27,801 --> 00:54:30,234
If the hardware supports it,
then there should be

1185
00:54:30,234 --> 00:54:31,501
a parameter for that.

1186
00:54:31,501 --> 00:54:33,567
One of the things
we've done is--

1187
00:54:33,567 --> 00:54:36,100
for hardware dev--
manufacturers

1188
00:54:36,100 --> 00:54:38,734
that have specific things
that they want to support,

1189
00:54:38,734 --> 00:54:40,868
that aren't like, standard--

1190
00:54:40,868 --> 00:54:44,767
they can add a prefix to their
parameter key value pairs.

1191
00:54:44,767 --> 00:54:47,534
So that will, you know--
it's unique to that device.

1192
00:54:47,534 --> 00:54:51,400
And we're certainly open
to manufacturers suggesting,

1193
00:54:51,400 --> 00:54:53,667
you know, new--
new standard parameters.

1194
00:54:53,667 --> 00:54:55,667
And we're starting to adopt
more of those.

1195
00:54:55,667 --> 00:55:00,701
So, for example, like,
white balance is in there.

1196
00:55:00,701 --> 00:55:03,133
Scene modes, things like that
are all part of it.

1197
00:55:03,133 --> 00:55:05,634
man: Okay.
Sparks: Yeah.

1198
00:55:05,634 --> 00:55:08,267
man: I was wondering
what kind of native code hooks

1199
00:55:08,267 --> 00:55:10,133
the audio framework has?

1200
00:55:10,133 --> 00:55:13,100
I'm working on an app
that basically would involve,

1201
00:55:13,100 --> 00:55:15,534
like, actively doing
a fast Fourier transform,

1202
00:55:15,534 --> 00:55:18,834
you know, on however many
samples you can get at a time.

1203
00:55:18,834 --> 00:55:22,234
And so, it seems like
for now--

1204
00:55:22,234 --> 00:55:24,234
or in the Java, for example,

1205
00:55:24,234 --> 00:55:26,467
it's mostly built
toward recording audio and--

1206
00:55:26,467 --> 00:55:27,968
and doing things with that.

1207
00:55:27,968 --> 00:55:31,000
What sort of active control
do you have over the device?

1208
00:55:31,000 --> 00:55:33,667
Sparks: So officially,
we don't support

1209
00:55:33,667 --> 00:55:37,567
native API access
to audio yet.

1210
00:55:37,567 --> 00:55:40,234
The reason for that is,

1211
00:55:40,234 --> 00:55:42,501
we, you know--
any API we publish,

1212
00:55:42,501 --> 00:55:44,067
we're going to have to live with
for a long whi--

1213
00:55:44,067 --> 00:55:45,634
a long time.

1214
00:55:45,634 --> 00:55:48,067
We're still playing
with APIs,

1215
00:55:48,067 --> 00:55:50,467
trying to, you know, get--
make them better.

1216
00:55:50,467 --> 00:55:51,734
And so the audio APIs

1217
00:55:51,734 --> 00:55:53,534
have changed a little bit
in Cupcake.

1218
00:55:53,534 --> 00:55:55,701
They're going to change again
in the next two releases.

1219
00:55:55,701 --> 00:55:57,567
At that point,
we'll probably be ready

1220
00:55:57,567 --> 00:56:00,000
to start providing
native access.

1221
00:56:00,000 --> 00:56:01,834
What you can do,

1222
00:56:01,834 --> 00:56:04,200
very shortly we'll have
a native SDK,

1223
00:56:04,200 --> 00:56:07,534
which will give you access
to libc and libm.

1224
00:56:07,534 --> 00:56:10,567
You can get access
to the audio

1225
00:56:10,567 --> 00:56:14,667
from the Java--
official Java APIs,

1226
00:56:14,667 --> 00:56:16,200
do your processing
in native code,

1227
00:56:16,200 --> 00:56:18,634
and then feed it back,
and you'll be able to do that

1228
00:56:18,634 --> 00:56:19,868
without having to do MEMcopies.

1229
00:56:19,868 --> 00:56:21,300
man: And so basically,
that would just be

1230
00:56:21,300 --> 00:56:23,634
accessing the buffer
that the audio writes to.

1231
00:56:23,634 --> 00:56:26,501
And also, just a very tiny
question about the buffer.

1232
00:56:26,501 --> 00:56:28,300
Does it--

1233
00:56:28,300 --> 00:56:30,767
does it loop back
when you record the audio?

1234
00:56:30,767 --> 00:56:34,133
Or is it--does it record in,
essentially, like, blocks?

1235
00:56:34,133 --> 00:56:36,868
Do you record an entire buffer
once in a row,

1236
00:56:36,868 --> 00:56:38,801
or does it sort of go back to
the start and then keep going?

1237
00:56:38,801 --> 00:56:42,133
Sparks: You can either have it
cycle through a static buffer,

1238
00:56:42,133 --> 00:56:45,067
or you can just pass in
new buffers each time,

1239
00:56:45,067 --> 00:56:46,067
depending on how you want
to use it.

1240
00:56:46,067 --> 00:56:47,534
man: Okay. Thanks.

1241
00:56:49,934 --> 00:56:52,200
man: Let's say
you have a game

1242
00:56:52,200 --> 00:56:56,367
where you want to generate
a sound instantly

1243
00:56:56,367 --> 00:56:59,601
on a button press or a touch.

1244
00:56:59,601 --> 00:57:01,601
Sparks: "Instantly"
is a relative term.

1245
00:57:01,601 --> 00:57:03,334
man: As instantly
as you can get.

1246
00:57:03,334 --> 00:57:05,868
Would you recommend,
then, the JET MIDI stuff,

1247
00:57:05,868 --> 00:57:07,934
or an Ogg, or what?

1248
00:57:07,934 --> 00:57:10,601
Sparks: You--you're probably
going to get best results

1249
00:57:10,601 --> 00:57:11,868
with SoundPool,

1250
00:57:11,868 --> 00:57:13,868
because SoundPool's
really aimed at that.

1251
00:57:13,868 --> 00:57:15,801
What SoundPool
doesn't give you--

1252
00:57:15,801 --> 00:57:17,133
and we don't have an API
for it,

1253
00:57:17,133 --> 00:57:18,467
we get a lot of requests
for it,

1254
00:57:18,467 --> 00:57:20,467
so, you know, it's on my list
of things to do--

1255
00:57:20,467 --> 00:57:22,467
is synchronization.

1256
00:57:22,467 --> 00:57:25,334
So if you're trying to do
a rhythm game

1257
00:57:25,334 --> 00:57:28,934
where you--you want to be able
to have very precise control

1258
00:57:28,934 --> 00:57:30,968
of--of, say, a drum track--

1259
00:57:30,968 --> 00:57:33,100
you--there isn't a way
to do that today.

1260
00:57:33,100 --> 00:57:34,367
But if you're just trying
to do--

1261
00:57:34,367 --> 00:57:35,734
man: Like gunfire kind of thing.

1262
00:57:35,734 --> 00:57:38,033
Sparks: Gunfire?
SoundPool is perfect for that.

1263
00:57:38,033 --> 00:57:41,100
That's--that's what it was
intended for.

1264
00:57:41,100 --> 00:57:44,367
man: Yeah, if I use
the audio mixer,

1265
00:57:44,367 --> 00:57:46,434
can I control the volume

1266
00:57:46,434 --> 00:57:48,234
of the different sources
differently?

1267
00:57:48,234 --> 00:57:49,534
Sparks: Yes.
man: Okay.

1268
00:57:49,534 --> 00:57:52,200
Sparks: So, SoundPool
has a volume control

1269
00:57:52,200 --> 00:57:55,534
for each of
its channels that you--

1270
00:57:55,534 --> 00:57:59,200
basically, when you trigger
a SoundPool sound,

1271
00:57:59,200 --> 00:58:00,868
you get an ID back.

1272
00:58:00,868 --> 00:58:02,934
And you can use that
to control that sound.

1273
00:58:02,934 --> 00:58:04,567
If you're using
the AudioTrack interface,

1274
00:58:04,567 --> 00:58:07,467
there's a volume control
interface on it.

1275
00:58:07,467 --> 00:58:10,868
man: My question is,

1276
00:58:10,868 --> 00:58:14,400
for the testing sites,
how--

1277
00:58:14,400 --> 00:58:18,667
does Google have a plan
to release a certain application

1278
00:58:18,667 --> 00:58:22,701
or testing program
to verify MediaPlayer

1279
00:58:22,701 --> 00:58:24,434
and other media middleware
like this?

1280
00:58:24,434 --> 00:58:25,567
Sparks: Right.

1281
00:58:25,567 --> 00:58:28,367
man: 3D and everything else?

1282
00:58:28,367 --> 00:58:31,701
Sparks:
So we haven't announced

1283
00:58:31,701 --> 00:58:32,968
what we're doing there yet.

1284
00:58:32,968 --> 00:58:34,434
I can't talk about it.

1285
00:58:34,434 --> 00:58:37,100
But it's definitely something
we're thinking about.

1286
00:58:37,100 --> 00:58:38,300
man: Okay.

1287
00:58:38,300 --> 00:58:41,133
Another question is about
the concurrency

1288
00:58:41,133 --> 00:58:43,801
there for the mobile devices.

1289
00:58:43,801 --> 00:58:45,467
The resource is very limited.

1290
00:58:45,467 --> 00:58:48,067
So for example,
the service you mentioned.

1291
00:58:48,067 --> 00:58:52,868
The memory
is very limited.

1292
00:58:52,868 --> 00:58:56,801
So how do we handle any--

1293
00:58:56,801 --> 00:58:58,534
or maybe you have
any experience--

1294
00:58:58,534 --> 00:59:00,801
handle the 3D surface

1295
00:59:00,801 --> 00:59:03,501
and also the multimedia surface

1296
00:59:03,501 --> 00:59:06,167
and put together
a raw atom surface

1297
00:59:06,167 --> 00:59:07,868
or something like that?

1298
00:59:07,868 --> 00:59:10,901
Sparks: So when you say "3D,"
you're talking about--

1299
00:59:10,901 --> 00:59:14,400
man: Like OpenGL,
because you do the overlay

1300
00:59:14,400 --> 00:59:15,901
and you use the overlay
and you--

1301
00:59:15,901 --> 00:59:18,334
Sparks: Yeah, I'm--
I'm not that up on it.

1302
00:59:18,334 --> 00:59:19,634
I'm not a graphics guy.

1303
00:59:19,634 --> 00:59:21,200
I'm really an audio guy.

1304
00:59:21,200 --> 00:59:23,901
But I actually manage the team
that does the 3D stuff.

1305
00:59:23,901 --> 00:59:25,701
So I'm kind of familiar
with it.

1306
00:59:25,701 --> 00:59:28,033
There's definitely
limited texture memory

1307
00:59:28,033 --> 00:59:30,167
that's available--that's
probably the most critical thing

1308
00:59:30,167 --> 00:59:32,701
that we're running into--
but obviously,

1309
00:59:32,701 --> 00:59:34,000
you know, that--

1310
00:59:34,000 --> 00:59:36,434
we're going to figure out
how to share that.

1311
00:59:36,434 --> 00:59:39,300
And so--

1312
00:59:39,300 --> 00:59:40,934
I don't have a good answer
for you,

1313
00:59:40,934 --> 00:59:42,501
but we're aware of the problem.

1314
00:59:42,501 --> 00:59:44,133
man: Okay.
Yeah.

1315
00:59:44,133 --> 00:59:46,801
Just one more question
is do you have any plan

1316
00:59:46,801 --> 00:59:49,000
to move OpenGL 2.0
for the Android?

1317
00:59:49,000 --> 00:59:50,901
Sparks: Yes. If you--

1318
00:59:50,901 --> 00:59:52,334
man: Do you have a time frame?

1319
00:59:52,334 --> 00:59:53,734
Sparks: Yeah,
if you're following

1320
00:59:53,734 --> 00:59:56,267
the master source tree
right now,

1321
00:59:56,267 --> 00:59:58,734
you'll start to see changes
come out for--

1322
00:59:58,734 --> 01:00:02,100
we're--we're marrying 2D
and 3D space.

1323
01:00:02,100 --> 01:00:07,200
So the 2D framework will be
running as an OpenGL context,

1324
01:00:07,200 --> 01:00:09,734
which will allow you, then,
to, you know--

1325
01:00:09,734 --> 01:00:12,167
ES 2.0 context.

1326
01:00:12,167 --> 01:00:14,667
So you'll be able to share
between the 3D app

1327
01:00:14,667 --> 01:00:15,734
and the 2D app.

1328
01:00:15,734 --> 01:00:17,067
Currently,
if you have a 3D app,

1329
01:00:17,067 --> 01:00:18,667
it takes over the frame buffer

1330
01:00:18,667 --> 01:00:20,200
and nothing else can run.

1331
01:00:20,200 --> 01:00:21,868
You'll actually be able
to run 3D

1332
01:00:21,868 --> 01:00:23,334
inside the 2D framework.

1333
01:00:23,334 --> 01:00:24,901
man: Okay, thank you.

1334
01:00:24,901 --> 01:00:26,667
man: I think this question
is sort of related.

1335
01:00:26,667 --> 01:00:29,567
I was wondering how would you
take, like, the--

1336
01:00:29,567 --> 01:00:31,100
the surface that you use
to play back video

1337
01:00:31,100 --> 01:00:33,334
and use it as a texture,
like in OpenGL?

1338
01:00:33,334 --> 01:00:35,033
Sparks: That's coming, yeah.

1339
01:00:35,033 --> 01:00:37,968
Yeah, that--so you actually
would be able to map

1340
01:00:37,968 --> 01:00:39,934
that texture onto a 3D--

1341
01:00:39,934 --> 01:00:42,000
man: Is there any way
you can do that today

1342
01:00:42,000 --> 01:00:43,167
with the current APIs?

1343
01:00:43,167 --> 01:00:44,334
Sparks: Nope.

1344
01:00:44,334 --> 01:00:45,901
Yeah, there's no access
to the--

1345
01:00:45,901 --> 01:00:48,767
to the video after it leaves
the media server.

1346
01:00:48,767 --> 01:00:50,033
man: And no time frame

1347
01:00:50,033 --> 01:00:51,534
as far as
when there'll be

1348
01:00:51,534 --> 01:00:53,567
some type of communication
as far as

1349
01:00:53,567 --> 01:00:55,501
how to about doing that
in your applications?

1350
01:00:55,501 --> 01:00:58,067
Sparks: Well, it's--
so it's in our--

1351
01:00:58,067 --> 01:00:59,901
what we call
our Eclair release.

1352
01:00:59,901 --> 01:01:01,601
So that's master today.

1353
01:01:01,601 --> 01:01:04,534
man: Okay.
Okay, thank you.

1354
01:01:04,534 --> 01:01:07,434
Sparks: I think--
are we out of time?

1355
01:01:07,434 --> 01:01:08,834
woman: [indistinct]

1356
01:01:08,834 --> 01:01:11,300
Sparks: Okay.

1357
01:01:11,300 --> 01:01:13,734
woman: Hi, do you have
any performance metrics

1358
01:01:13,734 --> 01:01:16,267
as to what are
the performance numbers

1359
01:01:16,267 --> 01:01:21,701
with the certain playback
of audio and video to share,

1360
01:01:21,701 --> 01:01:23,467
or any memory footprints
available

1361
01:01:23,467 --> 01:01:25,000
that we can look up, maybe?

1362
01:01:25,000 --> 01:01:26,434
Sparks: Not today.

1363
01:01:26,434 --> 01:01:29,067
It's actually part of some
of the work we're doing

1364
01:01:29,067 --> 01:01:31,133
that somebody was asking about
earlier.

1365
01:01:31,133 --> 01:01:32,701
That I can't talk about yet.
But yeah.

1366
01:01:32,701 --> 01:01:35,267
There's definitely some--
some plans to do metrics

1367
01:01:35,267 --> 01:01:38,767
and to have baselines
that you can depend on.

1368
01:01:38,767 --> 01:01:41,067
woman: And then the second
question that I have

1369
01:01:41,067 --> 01:01:44,133
is that do you have
any additional formats

1370
01:01:44,133 --> 01:01:47,067
that are lined up
or are in the roadmap?

1371
01:01:47,067 --> 01:01:50,834
Like VC-1 and additional
audio formats?

1372
01:01:50,834 --> 01:01:54,501
Sparks: No, not--
not officially, no.

1373
01:01:54,501 --> 01:01:56,100
woman: Okay.

1374
01:01:56,100 --> 01:01:59,200
woman: Hi, this is back
to the SoundPool question.

1375
01:01:59,200 --> 01:02:02,467
Is it possible
to calculate latency

1376
01:02:02,467 --> 01:02:03,868
or at least know, like,

1377
01:02:03,868 --> 01:02:06,601
when the song actually went
to the sound card

1378
01:02:06,601 --> 01:02:08,934
so I could at least know
when it actually did play--

1379
01:02:08,934 --> 01:02:11,067
if there's any sort of callback
or anything?

1380
01:02:11,067 --> 01:02:14,968
Sparks: So you can get
a playback complete callback

1381
01:02:14,968 --> 01:02:20,767
that tells you
when it left the player engine.

1382
01:02:20,767 --> 01:02:22,934
There's some additional latency
in the hardware

1383
01:02:22,934 --> 01:02:26,367
that we...we don't have
complete visibility into,

1384
01:02:26,367 --> 01:02:27,434
but it's reported back

1385
01:02:27,434 --> 01:02:29,334
through the audio track
interface,

1386
01:02:29,334 --> 01:02:31,767
theoretically,
if it's done correctly.

1387
01:02:31,767 --> 01:02:35,234
So at
the MediaPlayer level, no.

1388
01:02:35,234 --> 01:02:37,033
At the AudioTrack level, yes.

1389
01:02:37,033 --> 01:02:38,501
If that's...makes any sense.

1390
01:02:38,501 --> 01:02:40,033
woman: Okay, so I can at least
get that,

1391
01:02:40,033 --> 01:02:42,200
even if I can't actually
calculate latency

1392
01:02:42,200 --> 01:02:43,534
for every single call?

1393
01:02:43,534 --> 01:02:44,601
Sparks: Right, right.

1394
01:02:44,601 --> 01:02:46,000
woman: Okay. Thank you.

1395
01:02:46,000 --> 01:02:47,501
Sparks: Uh-huh.

1396
01:02:47,501 --> 01:02:49,367
man: Yeah, this is a question

1397
01:02:49,367 --> 01:02:51,968
about the samples processing.

1398
01:02:51,968 --> 01:02:55,234
You partially touched
upon that.

1399
01:02:55,234 --> 01:02:57,300
But in your architecture
diagram,

1400
01:02:57,300 --> 01:03:01,033
where do you think
the sound processing effect

1401
01:03:01,033 --> 01:03:02,767
really has to be placed?

1402
01:03:02,767 --> 01:03:05,100
For example, it could be
an equalizer

1403
01:03:05,100 --> 01:03:08,400
or different kind
of audio post processing

1404
01:03:08,400 --> 01:03:09,667
that needs to be done.

1405
01:03:09,667 --> 01:03:13,667
Because in the current
Cupcake version, 1.5,

1406
01:03:13,667 --> 01:03:16,200
I do not see a placeholder

1407
01:03:16,200 --> 01:03:18,300
or any implementation
of that sort.

1408
01:03:18,300 --> 01:03:21,167
Sparks: So one of the things
we're in the process of doing

1409
01:03:21,167 --> 01:03:24,467
is we're--
we're looking at OpenAL--

1410
01:03:24,467 --> 01:03:26,767
Have I got that right?
OpenAL ES?

1411
01:03:26,767 --> 01:03:31,701
As the, um--possibly the--
an abstraction for that.

1412
01:03:31,701 --> 01:03:33,534
But it definitely
is something you want to do

1413
01:03:33,534 --> 01:03:36,801
on an application-by-application
basis.

1414
01:03:36,801 --> 01:03:38,167
For example,
you don't want to have

1415
01:03:38,167 --> 01:03:42,467
effects running on, you know,
a notification if...

1416
01:03:42,467 --> 01:03:44,634
The--you--you wouldn't want
the application

1417
01:03:44,634 --> 01:03:46,167
in the foreground
and forcing something

1418
01:03:46,167 --> 01:03:48,801
on some other application
that's running in background.

1419
01:03:48,801 --> 01:03:51,100
So that's kind of the direction
we're headed with that.

1420
01:03:51,100 --> 01:03:53,534
man: What's the current
recommendation?

1421
01:03:53,534 --> 01:03:56,067
How do you want the developers
to address?

1422
01:03:56,067 --> 01:03:57,868
Sparks: Well, the--
since there isn't any way,

1423
01:03:57,868 --> 01:03:59,901
there's no recommendation.

1424
01:03:59,901 --> 01:04:01,701
I mean,
if you were doing native code,

1425
01:04:01,701 --> 01:04:03,133
it's kind of up to you.

1426
01:04:03,133 --> 01:04:06,767
But our recommendation would be
if you're, you know,

1427
01:04:06,767 --> 01:04:08,534
doing some special version
of the code,

1428
01:04:08,534 --> 01:04:10,434
you would probably want
to insert it

1429
01:04:10,434 --> 01:04:12,634
at the application level
and not sitting

1430
01:04:12,634 --> 01:04:14,300
at the bottom
of the Audio Flinger stack.

1431
01:04:14,300 --> 01:04:16,100
man: Okay, thanks.

1432
01:04:16,100 --> 01:04:19,634
woman: Is it better to get
the system service once

1433
01:04:19,634 --> 01:04:22,400
and share it across activities
in an application,

1434
01:04:22,400 --> 01:04:27,033
or let each activity
fetch the service?

1435
01:04:27,033 --> 01:04:29,567
Sparks: I mean, there's
a certain amount of overhead,

1436
01:04:29,567 --> 01:04:31,701
'cause it's a binder call
to do it.

1437
01:04:31,701 --> 01:04:33,968
So if you know
you're going to use it,

1438
01:04:33,968 --> 01:04:35,467
I would just keep it around.

1439
01:04:35,467 --> 01:04:38,000
I mean, it's just a--
a Java object reference.

1440
01:04:38,000 --> 01:04:41,734
So it's pretty cheap
to hold around.

1441
01:04:41,734 --> 01:04:43,934
man: Is there any way
to listen to music

1442
01:04:43,934 --> 01:04:46,334
on a mono Bluetooth?

1443
01:04:46,334 --> 01:04:48,901
Sparks: Ah, on a SCO?

1444
01:04:48,901 --> 01:04:50,868
Yeah, no.
[chuckles]

1445
01:04:50,868 --> 01:04:53,167
The reason
we haven't done that

1446
01:04:53,167 --> 01:04:56,033
is the audio quality
is really pretty poor.

1447
01:04:56,033 --> 01:04:58,133
I mean, it's designed for--
for call audio.

1448
01:04:58,133 --> 01:05:00,234
So the experience isn't going
to be very good.

1449
01:05:00,234 --> 01:05:03,000
Theoretically, you know,
it's possible.

1450
01:05:03,000 --> 01:05:06,067
We just don't think
it's a good idea.

1451
01:05:06,067 --> 01:05:07,634
[chuckling]

1452
01:05:07,634 --> 01:05:10,934
man: If you want to record
for a long period of time,

1453
01:05:10,934 --> 01:05:12,400
you know, like a half-hour,

1454
01:05:12,400 --> 01:05:14,400
can you frequency scale
the processor

1455
01:05:14,400 --> 01:05:16,734
or put it to sleep, or...

1456
01:05:16,734 --> 01:05:19,133
Sparks: It--well,
that happens automatically.

1457
01:05:19,133 --> 01:05:23,133
I mean, it's--
it's actually going to sleep

1458
01:05:23,133 --> 01:05:25,067
and waking up all the time.

1459
01:05:25,067 --> 01:05:27,701
So it's just depending
on what's--

1460
01:05:27,701 --> 01:05:30,000
man: But if you're doing, like,
a raw 8k sample rate,

1461
01:05:30,000 --> 01:05:33,167
how big a buffer can you have,
and then will it sleep in--

1462
01:05:33,167 --> 01:05:35,667
while that buffer's filling?

1463
01:05:35,667 --> 01:05:38,100
Sparks: So the--the size
of those buffers

1464
01:05:38,100 --> 01:05:40,300
is defined
in the media recorder service.

1465
01:05:40,300 --> 01:05:42,567
And I think they're...

1466
01:05:42,567 --> 01:05:46,734
I want to say they're like 2--
2k at...

1467
01:05:46,734 --> 01:05:47,934
whatever the output rate is.

1468
01:05:47,934 --> 01:05:49,200
So they're pretty good size.

1469
01:05:49,200 --> 01:05:51,367
I mean, it's like
a half a second of audio.

1470
01:05:51,367 --> 01:05:52,834
So the processor,
theoretically,

1471
01:05:52,834 --> 01:05:55,200
would be asleep
for quite some time.

1472
01:05:55,200 --> 01:05:56,868
man: So is that handled
by the codec,

1473
01:05:56,868 --> 01:05:59,000
or is it handled by--
I mean, the DSP on a codec?

1474
01:05:59,000 --> 01:06:00,067
Or is it handled by--

1475
01:06:00,067 --> 01:06:01,534
Sparks: So the...
the process

1476
01:06:01,534 --> 01:06:05,133
is going to wake up
when there's audio available.

1477
01:06:05,133 --> 01:06:07,400
It's going to...

1478
01:06:07,400 --> 01:06:11,133
you know, route it over
to the AMR encoder.

1479
01:06:11,133 --> 01:06:12,767
It's going to do its thing.

1480
01:06:12,767 --> 01:06:15,334
Spit out a bunch of bits
that'll go to the file composer

1481
01:06:15,334 --> 01:06:16,667
to be written out.

1482
01:06:16,667 --> 01:06:17,834
And then theoretically,

1483
01:06:17,834 --> 01:06:18,934
it's gonna go back
to sleep again.

1484
01:06:18,934 --> 01:06:20,200
man: No, I mean
on the recorder.

1485
01:06:20,200 --> 01:06:22,901
If you're recording the audio.

1486
01:06:22,901 --> 01:06:24,267
If you're off the microphone.

1487
01:06:24,267 --> 01:06:25,834
Sparks: I'm sorry?

1488
01:06:25,834 --> 01:06:27,901
man: If you're recording
raw audio off the microphone.

1489
01:06:27,901 --> 01:06:29,234
Sparks: Yeah.

1490
01:06:29,234 --> 01:06:31,701
Oh, oh, are you talking about
using the AudioTrack

1491
01:06:31,701 --> 01:06:33,000
or AudioRecord interface?

1492
01:06:33,000 --> 01:06:34,501
man: The AudioRecord interface.
ADPCM.

1493
01:06:34,501 --> 01:06:36,000
Sparks: Yeah, that's...

1494
01:06:36,000 --> 01:06:37,467
So it's pretty much
the same thing.

1495
01:06:37,467 --> 01:06:39,834
I mean, if you define
your buffer size large enough,

1496
01:06:39,834 --> 01:06:42,400
whatever that buffer size is,
that's the buffer size

1497
01:06:42,400 --> 01:06:44,701
it's going to use
at the lower level.

1498
01:06:44,701 --> 01:06:47,634
So it'll be asleep
for that amount of time.

1499
01:06:47,634 --> 01:06:49,434
man: And the DSP will be
the one filling the buffer?

1500
01:06:49,434 --> 01:06:51,501
Sparks: Yeah, yeah.
The DSP fills the buffer.

1501
01:06:51,501 --> 01:06:53,400
man: All right, thanks.

1502
01:06:53,400 --> 01:06:54,701
man: One last question.

1503
01:06:54,701 --> 01:06:56,534
From a platform perspective,

1504
01:06:56,534 --> 01:06:58,567
would you be able to state
a minimum requirement

1505
01:06:58,567 --> 01:07:01,067
on OpenGL performance?

1506
01:07:01,067 --> 01:07:03,067
Sparks: I'm not ready
to say that today.

1507
01:07:03,067 --> 01:07:05,267
But...

1508
01:07:05,267 --> 01:07:07,033
at some point we'll--

1509
01:07:07,033 --> 01:07:08,467
we'll be able
to tell you about that.

1510
01:07:08,467 --> 01:07:10,634
man: Okay, thanks.
Sparks: Uh-huh.

1511
01:07:10,634 --> 01:07:12,701
Guess that's my time.
Thanks, everyone.

1512
01:07:12,701 --> 01:07:15,634
[applause]

