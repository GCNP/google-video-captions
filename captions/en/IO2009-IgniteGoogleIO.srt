1
00:00:01,100 --> 00:00:01,534
- Forrest: Uh, just
before we get started,

2
00:00:01,534 --> 00:00:04,267
who's been to an Ignite before?
All right. 

3
00:00:04,267 --> 00:00:05,567
Well, for those of
you who haven't,

4
00:00:05,567 --> 00:00:08,434
it'll be a lot of fun.

5
00:00:08,434 --> 00:00:10,667
So, welcome to Ignite.

6
00:00:10,667 --> 00:00:15,801
It's a fun, normally beer-
filled, geek-filled night.

7
00:00:15,801 --> 00:00:18,400
Google invited me here
today to run one

8
00:00:18,400 --> 00:00:20,100
and we pulled in
a combination of

9
00:00:20,100 --> 00:00:24,801
Googlers, attendees, and
cool people who've done

10
00:00:24,801 --> 00:00:26,667
great Ignite talks
in the past.

11
00:00:26,667 --> 00:00:29,801
Uh, I'm Brady Forrest,
I write for O'Reilly,

12
00:00:29,801 --> 00:00:32,834
I do a bunch of conferences,
and I spend a lot of my time

13
00:00:32,834 --> 00:00:36,934
doing Ignites, which, in case
you wouldn't have guessed it,

14
00:00:36,934 --> 00:00:38,367
I love my job.

15
00:00:38,367 --> 00:00:42,734
Um, and I also--I started this
because geeks like to share,

16
00:00:42,734 --> 00:00:44,767
and geeks have a
lot of passions,

17
00:00:44,767 --> 00:00:47,634
they don't necessarily want to
take a whole weekend camp

18
00:00:47,634 --> 00:00:49,400
to explain it and
talk about it.

19
00:00:49,400 --> 00:00:51,067
They want to share
it with their friends

20
00:00:51,067 --> 00:00:54,367
but a long, 45-minute talk
is just a little too long.

21
00:00:54,367 --> 00:00:55,834
And geeks like beer.

22
00:00:55,834 --> 00:00:57,868
So, when you combine the
two things together,

23
00:00:57,868 --> 00:01:00,701
a fun, social night
out at a bar,

24
00:01:00,701 --> 00:01:03,300
with your passions,
and short talks,

25
00:01:03,300 --> 00:01:07,033
and your non-geek but
interested-in-Twitter friends,

26
00:01:07,033 --> 00:01:09,601
you get something like Ignite.

27
00:01:09,601 --> 00:01:13,000
And the way we do that is
we have this fun format,

28
00:01:13,000 --> 00:01:16,300
and it's not showing. Sorry.

29
00:01:17,834 --> 00:01:19,200
Ha.

30
00:01:23,534 --> 00:01:29,200
So this is what you just missed.

31
00:01:29,200 --> 00:01:30,701
And here's where we are.

32
00:01:30,701 --> 00:01:34,200
And we use this format to make
all the content interesting.

33
00:01:34,200 --> 00:01:35,601
Each speaker gets
just five minutes,

34
00:01:35,601 --> 00:01:38,767
20 slides that
auto-advance after 15 seconds.

35
00:01:38,767 --> 00:01:41,300
The speakers that get up here
have no control over the slides.

36
00:01:41,300 --> 00:01:43,133
What I just did is cheating.

37
00:01:43,133 --> 00:01:46,534
Um, but I feel like I had a good
reason, my own incompetence.

38
00:01:46,534 --> 00:01:49,267
And what you're going to see
today are nine speakers

39
00:01:49,267 --> 00:01:51,434
who are going to take you
through a variety of topics.

40
00:01:51,434 --> 00:01:53,734
Uh, speakers who are
here today are

41
00:01:53,734 --> 00:01:55,868
Pamela Fox from Google,
Kevin Marks from Google,

42
00:01:55,868 --> 00:02:00,167
Leo Dirac, Kathy Sierra and
Tim Ferriss, Mike Driscoll,

43
00:02:00,167 --> 00:02:03,868
and you may have an Ignite in
your city and you don't know it.

44
00:02:03,868 --> 00:02:05,701
And, if not, you
should go start one.

45
00:02:05,701 --> 00:02:07,400
They're very easy,
as you'll see.

46
00:02:07,400 --> 00:02:08,767
You just ask your
friends to give you

47
00:02:08,767 --> 00:02:10,200
20 slide presentations.

48
00:02:10,200 --> 00:02:11,367
You just set them to

49
00:02:11,367 --> 00:02:14,534
"All Auto-Transition after 15
seconds,"

50
00:02:14,534 --> 00:02:16,367
and then you go to a bar,

51
00:02:16,367 --> 00:02:19,067
and you can be like
any of these towns.

52
00:02:19,067 --> 00:02:22,801
At the last Ignite Seattle,
we had almost 600 people there.

53
00:02:22,801 --> 00:02:24,267
A recent one here
in San Francisco,

54
00:02:24,267 --> 00:02:26,734
we had 800.
It's a lot of fun.

55
00:02:26,734 --> 00:02:30,534
We put the videos up online
and it's a great way to

56
00:02:30,534 --> 00:02:33,334
share your passions,
get your name out there.

57
00:02:33,334 --> 00:02:38,067
If you want to see more of this,
check out "The Ignite Show."

58
00:02:38,067 --> 00:02:41,901
And, now, without much more ado,
I'd like to welcome up our first

59
00:02:41,901 --> 00:02:45,901
speaker, here from Google, but
an Ignite Seattle veteran,

60
00:02:45,901 --> 00:02:49,133
Leo Dirac. Please
give it up for Leo.

61
00:02:49,133 --> 00:02:51,434
- Dirac: Thanks, Brady.

62
00:02:51,434 --> 00:02:53,534
So, I'm Leo Dirac--
wow, this is loud--

63
00:02:53,534 --> 00:02:55,734
and, uh, I'm here to
talk to you about 

64
00:02:55,734 --> 00:02:58,167
saving the world with
The Better Alarm Clock.

65
00:02:58,167 --> 00:02:59,534
I'm going to give you
a couple of strategies

66
00:02:59,534 --> 00:03:01,501
for waking up in the
morning; the geek strategy

67
00:03:01,501 --> 00:03:03,567
and the hippie strategy.

68
00:03:03,567 --> 00:03:06,501
But, uh, I'd like to start out
by taking an audience poll.

69
00:03:06,501 --> 00:03:09,701
So, raise your hands if you
regularly use the Snooze button

70
00:03:09,701 --> 00:03:11,167
on your alarm clock.

71
00:03:11,167 --> 00:03:14,267
All right, now keep them up
if you regularly snooze 

72
00:03:14,267 --> 00:03:16,434
for more than 15 minutes.

73
00:03:16,434 --> 00:03:19,300
Half an hour? An hour?

74
00:03:19,300 --> 00:03:21,534
Yeah, it's okay,
I do it too, sometimes.

75
00:03:21,534 --> 00:03:24,968
The thing is, beds are comfy,
and they're warm, and

76
00:03:24,968 --> 00:03:26,934
they often have snuggly
things in them.

77
00:03:26,934 --> 00:03:29,868
And the alarm clock is a stupid
little robot that just goes,

78
00:03:29,868 --> 00:03:35,067
"Beep. Beep. Time to wake up and
face the cold, harsh reality

79
00:03:35,067 --> 00:03:38,067
of your life. Beep. Beep."

80
00:03:38,067 --> 00:03:40,167
So, a more effective
alarm clock would,

81
00:03:40,167 --> 00:03:42,067
say, make the bed uncomfortable.

82
00:03:42,067 --> 00:03:46,667
Suddenly. Say by, uh, pumping
cold fluid into the mattress,

83
00:03:46,667 --> 00:03:49,467
or making it not
horizontal anymore.

84
00:03:49,467 --> 00:03:52,767
But, you know, that's maybe not
the funnest way to deal with it.

85
00:03:52,767 --> 00:03:54,834
What if, what if
getting up was really fun?

86
00:03:54,834 --> 00:03:57,901
What if there's something
totally awesome you couldn't do

87
00:03:57,901 --> 00:03:59,868
lying down with
your eyes closed?

88
00:03:59,868 --> 00:04:01,968
Well, then you'd want
to get out of bed.

89
00:04:01,968 --> 00:04:03,167
So, what would that
be like, hmm?

90
00:04:03,167 --> 00:04:05,300
Well, I've got
a couple of ideas.

91
00:04:05,300 --> 00:04:08,200
Like, um, how about
snowboarding?

92
00:04:08,200 --> 00:04:11,467
Or, what if you were a
superhero, and you had to get

93
00:04:11,467 --> 00:04:14,167
out of bed every day to prevent
the end of the world?

94
00:04:14,167 --> 00:04:16,267
That would keep you from hitting
the snooze, wouldn't it?

95
00:04:16,267 --> 00:04:19,267
But, you know, I think each and
every one of you could be

96
00:04:19,267 --> 00:04:22,067
that superhero, because
our world is facing

97
00:04:22,067 --> 00:04:24,534
very real threats every day.

98
00:04:24,534 --> 00:04:26,868
Now, nuclear war, maybe not
as dire as it used to be,

99
00:04:26,868 --> 00:04:28,868
but, what about bio-terrorism?

100
00:04:28,868 --> 00:04:30,667
What if there was a
bio-engineered super virus

101
00:04:30,667 --> 00:04:33,667
that turned all humans into
flesh-eating zombies?

102
00:04:33,667 --> 00:04:35,934
Or, what about cataclysmic
climate change,

103
00:04:35,934 --> 00:04:37,300
or, gray goo?

104
00:04:37,300 --> 00:04:40,267
Or, you know, if we keep
going the way we have been,

105
00:04:40,267 --> 00:04:42,067
eventually, this planet isn't
going to be able

106
00:04:42,067 --> 00:04:44,534
to support human life at all.

107
00:04:44,534 --> 00:04:46,367
And how long do you think
we have before that?

108
00:04:46,367 --> 00:04:48,701
Do you think we'll
make it 100 years?

109
00:04:48,701 --> 00:04:51,467
A thousand?
I mean, I think, eventually,

110
00:04:51,467 --> 00:04:53,434
something's
going to wipe us out.

111
00:04:53,434 --> 00:04:57,133
And, uh, I mean, maybe it's not
even worth trying to save

112
00:04:57,133 --> 00:04:58,567
the human race at all.

113
00:04:58,567 --> 00:05:00,934
Maybe we should try to save
something more important.

114
00:05:00,934 --> 00:05:03,801
Well, what's more
important than people?

115
00:05:03,801 --> 00:05:06,868
That's a good question.
Let's put on our P.M. hat

116
00:05:06,868 --> 00:05:09,033
for a minute,
and go into triage mode.

117
00:05:09,033 --> 00:05:12,133
If you ask me,
the Pri 1 is complex thought.

118
00:05:12,133 --> 00:05:15,868
This is ideas and emotions.
Logic. Art.

119
00:05:15,868 --> 00:05:19,434
All of these things are
way more important than

120
00:05:19,434 --> 00:05:22,667
things like, uh,
eh, you know,

121
00:05:22,667 --> 00:05:28,133
birds or plants
or human beings.

122
00:05:28,133 --> 00:05:31,701
Because, so, okay, how do you
have complex thought without

123
00:05:31,701 --> 00:05:33,067
a human brain?

124
00:05:33,067 --> 00:05:35,701
Well, that's a--
that's a good question.

125
00:05:35,701 --> 00:05:37,601
What else can support
complex thoughts?

126
00:05:37,601 --> 00:05:40,567
Well, sounds kind of like an
engineering problem to me.

127
00:05:40,567 --> 00:05:42,400
And a really fun
challenge at that.

128
00:05:42,400 --> 00:05:44,834
What if we made robots that
were really powerful

129
00:05:44,834 --> 00:05:48,467
and could support human emotions
and live lives as rich as ours?

130
00:05:48,467 --> 00:05:51,601
Well, that'd be one way to do
it, and we're all geeks,

131
00:05:51,601 --> 00:05:53,234
let's get to it.
What do you say?

132
00:05:53,234 --> 00:05:56,667
Now, I know, some people are
going to miss having bodies.

133
00:05:56,667 --> 00:06:00,701
They're going to miss
food, watching sunsets,

134
00:06:00,701 --> 00:06:02,567
but you know, people get
nostalgic about all

135
00:06:02,567 --> 00:06:04,234
sorts of stupid stuff already.

136
00:06:04,234 --> 00:06:08,367
Like, "Boy, wasn't it nice when
we all used to huddle around the

137
00:06:08,367 --> 00:06:12,601
campfire to keep warm while
hiding from the saber-toothed

138
00:06:12,601 --> 00:06:16,033
tigers in our caves?" I mean,
come on. Let's get over it.

139
00:06:16,033 --> 00:06:17,567
It's time for us to move on.

140
00:06:17,567 --> 00:06:20,667
I say we cast off these weak,
fragile human bodies,

141
00:06:20,667 --> 00:06:22,367
and replace them with something
better.

142
00:06:22,367 --> 00:06:24,467
Let's let the robots take over.

143
00:06:24,467 --> 00:06:27,133
Okay, so here's what you can do
to help.

144
00:06:27,133 --> 00:06:29,634
First, pick a job that's
going to get you

145
00:06:29,634 --> 00:06:31,634
 out of bed every Monday
morning.

146
00:06:31,634 --> 00:06:33,501
Do something that's really
important for the world,

147
00:06:33,501 --> 00:06:35,567
something that's going to
help the robots take over.

148
00:06:35,567 --> 00:06:37,567
There's two ways to do
this; you can be a geek,

149
00:06:37,567 --> 00:06:38,968
or you can be a hippie.

150
00:06:38,968 --> 00:06:42,634
So, the geek way means do
science. Build technology.

151
00:06:42,634 --> 00:06:45,300
Help people communicate.
Help people solve

152
00:06:45,300 --> 00:06:46,934
complex problems together.

153
00:06:46,934 --> 00:06:48,767
Because, as the
world gets smarter

154
00:06:48,767 --> 00:06:50,968
at solving these problems,
we're getting closer to having

155
00:06:50,968 --> 00:06:54,534
the robots that we're gonna need
to get through this.

156
00:06:54,534 --> 00:06:57,267
The other thing,
we gotta buy more time.

157
00:06:57,267 --> 00:06:59,200
And that means being a hippy. 

158
00:06:59,200 --> 00:07:01,067
And you know what this
is; this is recycling,

159
00:07:01,067 --> 00:07:03,834
this is composting, this is
peace in the Middle East.

160
00:07:03,834 --> 00:07:06,200
All of the things the hippies
have been preaching for decades

161
00:07:06,200 --> 00:07:08,467
are actually really important.

162
00:07:08,467 --> 00:07:11,267
Because, the humans might
be doomed,

163
00:07:11,267 --> 00:07:13,968
but we've got to keep them
around for long enough

164
00:07:13,968 --> 00:07:15,834
so they can build us V2--

165
00:07:15,834 --> 00:07:19,834
ah, I mean, we have to keep
ourselves around long enough

166
00:07:19,834 --> 00:07:23,200
to build our own replacements,
because I'm a human too.

167
00:07:23,200 --> 00:07:26,467
And, uh, this is what gets
me up in the morning.

168
00:07:26,467 --> 00:07:31,667
Because, I don't know, uh, maybe
the humans will make it forever,

169
00:07:31,667 --> 00:07:34,133
but I'm not really willing
to take that risk.

170
00:07:34,133 --> 00:07:37,968
I think counting on that is
reckless and immoral.

171
00:07:37,968 --> 00:07:40,601
Because everything that we know
and care about in this world

172
00:07:40,601 --> 00:07:43,501
that's important is in
danger of being wiped out.

173
00:07:43,501 --> 00:07:47,234
And it's only by working
together, as geeks and hippies,

174
00:07:47,234 --> 00:07:49,334
that we can save the world.

175
00:07:49,334 --> 00:07:51,734
So, thank you.

176
00:07:57,067 --> 00:07:59,834
- Forrest: Thank you very much,
Leo, for, uh, telling us about

177
00:07:59,834 --> 00:08:01,534
Google's new product
Google Body.

178
00:08:01,534 --> 00:08:03,634
[laughs]

179
00:08:03,634 --> 00:08:06,167
Uh, and now we're going to move
to open source,

180
00:08:06,167 --> 00:08:07,834
because we want to
know what to save,

181
00:08:07,834 --> 00:08:09,100
and we'll need to
calculate that.

182
00:08:09,100 --> 00:08:11,133
Please welcome up Mike Driscoll,
telling us about R.

183
00:08:11,133 --> 00:08:18,367
- Driscoll: Thanks, Brady.

184
00:08:18,367 --> 00:08:22,868
So, uh, we are now living in
an age of big data.

185
00:08:22,868 --> 00:08:27,234
Every cash register, every cell
phone, uh,

186
00:08:27,234 --> 00:08:30,634
can I get some extra time?

187
00:08:30,634 --> 00:08:33,067
Uh, every car, uh, every
computer is streaming

188
00:08:33,067 --> 00:08:34,667
billions of data points.

189
00:08:34,667 --> 00:08:37,734
And, uh, the professor Joe
Hellerstein has called this the

190
00:08:37,734 --> 00:08:41,734
Industrial Age of Data. The
Industrial Revolution of Data.

191
00:08:41,734 --> 00:08:44,467
And, that's great,
that's exciting.

192
00:08:44,467 --> 00:08:46,601
You know, big data has become
something that a lot of people

193
00:08:46,601 --> 00:08:49,434
are talking about. Um,
and it's not just about

194
00:08:49,434 --> 00:08:53,033
gathering this data. Um, you
know, data's become interesting.

195
00:08:53,033 --> 00:08:56,734
In fact, data's become something
that's not just interesting,

196
00:08:56,734 --> 00:08:59,200
um, it's even become
something that's sexy.

197
00:08:59,200 --> 00:09:02,200
In fact, Hal Varian has said
that

198
00:09:02,200 --> 00:09:06,167
"Statisticians are the sexy job
in the next decade."

199
00:09:06,167 --> 00:09:09,234
And you might be wondering with
all this data, um,

200
00:09:09,234 --> 00:09:11,868
how can I learn how to
become sexy too?

201
00:09:11,868 --> 00:09:15,033
Uh, what can I do to
make pretty charts?

202
00:09:15,033 --> 00:09:17,601
Um, well, there's a tool
for you. It's called R.

203
00:09:17,601 --> 00:09:20,133
And it was invented by
these two guys, um,

204
00:09:20,133 --> 00:09:23,400
both whose names
begin with R, and

205
00:09:23,400 --> 00:09:25,534
R is different. It's an open
source tool for statistics

206
00:09:25,534 --> 00:09:28,467
and data analysis. It was
developed by statisticians

207
00:09:28,467 --> 00:09:33,234
for statisticians, and, what
it's great at is three things,

208
00:09:33,234 --> 00:09:37,501
really, um, data manipulation,
statistical analysis,

209
00:09:37,501 --> 00:09:39,100
and visualization.

210
00:09:39,100 --> 00:09:42,834
And I like to call these things
data munging, data modeling.

211
00:09:42,834 --> 00:09:46,334
Um, these are really things that
belong together.

212
00:09:46,334 --> 00:09:50,767
And we use these tools, and we
use this to build hypotheses

213
00:09:50,767 --> 00:09:53,367
about the world. This is one
such hypothesis.

214
00:09:53,367 --> 00:09:57,234
Um, Jessica Hagy said that
the more money you have,

215
00:09:57,234 --> 00:09:59,367
the more free time you've got.

216
00:09:59,367 --> 00:10:00,901
In fact, when you're broke,
you've got free time,

217
00:10:00,901 --> 00:10:03,801
when you're rich. I decided to
examine this by looking at

218
00:10:03,801 --> 00:10:06,167
OECD data for 29 countries.

219
00:10:06,167 --> 00:10:10,067
I took this data, munged it
with R, and examined whether

220
00:10:10,067 --> 00:10:12,567
Jessica's hypothesis was right.

221
00:10:12,567 --> 00:10:16,000
Well, it turns out, um,
she was partially right.

222
00:10:16,000 --> 00:10:18,801
Turns out that, uh,
if you're from Luxemburg,

223
00:10:18,801 --> 00:10:21,467
um, you're pretty rich and you
do have a lot of free time.

224
00:10:21,467 --> 00:10:24,133
But, actually, the poor
countries, um, basically

225
00:10:24,133 --> 00:10:26,734
don't have very much
free time, so, um,

226
00:10:26,734 --> 00:10:30,100
this is an example of using R
for hypothesis testing.

227
00:10:30,100 --> 00:10:31,801
Um, but there's a lot of
bigger data out there.

228
00:10:31,801 --> 00:10:35,067
And this is an example of
a gene array that has

229
00:10:35,067 --> 00:10:37,167
100,000 data points.
This is actually the chip

230
00:10:37,167 --> 00:10:38,801
I designed in graduate school.

231
00:10:38,801 --> 00:10:42,200
And we like to find ways to
distill this data down to

232
00:10:42,200 --> 00:10:44,000
something we can feed our
brains. 

233
00:10:44,000 --> 00:10:47,567
A visualization that we can
give, and this is what I did

234
00:10:47,567 --> 00:10:50,033
with R. Um, I took those
100,000 data points and

235
00:10:50,033 --> 00:10:52,968
created a single visualization
that tells me something about

236
00:10:52,968 --> 00:10:55,834
the variants on
this particular chip.

237
00:10:55,834 --> 00:11:00,667
Um, that's great because, uh,
looking at data is not something

238
00:11:00,667 --> 00:11:02,868
we can just do
like a computer does.

239
00:11:02,868 --> 00:11:05,534
Another example is, um,
credit card transactions.

240
00:11:05,534 --> 00:11:07,868
There'll be one million credit
card transactions during

241
00:11:07,868 --> 00:11:11,133
this presentation, and we can
use this data to predict

242
00:11:11,133 --> 00:11:13,367
something about what we consume.

243
00:11:13,367 --> 00:11:17,767
Um, in fact, every time you go
to Amazon or Netflix,

244
00:11:17,767 --> 00:11:19,901
uh, you see questions
about which products

245
00:11:19,901 --> 00:11:23,868
are ordered together. Um, we can
use this credit card

246
00:11:23,868 --> 00:11:26,367
transactional data, in fact I
used it for a particular 

247
00:11:26,367 --> 00:11:30,534
client of mine, to figure
out, whether or not, uh,

248
00:11:30,534 --> 00:11:33,267
if you like Google IO,
you're going to love, uh,

249
00:11:33,267 --> 00:11:35,601
Oscon 2009.

250
00:11:35,601 --> 00:11:38,667
Click data; there are a billion
clicks that will happen during

251
00:11:38,667 --> 00:11:41,534
this presentation, but you can
use click data and pull it into

252
00:11:41,534 --> 00:11:44,200
R to make interesting, uh,

253
00:11:44,200 --> 00:11:45,801
predictions about what people
are doing.

254
00:11:45,801 --> 00:11:48,734
In fact, the advertising guru
John Wanamaker said

255
00:11:48,734 --> 00:11:50,834
that half of the money
I spend on advertising

256
00:11:50,834 --> 00:11:53,234
is wasted, but the problem is,
I don't know which half.

257
00:11:53,234 --> 00:11:55,601
Well, we can change
this using data.

258
00:11:55,601 --> 00:11:58,601
Right here, we do an analysis
using Baisian statistics

259
00:11:58,601 --> 00:12:01,501
to figure out which web ads
are more successful.

260
00:12:01,501 --> 00:12:03,334
Again, this is done using R.

261
00:12:03,334 --> 00:12:04,868
But now let's talk about
something really important.

262
00:12:04,868 --> 00:12:07,300
Pitches. Major league
baseball pitchers.

263
00:12:07,300 --> 00:12:09,367
Major league baseball
has a database

264
00:12:09,367 --> 00:12:11,067
of over one million pitches

265
00:12:11,067 --> 00:12:13,434
with their velocity, their
location, and their speed,

266
00:12:13,434 --> 00:12:14,734
and we can take this data,

267
00:12:14,734 --> 00:12:17,834
and we can build
visual fingerprints for pitches.

268
00:12:17,834 --> 00:12:20,534
The top here is Cole Hamels,
the bottom in Brandon Webb,

269
00:12:20,534 --> 00:12:22,567
and I've used this data to look
at the kinds of pitches

270
00:12:22,567 --> 00:12:24,434
these guys throw.

271
00:12:24,434 --> 00:12:27,634
Uh, Cole Hamels is a finesse
pitcher, Brandon Webb

272
00:12:27,634 --> 00:12:31,667
uses change-ups, ways of
deceiving the pitchers.

273
00:12:31,667 --> 00:12:35,167
And that's great. The truth is
that, what we're moving towards

274
00:12:35,167 --> 00:12:37,934
is a way to bring
data to the masses.

275
00:12:37,934 --> 00:12:40,701
Um, and we have actually, uh,
because R is open source

276
00:12:40,701 --> 00:12:42,400
we can put it into a web page.

277
00:12:42,400 --> 00:12:44,801
Um, we don't have to have it
sitting on our desktop.

278
00:12:44,801 --> 00:12:46,634
This is a stack I like to call
LAMR.

279
00:12:46,634 --> 00:12:50,133
Um, if you've got a better name,
please let me know.

280
00:12:50,133 --> 00:12:52,300
So the reason we want to do this
is because, you know,

281
00:12:52,300 --> 00:12:54,901
data is out there, it's in the
clouds. Well, there's no reason

282
00:12:54,901 --> 00:12:58,534
to be bringing all this data to
your desktop, that's just crazy.

283
00:12:58,534 --> 00:13:01,467
Um, and that's why we need to
think about putting R

284
00:13:01,467 --> 00:13:05,234
into that stack, because--and
the truth is, that, you know,

285
00:13:05,234 --> 00:13:08,000
I love coding, it's great, but,
given a choice, we'd rather be

286
00:13:08,000 --> 00:13:10,901
clicking on applications.
When we're doing data analysis,

287
00:13:10,901 --> 00:13:13,567
we'd rather be clicking our way
through it, rather than

288
00:13:13,567 --> 00:13:17,000
coding our way, and putting R in
the stack; using the force of

289
00:13:17,000 --> 00:13:19,067
open source, we can do that.

290
00:13:19,067 --> 00:13:21,968
So, in conclusion, uh,
it's an exciting period.

291
00:13:21,968 --> 00:13:24,868
We live in the age of big data.
Uh, may the force of open source

292
00:13:24,868 --> 00:13:27,133
be with you, and, uh, I hope
you'll check out R.

293
00:13:27,133 --> 00:13:30,934
Thanks very much.

294
00:13:30,934 --> 00:13:35,167
- Forrest:
Thank you very much, Mike.

295
00:13:35,167 --> 00:13:37,901
I consider myself a geek,
I consider most of these talks

296
00:13:37,901 --> 00:13:41,434
to be geek-oriented, and now
we're going to learn from

297
00:13:41,434 --> 00:13:43,501
one of our speakers how she
grew up to be a geek.

298
00:13:43,501 --> 00:13:49,767
Please welcome the Elven
cartographer, Pamela Fox.

299
00:13:49,767 --> 00:13:51,734
- Fox: All right, hey,
I'm Pamela Fox.

300
00:13:51,734 --> 00:13:54,200
I've been the Google Maps API
Support Engineer for the last

301
00:13:54,200 --> 00:13:57,267
two years, and a lot of times
people ask me how I got into

302
00:13:57,267 --> 00:13:59,701
this crazy world of web
development, so I'm going

303
00:13:59,701 --> 00:14:04,334
to try to boil it all down into
five minutes for you guys.

304
00:14:04,334 --> 00:14:07,701
So yeah, I'm a geek. Uh, but
I didn't start this fire.

305
00:14:07,701 --> 00:14:10,834
It's not my fault. It happened
at CalTech, as all good love

306
00:14:10,834 --> 00:14:14,067
stories do, when two people
infinitely geekier than me,

307
00:14:14,067 --> 00:14:16,133
you know, fell in love. So,
I want to introduce you

308
00:14:16,133 --> 00:14:20,534
to my parents, and justify
their geek cred for you.

309
00:14:20,534 --> 00:14:23,133
Starts with my dad, Geoffrey
Fox. He started in physics

310
00:14:23,133 --> 00:14:25,267
and then moved to computer
science when he realized

311
00:14:25,267 --> 00:14:26,868
that he needed
mad CPU cycles

312
00:14:26,868 --> 00:14:28,968
in order to compute all this
crazy physics shit.

313
00:14:28,968 --> 00:14:31,000
Back then he was doing stuff
like writing

314
00:14:31,000 --> 00:14:34,167
the Mathematica forerunner's
kernel with Stephen Wolfram,

315
00:14:34,167 --> 00:14:36,200
and running the physics
department with Feynman.

316
00:14:36,200 --> 00:14:39,434
Here's my mom, she was my dad's
physics student, ooh la la,

317
00:14:39,434 --> 00:14:42,234
and, uh, she also does
a lot of space stuff.

318
00:14:42,234 --> 00:14:45,267
She worked for NASA JPL and made
something called a scatterometer

319
00:14:45,267 --> 00:14:46,801
which is orbiting space
above our heads and,

320
00:14:46,801 --> 00:14:51,100
I'm kind of worried that maybe
it's watching me right now.

321
00:14:51,100 --> 00:14:53,033
So they decided to get married
and have babies,

322
00:14:53,033 --> 00:14:54,734
but they never stopped writing
research papers that had

323
00:14:54,734 --> 00:14:57,734
ridiculously long titles.

324
00:14:57,734 --> 00:15:00,100
I never knew that particle decay
could, like, provoke so many

325
00:15:00,100 --> 00:15:02,567
passionate nights of conception,
and I'm a bit concerned that

326
00:15:02,567 --> 00:15:06,200
my titles are the dorkiest.

327
00:15:06,200 --> 00:15:08,968
So, we grew up and we were kind
of oblivious to the fact that

328
00:15:08,968 --> 00:15:11,734
we were different. Right?
We didn't know it was strange

329
00:15:11,734 --> 00:15:14,200
that around the house instead of
having framed family photos,

330
00:15:14,200 --> 00:15:15,834
we had portraits
of Richard Feynman

331
00:15:15,834 --> 00:15:20,701
and framed super
computer chips.

332
00:15:20,701 --> 00:15:23,634
Uh, we also didn't know it was
kind of weird that we had

333
00:15:23,634 --> 00:15:27,901
six computers
and just two tiny, little TVs.

334
00:15:27,901 --> 00:15:29,701
It just made family
communication a lot easier

335
00:15:29,701 --> 00:15:31,868
because when it was dinner time,
we could just instant message

336
00:15:31,868 --> 00:15:33,868
upstairs and be like,
"Dad, it's time for dinner.

337
00:15:33,868 --> 00:15:35,968
Come downstairs." 

338
00:15:35,968 --> 00:15:38,701
And, uh, speaking of that,
we were also the only people

339
00:15:38,701 --> 00:15:40,467
in the city
that had a T1 connection

340
00:15:40,467 --> 00:15:42,300
straight to the university.

341
00:15:42,300 --> 00:15:44,634
To me, this was just
instant popularity, right?

342
00:15:44,634 --> 00:15:47,734
I had so many new friends who
wanted to come over and look at

343
00:15:47,734 --> 00:15:51,901
Backstreet Boys websites
and porn.

344
00:15:51,901 --> 00:15:54,868
So, back then, I was using all
of our computers to use, like,

345
00:15:54,868 --> 00:15:57,234
awesome old school computer
programs like Carmen San Diego,

346
00:15:57,234 --> 00:16:00,834
which I now really, really want
to redo using the maps API,

347
00:16:00,834 --> 00:16:04,467
and also Kid Pix Deluxe, which
is basically Windows Paint

348
00:16:04,467 --> 00:16:07,467
on crack or LSD or
something really strong.

349
00:16:07,467 --> 00:16:09,634
Uh, but one day it was Mother's
Day and I realized I needed

350
00:16:09,634 --> 00:16:14,033
a present for my mom, so I
googled or yahooed HTML and

351
00:16:14,033 --> 00:16:17,834
learnt it and got this MS Word
plugin called Internet Assistant

352
00:16:17,834 --> 00:16:21,267
and, uh, basically I've never
bought presents since.

353
00:16:21,267 --> 00:16:24,100
Parents love web pages. So my
dad saw this and decided to

354
00:16:24,100 --> 00:16:26,501
introduce me to real
programming, which was Perl,

355
00:16:26,501 --> 00:16:29,501
back then. Uh, so one New Year's
Eve, instead of watching

356
00:16:29,501 --> 00:16:33,167
fireworks, we sat together and
created my first Perl program

357
00:16:33,167 --> 00:16:36,067
when the clock struck midnight.
Adorable.

358
00:16:36,067 --> 00:16:37,734
It was--that's the Mad Libs.

359
00:16:37,734 --> 00:16:39,033
Uh, so my dad was such
a huge proponent of Java

360
00:16:39,033 --> 00:16:41,667
back then. He thought it was the
future of the internet.

361
00:16:41,667 --> 00:16:46,701
He still thinks that. And, um,
so he had me learn Java and, uh,

362
00:16:46,701 --> 00:16:50,167
and run a Java Academy, and this
is actually where I first got

363
00:16:50,167 --> 00:16:53,033
asked out by my first boyfriend,
with a Java applet.

364
00:16:53,033 --> 00:16:56,667
I said yeah. Um, so as kids,
we had a lot of freedom,

365
00:16:56,667 --> 00:16:59,167
but then suddenly my dad became
really strict and he had this

366
00:16:59,167 --> 00:17:02,734
one rule for me that, no matter
what, I had to program Java

367
00:17:02,734 --> 00:17:05,767
that week. He wouldn't give me
allowance or let me go out,

368
00:17:05,767 --> 00:17:07,968
unless I programmed
some Java.

369
00:17:07,968 --> 00:17:10,434
But I was in high school,
so, yeah,

370
00:17:10,434 --> 00:17:12,634
I programmed a bit, but there
was just so much else that I

371
00:17:12,634 --> 00:17:16,234
wanted to do too, so I, I was
class president for four years,

372
00:17:16,234 --> 00:17:17,567
and laid out the newspaper

373
00:17:17,567 --> 00:17:21,000
and did volunteerism as well,
and so my dad

374
00:17:21,000 --> 00:17:23,701
wasn't thrilled by all this
other stuff I was doing.

375
00:17:23,701 --> 00:17:26,667
And then, afterwards, I went to
USC and I did computer science

376
00:17:26,667 --> 00:17:28,734
because that was still my,
you know, my core interest.

377
00:17:28,734 --> 00:17:31,601
But I still pursued other loves
as well, so, linguistics,

378
00:17:31,601 --> 00:17:36,467
animation, volunteerism, being a
radical hippy, save the world.

379
00:17:36,467 --> 00:17:38,634
Uh, so my, once again,
Dad wasn't that thrilled,

380
00:17:38,634 --> 00:17:40,834
but one day he comes
to visit me at USC

381
00:17:40,834 --> 00:17:42,300
to give a talk about SOAP
web services,

382
00:17:42,300 --> 00:17:44,501
which looked like gobbledy gook
to me, then.

383
00:17:44,501 --> 00:17:47,000
And, uh, he looked around and
saw everything I did and said,

384
00:17:47,000 --> 00:17:49,000
"Hey, you know, maybe it's
actually a good thing

385
00:17:49,000 --> 00:17:51,968
that you decided to do stuff
other than program."

386
00:17:51,968 --> 00:17:55,400
So finally I felt pretty good
that I had some validation.

387
00:17:55,400 --> 00:17:59,467
Uh, and then I got into web APIs
and mashups and learned that

388
00:17:59,467 --> 00:18:02,367
SOAP really is gobbledy gook,
but just in XML form.

389
00:18:02,367 --> 00:18:07,033
So it's a standard. Uh, and you
can see my dad finally admitted

390
00:18:07,033 --> 00:18:10,534
that SOAP is just,
it's not cool anymore.

391
00:18:10,534 --> 00:18:12,501
Uh, so, what about
the rest of my family?

392
00:18:12,501 --> 00:18:15,234
This is my sister; she's now in
Boston doing web development

393
00:18:15,234 --> 00:18:17,501
with jQuery. Uh, my brother
logged off Facebook

394
00:18:17,501 --> 00:18:20,167
before we actually created our
Fox Family Group, so we don't

395
00:18:20,167 --> 00:18:23,334
actually know what he's doing,
so if you see him, if you could

396
00:18:23,334 --> 00:18:25,100
say "Hi" and let me know.

397
00:18:25,100 --> 00:18:27,667
Uh, this is my Mum, she's
a scientific programmer now,

398
00:18:27,667 --> 00:18:31,267
and she's analyzing spectrol
emissions from rocket, uh,

399
00:18:31,267 --> 00:18:33,767
rocket emissions. So she's
basically a rocket scientist.

400
00:18:33,767 --> 00:18:36,567
And, uh, she actually visited me
the other day and said they're

401
00:18:36,567 --> 00:18:38,701
thinking of publishing
their rocket science

402
00:18:38,701 --> 00:18:41,334
using Amazon EC2
and App Engine.

403
00:18:41,334 --> 00:18:44,267
And, here is some new spawn
for my dad.

404
00:18:44,267 --> 00:18:47,634
This is with his new wife, who
was also his physics student.

405
00:18:47,634 --> 00:18:49,267
Bit of a pattern there.

406
00:18:49,267 --> 00:18:52,534
And, clearly, he's trying to get
her to learn programming already

407
00:18:52,534 --> 00:18:55,133
but hopefully he lets her
explore other interests as well.

408
00:18:55,133 --> 00:18:58,167
She'll probably come up geek
anyway.

409
00:19:06,200 --> 00:19:07,734
- Forrest:
Thank you very much, Pamela.

410
00:19:07,734 --> 00:19:09,000
In case you just came in,

411
00:19:09,000 --> 00:19:10,901
you're in the middle
of an Ignite session.

412
00:19:10,901 --> 00:19:13,934
We've got nine speakers.
We just had our third talk.

413
00:19:13,934 --> 00:19:16,868
Uh, all the talks are the same
in that they're

414
00:19:16,868 --> 00:19:20,501
five minutes, 20 slides,
15 seconds a slide.

415
00:19:20,501 --> 00:19:24,267
And the speakers
have no control.

416
00:19:24,267 --> 00:19:26,133
And our next speaker
is a control freak

417
00:19:26,133 --> 00:19:28,634
and not used to this.

418
00:19:28,634 --> 00:19:30,267
Please meet Tim Ferriss.

419
00:19:30,267 --> 00:19:32,000
He's the author of
"The Four Hour Work Week"

420
00:19:32,000 --> 00:19:35,300
and he's here to talk
about practical pessimism.

421
00:19:35,300 --> 00:19:36,367
- Ferriss: All right, guys,

422
00:19:36,367 --> 00:19:38,133
this is not meant to be
depressing,

423
00:19:38,133 --> 00:19:41,968
it's meant to be practical. I
changed my topic, uh, a bit, so,

424
00:19:41,968 --> 00:19:44,467
uh, hopefully, at least, perhaps
one or two percent of you

425
00:19:44,467 --> 00:19:48,133
will find this useful.

426
00:19:48,133 --> 00:19:51,934
Do a little dance.
All right,

427
00:19:51,934 --> 00:19:55,234
so this is a photograph
of Las Lenas in Argentina,

428
00:19:55,234 --> 00:19:59,400
where I went skiing with two
close friends, one of whom

429
00:19:59,400 --> 00:20:03,434
recently died of pancreatic
cancer. He was in his early 30s.

430
00:20:03,434 --> 00:20:05,567
On the same day I received
an email notifying me

431
00:20:05,567 --> 00:20:08,434
that the ten-year-old daughter
of the close friend

432
00:20:08,434 --> 00:20:11,100
had been diagnosed with
inoperable cancer,

433
00:20:11,100 --> 00:20:14,801
and, uh, this was very recent,
and this catalyzed,

434
00:20:14,801 --> 00:20:18,634
it produced a profound sense
of urgency in me

435
00:20:18,634 --> 00:20:22,000
to do bigger and better things
in my life, and to test

436
00:20:22,000 --> 00:20:27,033
new directions before some
undefined point in the future.

437
00:20:27,033 --> 00:20:30,434
So I want to talk about the most
effective pair

438
00:20:30,434 --> 00:20:34,167
of productivity techniques that
I've come across since 2004,

439
00:20:34,167 --> 00:20:37,834
uh, that have helped me up to
this point, test the uncommon

440
00:20:37,834 --> 00:20:41,567
despite the fear of ridicule,
criticism,

441
00:20:41,567 --> 00:20:42,834
failure, and so forth.

442
00:20:42,834 --> 00:20:45,200
And both techniques,
I cheated a bit with the format,

443
00:20:45,200 --> 00:20:48,601
some things will repeat, uh,
are borrowed from stoicism,

444
00:20:48,601 --> 00:20:52,267
which was a school of philosophy
from the Hellenistic period

445
00:20:52,267 --> 00:20:55,734
used by a lot of the Greco-Roman
educated elite,

446
00:20:55,734 --> 00:20:58,701
including emperors and military
and statesmen.

447
00:20:58,701 --> 00:21:03,934
The first is called negative
visualization, and it's all

448
00:21:03,934 --> 00:21:06,300
related to the basic assumption
that defining your fears,

449
00:21:06,300 --> 00:21:11,300
instead of your goals, is a key
to doing anything uncommon,

450
00:21:11,300 --> 00:21:15,067
anything big. Uh, negative
visualization is,

451
00:21:15,067 --> 00:21:18,133
what I would call, preparation
in practical pessimism.

452
00:21:18,133 --> 00:21:22,200
And that is, defining
in excruciating detail

453
00:21:22,200 --> 00:21:23,534
the worst case scenarios.

454
00:21:23,534 --> 00:21:25,501
So, as an anecdote, in 2004,

455
00:21:25,501 --> 00:21:29,634
I was working 14 hours a day,
uh, in my own company,

456
00:21:29,634 --> 00:21:31,567
trapped in a beast
of my own design,

457
00:21:31,567 --> 00:21:36,100
and knew that I had to take
a two to four week retreat

458
00:21:36,100 --> 00:21:40,234
to either, uh, streamline the
business and extricate myself,

459
00:21:40,234 --> 00:21:43,167
or shut it down, because there
were issues with exit options.

460
00:21:43,167 --> 00:21:46,634
I didn't do that for six months
because I was running

461
00:21:46,634 --> 00:21:48,467
an endless loop
of what-if scenarios.

462
00:21:48,467 --> 00:21:52,200
What if I missed a notification
with the IRS?

463
00:21:52,200 --> 00:21:56,634
What if we lost the biggest
customer we have and, therefore,

464
00:21:56,634 --> 00:21:58,334
had problems A, B, and C?

465
00:21:58,334 --> 00:22:00,467
Problem is, those fears
weren't actionable,

466
00:22:00,467 --> 00:22:02,868
just like poorly-defined goals
aren't actionable.

467
00:22:02,868 --> 00:22:07,000
Then I came across the writings
of Seneca, Lucius Seneca,

468
00:22:07,000 --> 00:22:10,801
who was an advisor to the
emperor in his day, in Rome.

469
00:22:10,801 --> 00:22:12,300
Also, what you might consider

470
00:22:12,300 --> 00:22:14,300
the most successful investment
banker and playwright,

471
00:22:14,300 --> 00:22:16,267
at the time, in Rome.

472
00:22:16,267 --> 00:22:20,033
And, I performed an exercise
that he suggested,

473
00:22:20,033 --> 00:22:22,067
which was taking
out a piece of paper,

474
00:22:22,067 --> 00:22:24,601
in my case an eight and a half
by eleven sheet one evening,

475
00:22:24,601 --> 00:22:26,200
and detailing,
in the first column,

476
00:22:26,200 --> 00:22:28,567
all of the terrible things,
the worst case scenarios

477
00:22:28,567 --> 00:22:30,267
that could happen, if I did
what I was considering,

478
00:22:30,267 --> 00:22:31,734
which was this retreat.

479
00:22:31,734 --> 00:22:34,167
For you, it might be a change
of job, it might be

480
00:22:34,167 --> 00:22:37,734
proposing a new project, it
might be ending a relationship,

481
00:22:37,734 --> 00:22:38,968
it could be
any number of things.

482
00:22:38,968 --> 00:22:41,100
All of the negative
things that could happen.

483
00:22:41,100 --> 00:22:42,968
Second column, all of the
things that I could do

484
00:22:42,968 --> 00:22:45,634
to minimize the likelihood of
those things happening.

485
00:22:45,634 --> 00:22:49,200
And then the last column were
all the line by line actions

486
00:22:49,200 --> 00:22:51,467
I could take to get back to
where I was then.

487
00:22:51,467 --> 00:22:53,767
To reachieve the status quo, so
to speak, maybe getting back

488
00:22:53,767 --> 00:22:57,000
into the industry that you could
leave to start your own start up

489
00:22:57,000 --> 00:22:58,701
whatever that might be.

490
00:22:58,701 --> 00:23:01,868
And, in that instant, I saw that
on a scale from zero to ten,

491
00:23:01,868 --> 00:23:07,200
ten being most impactful, I was
looking at a unlikely transient

492
00:23:07,200 --> 00:23:10,968
pain of about two,
and a potential, life-changing,

493
00:23:10,968 --> 00:23:14,167
permanent change of ten,
and, I took the trip.

494
00:23:14,167 --> 00:23:17,267
I took the trip, and that's why
the book happened,

495
00:23:17,267 --> 00:23:20,267
that's why the world
championships in tango happen,

496
00:23:20,267 --> 00:23:23,367
everything that
brought me to stand here today,

497
00:23:23,367 --> 00:23:26,200
I can trace back to that one
evening in that one exercise.

498
00:23:26,200 --> 00:23:28,334
So, let's move to practice,
the second piece,

499
00:23:28,334 --> 00:23:29,501
the second technique

500
00:23:29,501 --> 00:23:33,067
is rehearsing the worst-case
scenarios.

501
00:23:33,067 --> 00:23:34,367
Seneca would put it thus,

502
00:23:34,367 --> 00:23:36,767
"Set aside
a number of days each month,

503
00:23:36,767 --> 00:23:40,667
"where you are satisfied
with the cheapest and

504
00:23:40,667 --> 00:23:42,968
"scantiest of fare,
meaning food,

505
00:23:42,968 --> 00:23:46,200
"the roughest of dress,
all the while asking yourself,

506
00:23:46,200 --> 00:23:49,200
'Is this the condition
I feared?'"

507
00:23:49,200 --> 00:23:52,434
What you're doing is exposing
yourself to negative emotions,

508
00:23:52,434 --> 00:23:57,567
like fear, embarrassment, lack
of finances, so that you're

509
00:23:57,567 --> 00:24:01,033
inoculated when you later
have to make hard decisions,

510
00:24:01,033 --> 00:24:05,734
ask for hard things,
or reject refused things,

511
00:24:05,734 --> 00:24:08,300
uh, so that you can act
despite these emotions.

512
00:24:08,300 --> 00:24:12,234
Uh, Cato, who has viewed Seneca
as the perfect Stoic,

513
00:24:12,234 --> 00:24:17,567
wore darker clothing than his,
uh, expected light purple,

514
00:24:17,567 --> 00:24:21,167
didn't go with the tunic, he was
very out of style in his day.

515
00:24:21,167 --> 00:24:24,734
And he did so that he would
learn to be ashamed

516
00:24:24,734 --> 00:24:26,467
of only the things
that were truly shameful

517
00:24:26,467 --> 00:24:28,467
and to ignore
the millions of things

518
00:24:28,467 --> 00:24:31,067
that men would otherwise have
low opinions of.

519
00:24:31,067 --> 00:24:33,767
Uh, so it's very important that
you practice

520
00:24:33,767 --> 00:24:35,801
your worst case scenario,
and what you'll find is that

521
00:24:35,801 --> 00:24:39,601
many of the fears you have
are based on undervaluing

522
00:24:39,601 --> 00:24:41,300
the things that are
easily attainable.

523
00:24:41,300 --> 00:24:43,400
So, those are two techniques

524
00:24:43,400 --> 00:24:45,601
that have
resulted in the greatest gains,

525
00:24:45,601 --> 00:24:48,868
all of the uncommon, all of the
big things I've been able to do,

526
00:24:48,868 --> 00:24:50,200
and I would encourage you,

527
00:24:50,200 --> 00:24:51,801
before trying
to define your goals,

528
00:24:51,801 --> 00:24:53,400
to focus on
defining your fears.

529
00:24:53,400 --> 00:24:55,767
Thank you very much.

530
00:25:02,100 --> 00:25:05,200
- Forrest:
Thank you very much, Tim.

531
00:25:10,400 --> 00:25:13,000
Pardon the admin time.

532
00:25:17,334 --> 00:25:19,501
Our next speaker is going to
talk about something that's

533
00:25:19,501 --> 00:25:21,601
near and dear, I'm sure,
to many of your hearts,

534
00:25:21,601 --> 00:25:26,801
and that is scaling.
Please welcome Nitin.

535
00:25:26,801 --> 00:25:31,133
- Nitin: So this is about the
Twitter flame wars that started

536
00:25:31,133 --> 00:25:33,968
last year, when Twitter first
had some scaling problems,

537
00:25:33,968 --> 00:25:37,767
and, uh, it's about a principle
that I derived from listening to

538
00:25:37,767 --> 00:25:40,033
all of that stuff and, uh,
trying to get underneath

539
00:25:40,033 --> 00:25:42,467
and trying to find the
fundamental principles

540
00:25:42,467 --> 00:25:46,501
by first, uh, clearing
your mind, and trying to get

541
00:25:46,501 --> 00:25:47,734
to the bottom of things,

542
00:25:47,734 --> 00:25:50,200
and by trying to find
fundamental principles

543
00:25:50,200 --> 00:25:54,234
that are, uh, independent of
technology, uh, well,

544
00:25:54,234 --> 00:25:56,901
specific technology or specific
languages and so forth.

545
00:25:56,901 --> 00:25:59,334
And this is what all of that
sounded like to me, because

546
00:25:59,334 --> 00:26:01,467
these were specific phrases
that were used

547
00:26:01,467 --> 00:26:03,200
when people were
yelling at each other.

548
00:26:03,200 --> 00:26:05,200
There was a lot of emotion
and things like that.

549
00:26:05,200 --> 00:26:07,834
And, uh, underneath all that,
there was some discussions

550
00:26:07,834 --> 00:26:10,300
about engineering,
and, uh, at some point,

551
00:26:10,300 --> 00:26:13,501
I started to get beyond this and
started to hear some stuff that

552
00:26:13,501 --> 00:26:15,868
had to do with engineering, but
still, there wasn't anything

553
00:26:15,868 --> 00:26:17,934
there that I could see was
a fundamental principle.

554
00:26:17,934 --> 00:26:22,300
And I wished I could be like
that dog in that famous cartoon

555
00:26:22,300 --> 00:26:25,534
where people or somebody's--
people are yelling at the dog

556
00:26:25,534 --> 00:26:26,667
and the dog is just hearing

557
00:26:26,667 --> 00:26:28,300
the stuff
that the dog wants to hear.

558
00:26:28,300 --> 00:26:31,601
So, for you visual learners,
uh, something here.

559
00:26:31,601 --> 00:26:34,801
And, uh, again, so focusing down
and trying to distill that to

560
00:26:34,801 --> 00:26:39,801
fundamental principles, um,
I began to hear something that,

561
00:26:39,801 --> 00:26:43,000
to the database person, sounded
like, people were talking only

562
00:26:43,000 --> 00:26:44,367
about what I called
the physical model,

563
00:26:44,367 --> 00:26:46,033
which is just about
implementation.

564
00:26:46,033 --> 00:26:48,000
And they weren't talking
too much about design.

565
00:26:48,000 --> 00:26:49,601
Uh, in the database world,
we talk about physical model

566
00:26:49,601 --> 00:26:50,801
and the logical model,

567
00:26:50,801 --> 00:26:52,601
which is the abstract
structure of the data.

568
00:26:52,601 --> 00:26:54,634
And I didn't hear too much
about database design,

569
00:26:54,634 --> 00:26:56,834
and I didn't hear too much
about, uh, queries and stuff,

570
00:26:56,834 --> 00:26:58,501
and so, that's what
I'm going to talk about.

571
00:26:58,501 --> 00:27:00,167
And I'm going to talk less
about, uh,

572
00:27:00,167 --> 00:27:01,968
all the stuff that was
talked about earlier.

573
00:27:01,968 --> 00:27:04,501
So, uh, we take a simple query
that, uh,

574
00:27:04,501 --> 00:27:06,234
happens in two
different cases,

575
00:27:06,234 --> 00:27:10,267
and during Flickr in 2005, I had
a problem with the servers

576
00:27:10,267 --> 00:27:12,367
and the servers were crashing
because of the way

577
00:27:12,367 --> 00:27:13,834
that had to do with groups.

578
00:27:13,834 --> 00:27:15,267
And, it turns out,
a very similar query

579
00:27:15,267 --> 00:27:18,634
is a query that was causing
Twitter to crash in 2008,

580
00:27:18,634 --> 00:27:21,033
and I, uh, extracted
out of what is common

581
00:27:21,033 --> 00:27:22,400
in both of these queries,

582
00:27:22,400 --> 00:27:26,434
and it turns out that there's
a problem of visibility.

583
00:27:26,434 --> 00:27:29,701
Uh, there are two people, one
person is, uh, publishing some

584
00:27:29,701 --> 00:27:33,434
content with some restrictions,
uh, like groups or, uh,

585
00:27:33,434 --> 00:27:35,434
blocking users
in the case of Twitter,

586
00:27:35,434 --> 00:27:36,767
and the other user says,

587
00:27:36,767 --> 00:27:38,534
"What, what can I see?"
And that's the common query

588
00:27:38,534 --> 00:27:40,968
in all of this, and what causes
a scaling problem

589
00:27:40,968 --> 00:27:42,133
in all of this queries

590
00:27:42,133 --> 00:27:45,834
is a self-join
on a million row user table.

591
00:27:45,834 --> 00:27:48,901
And that's at the core of this
problem, and you don't see this

592
00:27:48,901 --> 00:27:52,300
in outside social networks,
because, in the enterprise,

593
00:27:52,300 --> 00:27:55,367
you don't have a million row
user tables.

594
00:27:55,367 --> 00:27:57,300
And, uh, in the enterprise,
you have, uh,

595
00:27:57,300 --> 00:27:59,667
more hierarchical structures.

596
00:27:59,667 --> 00:28:00,934
That's what the enterprise
looks like

597
00:28:00,934 --> 00:28:03,033
and that's what a social network
looks like.

598
00:28:03,033 --> 00:28:04,767
And you can't really break
it down and partition it,

599
00:28:04,767 --> 00:28:06,968
and so I called it
"Shard-Nothing."

600
00:28:06,968 --> 00:28:09,868
And, that's got lots of many to
many relationships,

601
00:28:09,868 --> 00:28:12,033
that's got a lot of one
to many relationships,

602
00:28:12,033 --> 00:28:13,634
and so let's get
back to basics

603
00:28:13,634 --> 00:28:16,100
and do some science and see
what have you got that's good.

604
00:28:16,100 --> 00:28:19,367
Uh, so RAM and cores, good.
And query cost,

605
00:28:19,367 --> 00:28:22,434
lots of users and squared
to the denominator, bad.

606
00:28:22,434 --> 00:28:27,133
And so, I created a formula that
I call data crunching power.

607
00:28:27,133 --> 00:28:30,834
And, you divide RAM times core
by n squared, and so you've got

608
00:28:30,834 --> 00:28:33,734
a lot of good stuff, you've got
a lot of data crunching power.

609
00:28:33,734 --> 00:28:36,067
If you've got a lot of bad
stuff, well, you know,

610
00:28:36,067 --> 00:28:37,534
servers are going to crash.

611
00:28:37,534 --> 00:28:39,300
And so, you're going to say,
so you're going to say

612
00:28:39,300 --> 00:28:41,367
"Okay, I'm just going to put
a lot of servers on here,

613
00:28:41,367 --> 00:28:43,567
I'm going to put a lot
of, uh, cores,"

614
00:28:43,567 --> 00:28:46,167
but you've got a problem.

615
00:28:46,167 --> 00:28:49,100
And so, you got to stay far away
from that intersection point

616
00:28:49,100 --> 00:28:51,868
and, uh, you can do that by
trying to keep shifting this

617
00:28:51,868 --> 00:28:54,133
curve over on the other side by
adding more servers, but you

618
00:28:54,133 --> 00:28:55,968
can't really use the amount of
data you're dealing with

619
00:28:55,968 --> 00:28:57,367
by going down.

620
00:28:57,367 --> 00:29:00,701
And so, I pulled my friend's
timeline from Twitter,

621
00:29:00,701 --> 00:29:02,634
and put it on my laptop.

622
00:29:02,634 --> 00:29:04,467
And I said "Let's see what
queries I can do on it

623
00:29:04,467 --> 00:29:06,667
versus what Twitter
can do for me."

624
00:29:06,667 --> 00:29:09,200
And so, those are
the numbers from 2008,

625
00:29:09,200 --> 00:29:12,200
and Twitter had a single 8 core
server with 64G of RAM, 

626
00:29:12,200 --> 00:29:14,067
or something,
put it into my formula,

627
00:29:14,067 --> 00:29:15,501
and guess what comes out.

628
00:29:15,501 --> 00:29:20,067
Look at this stuff on the right.
Uh, my laptop has a 100,000

629
00:29:20,067 --> 00:29:23,767
times advantage over Twitter
when it's dealing with my data.

630
00:29:23,767 --> 00:29:26,367
So, clearly not with all of the
data, but just with my data.

631
00:29:26,367 --> 00:29:28,434
So I can do more stuff
with my data

632
00:29:28,434 --> 00:29:33,334
than Twitter can do with,
with my data on Twitter.

633
00:29:33,334 --> 00:29:35,534
Now, of course, Twitter can do
search and they can do trans

634
00:29:35,534 --> 00:29:39,234
and all of this stuff,
and I can't do that, so...

635
00:29:39,234 --> 00:29:42,901
So, the principle here is that,
you know, you ought to be

636
00:29:42,901 --> 00:29:45,901
taking your own data back and,
and, but right now

637
00:29:45,901 --> 00:29:48,033
you can't shard this, so,

638
00:29:48,033 --> 00:29:50,767
hidden in here is another
solution which, uh,

639
00:29:50,767 --> 00:29:53,868
I call "Shard-Everything."
So, you take every user's data

640
00:29:53,868 --> 00:29:56,200
and you give it to them
to manage on their laptop,

641
00:29:56,200 --> 00:29:59,334
and all, and then, the vendor

642
00:29:59,334 --> 00:30:00,934
just does
all of the aggregate stuff

643
00:30:00,934 --> 00:30:04,367
like search and trans
and all of the stuff that,

644
00:30:04,367 --> 00:30:06,100
are very simple queries
that can be done

645
00:30:06,100 --> 00:30:07,834
on data warehouses and stuff
like that.

646
00:30:07,834 --> 00:30:10,267
And all of that comes out
of a law that I call

647
00:30:10,267 --> 00:30:13,267
"The Scaling Law of Gravity"
because you can't escape it

648
00:30:13,267 --> 00:30:16,934
and it's an inverse square law,
but also because my name sounds

649
00:30:16,934 --> 00:30:20,601
like Newton, and I
did this on an Apple, so...

650
00:30:26,000 --> 00:30:28,634
- Forrest:
Thank you very much, Nitin.

651
00:30:28,634 --> 00:30:29,834
Our next speaker asks,

652
00:30:29,834 --> 00:30:33,400
"Why are we bigoted
about social networks?"

653
00:30:33,400 --> 00:30:35,300
And, I would argue
that one of the reasons is

654
00:30:35,300 --> 00:30:36,734
'cause many of them are slow.

655
00:30:36,734 --> 00:30:38,868
And that might be why we choose
one over the other.

656
00:30:38,868 --> 00:30:40,734
But I'm sure Kevin
has his own reasons,

657
00:30:40,734 --> 00:30:44,267
so please let's welcome
Kevin Marks.

658
00:30:44,267 --> 00:30:46,400
- Marks: Thank you.

659
00:30:46,400 --> 00:30:49,033
This is something I started
noticing a while ago,

660
00:30:49,033 --> 00:30:51,467
which is that people
are very insular.

661
00:30:51,467 --> 00:30:55,734
Um, but it manifests itself in
social networks particularly.

662
00:30:55,734 --> 00:30:58,434
Um, so I picked a few quotes out
of the press that covers this.

663
00:30:58,434 --> 00:31:01,767
This is Pete Cashmore of
Mashable, um,

664
00:31:01,767 --> 00:31:03,267
referring to Orkut

665
00:31:03,267 --> 00:31:05,167
as "Orkut's Brazilian drug
dealers" as a collective noun

666
00:31:05,167 --> 00:31:06,567
for the Orkut users.

667
00:31:06,567 --> 00:31:08,868
That, that one surprised me.
I thought "Okay, maybe this is,

668
00:31:08,868 --> 00:31:11,901
this is just, you
know, xenophobia."

669
00:31:11,901 --> 00:31:14,067
If you think about,
you know, this is, this is

670
00:31:14,067 --> 00:31:16,200
Le Monde's view of social
networks and each one

671
00:31:16,200 --> 00:31:18,667
takes over a different country
and they're obviously

672
00:31:18,667 --> 00:31:20,834
very nationalistic and
there's sort of a great,

673
00:31:20,834 --> 00:31:22,300
sort of, imperialist
thing going on here

674
00:31:22,300 --> 00:31:23,467
where each social network
invades a place

675
00:31:23,467 --> 00:31:25,501
and takes it over and,
therefore, obviously

676
00:31:25,501 --> 00:31:27,200
you'd resent ones that have
in other countries.

677
00:31:27,200 --> 00:31:30,033
So that's one thing, and then
Marshall did this last week.

678
00:31:30,033 --> 00:31:32,801
He said, "MySpace is like
a bratty little sister

679
00:31:32,801 --> 00:31:34,434
wearing too
little clothing."

680
00:31:34,434 --> 00:31:37,734
So there's something, there's
something else going on there

681
00:31:37,734 --> 00:31:39,501
than just,
sort of, xenophobia.

682
00:31:39,501 --> 00:31:43,801
There's some, is this, you know,
is this, your sister problems?

683
00:31:43,801 --> 00:31:46,801
Then I read Michael Wolfe.
Now this is really impressive.

684
00:31:46,801 --> 00:31:49,067
He says, "If you're on MySpace,
you're a cretin.

685
00:31:49,067 --> 00:31:50,234
"You're a poor cretin.

686
00:31:50,234 --> 00:31:52,467
"Nobody beyond 8th grade level
of education

687
00:31:52,467 --> 00:31:55,734
is on MySpace.
It's for backwards people."

688
00:31:55,734 --> 00:31:58,968
So, there's something stronger
than just little sisters here.

689
00:31:58,968 --> 00:32:00,734
Um, if you look at the social
networks

690
00:32:00,734 --> 00:32:03,067
and their growth over time,
they've spread out.

691
00:32:03,067 --> 00:32:05,901
They started with out
with a few, you know,

692
00:32:05,901 --> 00:32:07,667
15 years ago,
and they've grown up gradually,

693
00:32:07,667 --> 00:32:09,267
and there are lots
of different ones,

694
00:32:09,267 --> 00:32:12,234
and they end up having
different feels to them.

695
00:32:12,234 --> 00:32:15,934
Um, so, here's one more
from The Times, um,

696
00:32:15,934 --> 00:32:17,334
he's talking about
Twitter, he says,

697
00:32:17,334 --> 00:32:19,234
"Typical profile of a follower
is someone young who feels

698
00:32:19,234 --> 00:32:20,801
"marginalized, empty,
and pointless.

699
00:32:20,801 --> 00:32:25,801
They don't have an inner life."

700
00:32:25,801 --> 00:32:29,868
So, it's fear of the other,
is what's going on here.

701
00:32:29,868 --> 00:32:32,501
This is XKCD's map of social
networks, and it says,

702
00:32:32,501 --> 00:32:35,367
they're not like countries, or
they're kind of like countries.

703
00:32:35,367 --> 00:32:38,267
You sort of explore them, um,
they take up space, and you

704
00:32:38,267 --> 00:32:39,534
kind of know they exist,

705
00:32:39,534 --> 00:32:40,934
but you've only been
to one or two of them.

706
00:32:40,934 --> 00:32:43,100
You might visit one of them,
you have friends who live there

707
00:32:43,100 --> 00:32:44,367
and say
it's a great place to holiday.

708
00:32:44,367 --> 00:32:46,067
Um, and he summed it
like this, he says,

709
00:32:46,067 --> 00:32:48,067
"I'm waiting for the day when,
if you tell someone 'I'm from

710
00:32:48,067 --> 00:32:49,701
"the internet,' instead of
laughing, they just ask

711
00:32:49,701 --> 00:32:52,467
'well which part?'"

712
00:32:52,467 --> 00:32:56,100
And that's, I think that's sort
of getting closer to this.

713
00:32:56,100 --> 00:33:00,701
What happens is we, um,
we only see a different web.

714
00:33:00,701 --> 00:33:02,634
We each see something different.
We're all looking at our own

715
00:33:02,634 --> 00:33:05,868
little filter on the web, now.
And, we don't have a shared

716
00:33:05,868 --> 00:33:08,701
public in the way we thought
we did when all we had was

717
00:33:08,701 --> 00:33:11,701
newspapers and television and we
could assume that people had

718
00:33:11,701 --> 00:33:13,968
seen the same thing
as we had done.

719
00:33:13,968 --> 00:33:17,801
Um, the idea of there
being one public

720
00:33:17,801 --> 00:33:21,334
and then lots of little
privates is not there anymore.

721
00:33:21,334 --> 00:33:23,133
What we have is many publics.

722
00:33:23,133 --> 00:33:27,367
Um, we have, we all have our own
view of the web, um, we can't

723
00:33:27,367 --> 00:33:29,367
all see the same thing, and if
you look at the social networks

724
00:33:29,367 --> 00:33:32,367
that are successful, they
reflect this by showing us

725
00:33:32,367 --> 00:33:34,400
all different views of it. If
you look at Twitter, everyone

726
00:33:34,400 --> 00:33:36,734
sees something different, and
there are more social networks

727
00:33:36,734 --> 00:33:38,834
out there than you know. Now,
I thought I knew this field,

728
00:33:38,834 --> 00:33:41,968
and I keep finding 30 million
user social networks that are

729
00:33:41,968 --> 00:33:44,734
signing up for OpenSocial that I
hadn't previously heard of.

730
00:33:44,734 --> 00:33:48,667
Um, so what's happening with the
Le Monde thing is actually

731
00:33:48,667 --> 00:33:51,000
that these social networks
are growing organically,

732
00:33:51,000 --> 00:33:52,567
they're spreading through
friendship groups,

733
00:33:52,567 --> 00:33:54,968
they're growing out, um, people
apply to more of their friends

734
00:33:54,968 --> 00:33:57,300
and they're not overlapping
much, and then the bump

735
00:33:57,300 --> 00:34:01,033
into the existing cultural
boundaries that are there.

736
00:34:01,033 --> 00:34:02,434
Um, and we don't really want

737
00:34:02,434 --> 00:34:04,667
hundreds
of social network sites.

738
00:34:04,667 --> 00:34:06,767
None of us want to sign up,
fill in forms,

739
00:34:06,767 --> 00:34:08,767
for more than a few.

740
00:34:08,767 --> 00:34:10,501
We really don't want to have to
go through this process

741
00:34:10,501 --> 00:34:11,834
again and again and again.

742
00:34:11,834 --> 00:34:17,033
Um, so that's, um,
we want to be able to reuse

743
00:34:17,033 --> 00:34:18,834
the ones we gotten.
We're starting to see this now.

744
00:34:18,834 --> 00:34:21,434
In the last few weeks we've
seen, um, FriendFeed let

745
00:34:21,434 --> 00:34:23,434
you sign up with other
social networks.

746
00:34:23,434 --> 00:34:25,601
We've got Friend Connect that
lets you do that across

747
00:34:25,601 --> 00:34:27,934
many social sites so you can
bring the places you've already

748
00:34:27,934 --> 00:34:29,634
got sets of friends and social
network stuff,

749
00:34:29,634 --> 00:34:30,868
to the rest of the web.

750
00:34:30,868 --> 00:34:32,868
We've got a set of open
standards to do this.

751
00:34:32,868 --> 00:34:35,868
There's starting to be, to show
up in actual real world action.

752
00:34:35,868 --> 00:34:38,033
Even Facebook is now adopting
this for logging in,

753
00:34:38,033 --> 00:34:39,234
which surprised me,

754
00:34:39,234 --> 00:34:42,567
as they don't
let you take any data out.

755
00:34:42,567 --> 00:34:44,934
Um, but we're extending
the networks across the web

756
00:34:44,934 --> 00:34:48,934
and we're creating activities
that then flow back from our

757
00:34:48,934 --> 00:34:52,400
explorations of the web, from
our publics, to our friends in

758
00:34:52,400 --> 00:34:55,868
the social networks. Um, feeding
the stuff back to them so they

759
00:34:55,868 --> 00:34:58,033
can share even what we're
seeing, so that we can actually

760
00:34:58,033 --> 00:35:00,100
connect across the web
in this way.

761
00:35:00,100 --> 00:35:04,567
Um, so, the challenge
is always who you trust.

762
00:35:04,567 --> 00:35:08,067
Douglas Adams warns that
deciding who to trust is

763
00:35:08,067 --> 00:35:11,801
what a large part of our brains
is for, um, and we can't really

764
00:35:11,801 --> 00:35:13,067
delegate that
to the computers.

765
00:35:13,067 --> 00:35:14,834
The computers can't
model this very well.

766
00:35:14,834 --> 00:35:16,701
But what they can have
is they can have

767
00:35:16,701 --> 00:35:20,467
a list of people that we know,
um, with photographs and names

768
00:35:20,467 --> 00:35:22,767
next to them attached to the
information, and then we can use

769
00:35:22,767 --> 00:35:25,834
our brains to decide
what to trust.

770
00:35:25,834 --> 00:35:28,234
So, we can use the standards for
the social networking

771
00:35:28,234 --> 00:35:30,567
to connect
people across the web,

772
00:35:30,567 --> 00:35:35,100
um, but rely on our own mental
models of whom to trust,

773
00:35:35,100 --> 00:35:37,334
um, and have people
attach the information

774
00:35:37,334 --> 00:35:39,868
so that we can filter
the information ourselves,

775
00:35:39,868 --> 00:35:42,067
through the network of our
friendships across the web

776
00:35:42,067 --> 00:35:45,100
and hopefully end some of this
bigotry about other people

777
00:35:45,100 --> 00:35:48,901
elsewhere, um, being different
and nasty and strange.

778
00:35:48,901 --> 00:35:50,834
Thank you.

779
00:35:54,901 --> 00:35:57,634
- Forrest: Thank you very much,
Kevin, and Kevin is the one

780
00:35:57,634 --> 00:35:58,968
who arranged for us
to do this today,

781
00:35:58,968 --> 00:36:01,834
so let's just give
him an extra hand.

782
00:36:06,767 --> 00:36:09,667
And our next speaker
is going to talk about

783
00:36:09,667 --> 00:36:11,000
not the needs
of the consumer,

784
00:36:11,000 --> 00:36:12,567
not the needs of the enterprise,
but, instead,

785
00:36:12,567 --> 00:36:15,033
the needs of NGOs
and developing countries.

786
00:36:15,033 --> 00:36:18,300
Please welcome Andrew Hatton
on coding against cholera.

787
00:36:18,300 --> 00:36:19,834
- Hatton: Thank you.

788
00:36:19,834 --> 00:36:24,234
Hi. This isn't a Google product,
um, so I hope no alarms

789
00:36:24,234 --> 00:36:25,601
are going to go off here.

790
00:36:25,601 --> 00:36:27,467
Um, and this is
a bit of a sell, so,

791
00:36:27,467 --> 00:36:28,901
apologies in advance.

792
00:36:28,901 --> 00:36:30,734
Um, I'm going to talk to you
this afternoon

793
00:36:30,734 --> 00:36:32,667
about clever plastic
and cool code,

794
00:36:32,667 --> 00:36:36,501
or coding against cholera.

795
00:36:36,501 --> 00:36:40,000
Um, so I worked for Oxfam,
which is an NGO, N/NGO.

796
00:36:40,000 --> 00:36:43,067
Um, now,
I'm not meaning to offend anyone

797
00:36:43,067 --> 00:36:45,968
with this question, but really I
just want to make the point that

798
00:36:45,968 --> 00:36:49,767
something that we see as, um,
kind of, treatable and trivial,

799
00:36:49,767 --> 00:36:52,734
in a sense, actually kills
a lot of people.

800
00:36:52,734 --> 00:36:55,834
Second leading cause of death
among children under five.

801
00:36:55,834 --> 00:36:58,667
A major cause of that
is the Cholera bacteria.

802
00:36:58,667 --> 00:37:00,400
And many of the places
where we work,

803
00:37:00,400 --> 00:37:02,767
we find that the Cholera
bacteria is there.

804
00:37:02,767 --> 00:37:06,133
Overcrowded camps,
spreads very, very quickly,

805
00:37:06,133 --> 00:37:08,267
and it can kill
people very quickly.

806
00:37:08,267 --> 00:37:10,801
The treatment, however,
is really well known,

807
00:37:10,801 --> 00:37:13,767
how to handle this. Something
that we call "Watsan,"

808
00:37:13,767 --> 00:37:16,267
or "Clean Water,
Good Sanitation,"

809
00:37:16,267 --> 00:37:17,701
and then, of course,

810
00:37:17,701 --> 00:37:20,767
um, kind of best practice
in terms of hygiene standards.

811
00:37:20,767 --> 00:37:22,133
So it is kind of
very well established

812
00:37:22,133 --> 00:37:23,667
how to manage this stuff.

813
00:37:23,667 --> 00:37:26,567
Now we've got some really good
front line tools in the war

814
00:37:26,567 --> 00:37:29,667
against, um, disease
like, um, cholera.

815
00:37:29,667 --> 00:37:32,100
Um, one is, um,
the bucket over here

816
00:37:32,100 --> 00:37:34,334
which I've been walking
around the conference center,

817
00:37:34,334 --> 00:37:37,234
trying to promote it in front
of all the video cameras.

818
00:37:37,234 --> 00:37:38,868
And then
the other was the toilet.

819
00:37:38,868 --> 00:37:42,367
Now I'm calling this "Bucket
3.0," so we've already made

820
00:37:42,367 --> 00:37:45,400
a start there on, um, a lot of
the technology companies.

821
00:37:45,400 --> 00:37:49,167
Bucket 1.0, 2.0, 3.0,
and that's the best bucket.

822
00:37:49,167 --> 00:37:51,234
Award-winning
bucket this is now.

823
00:37:51,234 --> 00:37:53,133
Um, we recently won
an award with this.

824
00:37:53,133 --> 00:37:55,567
So some of the kind of key
features with this bucket,

825
00:37:55,567 --> 00:37:58,601
it's got a good lid, um, it's
got very thick plastic,

826
00:37:58,601 --> 00:38:02,501
it's UV resistant, so bacteria
and algae won't grow inside,

827
00:38:02,501 --> 00:38:03,934
and it's got also a tap there,

828
00:38:03,934 --> 00:38:06,400
so you can measure your
water out very carefully,

829
00:38:06,400 --> 00:38:09,701
and it stacks, so it can be
transported very easily.

830
00:38:09,701 --> 00:38:11,434
So we're going to write
a quick app,

831
00:38:11,434 --> 00:38:12,634
and we're
going to get this bucket out

832
00:38:12,634 --> 00:38:13,934
to somewhere that needs it.

833
00:38:13,934 --> 00:38:15,834
We work in 72 countries around
the world.

834
00:38:15,834 --> 00:38:17,667
In our case study now,

835
00:38:17,667 --> 00:38:19,100
we're going to get it
to the DRC,

836
00:38:19,100 --> 00:38:20,868
or Democratic Republic
of Congo,

837
00:38:20,868 --> 00:38:22,968
so that's where we're going to
send our bucket

838
00:38:22,968 --> 00:38:25,801
and write it up to them
to order that bucket.

839
00:38:25,801 --> 00:38:28,300
And the Congo recently
came out of conflict.

840
00:38:28,300 --> 00:38:31,033
Um, there are still up to a
million people living in camps

841
00:38:31,033 --> 00:38:34,234
for displaced people, so the
kind of conditions where you're

842
00:38:34,234 --> 00:38:36,567
going to get disease spreading
very, very quickly,

843
00:38:36,567 --> 00:38:38,701
people are
going to be suffering.

844
00:38:38,701 --> 00:38:40,434
And one of the key
tentacle challenges

845
00:38:40,434 --> 00:38:41,701
of the first that we have

846
00:38:41,701 --> 00:38:44,067
in working somewhere like DRC
is bandwidth.

847
00:38:44,067 --> 00:38:47,434
Um, light blue is bad,
so Congo is bad.

848
00:38:47,434 --> 00:38:49,901
Basically, our only option there
is a VSAP connection,

849
00:38:49,901 --> 00:38:53,434
pretty much. Um, there are some
movements happening

850
00:38:53,434 --> 00:38:56,400
to make that better, um,
but it's still very poor.

851
00:38:56,400 --> 00:38:59,334
Um, so the kind of connection
speeds that we're going to see

852
00:38:59,334 --> 00:39:02,934
are pretty low.
Um, 450 kilobits per second.

853
00:39:02,934 --> 00:39:06,601
Obviously much, much slower than
we're used to in the west.

854
00:39:06,601 --> 00:39:08,501
Um, so that's going
to be a challenge.

855
00:39:08,501 --> 00:39:09,834
One of the main challenges

856
00:39:09,834 --> 00:39:11,834
around those types of
connections is latency.

857
00:39:11,834 --> 00:39:14,667
And I don't know
if anyone here has had a VoIP,

858
00:39:14,667 --> 00:39:16,601
um, over a really poor
latent connection,

859
00:39:16,601 --> 00:39:19,334
then you'll kind of
know what that is like.

860
00:39:19,334 --> 00:39:21,067
And the message will be
distorted,

861
00:39:21,067 --> 00:39:23,634
although, interestingly, you'll
recognize that line,

862
00:39:23,634 --> 00:39:26,868
Obama's recent inauguration
speech kind of works

863
00:39:26,868 --> 00:39:28,868
pretty much however much
you chop that message up,

864
00:39:28,868 --> 00:39:30,501
which I thought was
quite interesting.

865
00:39:30,501 --> 00:39:31,834
Um, our approach to the app

866
00:39:31,834 --> 00:39:33,534
is going to be based on
simplicity,

867
00:39:33,534 --> 00:39:37,100
very simple work flow,
just a couple of steps,

868
00:39:37,100 --> 00:39:39,434
have an offline option as well,
so an offline client

869
00:39:39,434 --> 00:39:42,901
and deliver across multiple
clients, so mobile.

870
00:39:42,901 --> 00:39:44,300
Security, very important,

871
00:39:44,300 --> 00:39:46,267
different languages we need
to support,

872
00:39:46,267 --> 00:39:48,200
and, of course, search.

873
00:39:48,200 --> 00:39:51,167
Good findability for
the data is very important.

874
00:39:51,167 --> 00:39:53,334
So those things are all going to
basically meet,

875
00:39:53,334 --> 00:39:55,801
uh, be our
requirements, if you like.

876
00:39:55,801 --> 00:39:57,234
Um, our approach to training

877
00:39:57,234 --> 00:39:59,267
is going to almost be like,
kind of, viral.

878
00:39:59,267 --> 00:40:00,901
We'll train
a couple of people up,

879
00:40:00,901 --> 00:40:02,467
they'll train a couple
of people up,

880
00:40:02,467 --> 00:40:04,033
and they'll train
a couple of people up.

881
00:40:04,033 --> 00:40:06,734
So you kind of spread the
message, basically, quickly

882
00:40:06,734 --> 00:40:09,000
and cheaply, um, as you can.

883
00:40:09,000 --> 00:40:11,267
So all of these things go into
our sausage machine,

884
00:40:11,267 --> 00:40:15,267
or the appropriate app engine,
otherwise known as a developer,

885
00:40:15,267 --> 00:40:18,901
couple of other inputs in there,
might be chocolate and money,

886
00:40:18,901 --> 00:40:21,300
um, because they like those as
well, and out of the end

887
00:40:21,300 --> 00:40:24,601
you get your sausage, or you
get your appropriate app,

888
00:40:24,601 --> 00:40:27,234
um, for this
particular scenario.

889
00:40:27,234 --> 00:40:29,234
So, just summarized,
the appropriate app

890
00:40:29,234 --> 00:40:32,968
is low bandwidth friendly,
copes with poor latency,

891
00:40:32,968 --> 00:40:36,767
so not a chatty application,
printer friendly, offline mode,

892
00:40:36,767 --> 00:40:39,801
secure, multi-lingual,
minimal workflow.

893
00:40:39,801 --> 00:40:44,467
So, diarrhea kills, but can we
beat it? Yes, we can.

894
00:40:44,467 --> 00:40:48,501
Basic hygiene goes a long way,
well-designed water carrier,

895
00:40:48,501 --> 00:40:49,801
and bandwidth is scarce,

896
00:40:49,801 --> 00:40:51,968
so we're going to design
an appropriate app.

897
00:40:51,968 --> 00:40:54,801
So, those are the key kind
of things

898
00:40:54,801 --> 00:40:56,100
that we want to achieve.

899
00:40:56,100 --> 00:40:58,200
Just very quick, there are
some useful links there,

900
00:40:58,200 --> 00:41:00,868
um, slightly
odd formatting, but just,

901
00:41:00,868 --> 00:41:04,367
um, kind of illustrate some of
the bandwidth maps, um,

902
00:41:04,367 --> 00:41:07,167
that kind of show
the bandwidth situation.

903
00:41:07,167 --> 00:41:10,367
And then maybe just one last
thought, before we go,

904
00:41:10,367 --> 00:41:13,667
that really is my, um, kind of
conclusion of happiness,

905
00:41:13,667 --> 00:41:14,901
the one mentioned

906
00:41:14,901 --> 00:41:17,200
what their conclusion was
of happiness earlier

907
00:41:17,200 --> 00:41:18,634
but, kind of, um, a humorous,

908
00:41:18,634 --> 00:41:21,334
uh, making a serious point
with humor.

909
00:41:21,334 --> 00:41:23,267
Thank you.

910
00:41:27,133 --> 00:41:28,767
- Forrest:
Thank you very much.

911
00:41:28,767 --> 00:41:32,834
We've got two more talks and,
in case you've just walked in,

912
00:41:32,834 --> 00:41:35,000
everybody gets just 20 slides,
15 seconds a slide,

913
00:41:35,000 --> 00:41:36,434
and they have no control.

914
00:41:36,434 --> 00:41:39,501
And our next speaker predicted
the future about five years ago

915
00:41:39,501 --> 00:41:43,834
and he's here to talk about
the short film epic,

916
00:41:43,834 --> 00:41:46,868
and how to forecast the future
in the future

917
00:41:46,868 --> 00:41:49,901
for you to do that.

918
00:41:49,901 --> 00:41:51,634
- Robin: Hi, everybody,
I'm Robin,

919
00:41:51,634 --> 00:41:53,100
and I'm going to talk about
how to predict the future.

920
00:41:53,100 --> 00:41:56,133
My goal is to give you three
simple tools you can use

921
00:41:56,133 --> 00:41:58,367
in your life, your work, to sort
of improve the way

922
00:41:58,367 --> 00:42:00,968
that you think
about what happens next.

923
00:42:00,968 --> 00:42:03,033
Why am I qualified
to talk about this?

924
00:42:03,033 --> 00:42:05,434
Uh, I'm not, but to the degree
that anyone is, you know,

925
00:42:05,434 --> 00:42:07,534
I actually had an experience
predicting the future,

926
00:42:07,534 --> 00:42:11,767
I made a short movie called
"Epic 2014," back in 2004,

927
00:42:11,767 --> 00:42:13,701
with a friend of mine
named Matt Thompson.

928
00:42:13,701 --> 00:42:15,200
It was about
the future of news

929
00:42:15,200 --> 00:42:17,501
and its core argument
was that the future,

930
00:42:17,501 --> 00:42:19,968
that future is actually more
in the hands of companies

931
00:42:19,968 --> 00:42:22,901
like "Googlezon" than it
is the New York Times.

932
00:42:22,901 --> 00:42:25,934
Googlezon, of course, being
the company that, uh, sort of

933
00:42:25,934 --> 00:42:29,901
emerged from the merger of
Google and Amazon in 2012.

934
00:42:29,901 --> 00:42:33,767
So, millions of people actually
watched this video, um, which

935
00:42:33,767 --> 00:42:37,133
was a lot in the pre-You Tube
days, um, and,

936
00:42:37,133 --> 00:42:39,934
uh, I'm going to
come back to it.

937
00:42:39,934 --> 00:42:41,567
Dah dah dah dah dah.

938
00:42:41,567 --> 00:42:43,033
Got emailed around, got IMed,

939
00:42:43,033 --> 00:42:44,934
got shown at
conferences like this.

940
00:42:44,934 --> 00:42:46,100
I'm going to come back to it.

941
00:42:46,100 --> 00:42:48,100
First I want to talk
about tip number one.

942
00:42:48,100 --> 00:42:50,200
Philip Tetlock, pictured here
in the center,

943
00:42:50,200 --> 00:42:52,334
is a researcher at
UC Berkeley

944
00:42:52,334 --> 00:42:54,434
who has done a radical thing
when it comes to the future.

945
00:42:54,434 --> 00:42:56,200
He has run an experiment.

946
00:42:56,200 --> 00:42:59,868
He's been distributing surveys
to thousands of experts, um,

947
00:42:59,868 --> 00:43:02,534
people in the military, people
in the academy, asking them

948
00:43:02,534 --> 00:43:05,467
for qualitative, quantitative,
rather, um,

949
00:43:05,467 --> 00:43:06,767
predictions about the future.

950
00:43:06,767 --> 00:43:08,801
He's been doing it
for over 20 years, um,

951
00:43:08,801 --> 00:43:10,000
and he's discovered something

952
00:43:10,000 --> 00:43:11,501
about the predictions
and the kind of people

953
00:43:11,501 --> 00:43:12,934
who make predictions.

954
00:43:12,934 --> 00:43:14,367
He breaks them down
into two groups,

955
00:43:14,367 --> 00:43:16,701
these are actually
Isaiah Berlin's categories,

956
00:43:16,701 --> 00:43:18,267
Hedgehogs and Foxes.

957
00:43:18,267 --> 00:43:21,334
Now, Hedgehogs are big thinkers,
they're people with big ideas,

958
00:43:21,334 --> 00:43:23,467
they like big theories,
they're visionaries,

959
00:43:23,467 --> 00:43:25,267
and Hedgehogs can
change the world,

960
00:43:25,267 --> 00:43:27,400
but they're really bad
at predicting the future.

961
00:43:27,400 --> 00:43:30,467
On the other hand, there's a
person who he calls Foxes.

962
00:43:30,467 --> 00:43:33,400
Foxes actually hate theories,
they hate extrapolating

963
00:43:33,400 --> 00:43:34,734
too much at all.

964
00:43:34,734 --> 00:43:36,834
They like taking things
on a case by case basis.

965
00:43:36,834 --> 00:43:38,400
They really like the specifics,

966
00:43:38,400 --> 00:43:40,934
and they're much better
at predicting the future.

967
00:43:40,934 --> 00:43:42,534
So, when you think about
the future,

968
00:43:42,534 --> 00:43:45,334
think about specifics and
listen to foxes, not hedgehogs.

969
00:43:45,334 --> 00:43:48,167
So, uh, there's a historian
named Neil Ferguson.

970
00:43:48,167 --> 00:43:50,367
This is number two,
pictured here.

971
00:43:50,367 --> 00:43:53,434
Um, he actually agrees with
Phil Tetlock on another issue.

972
00:43:53,434 --> 00:43:55,467
They both think that the
practice of history

973
00:43:55,467 --> 00:43:58,033
needs to involve something
called "counter-factual."

974
00:43:58,033 --> 00:44:00,033
Now something funny happens on
the way to the future, 

975
00:44:00,033 --> 00:44:02,934
it seems all strange and
unpredictable until we get there

976
00:44:02,934 --> 00:44:05,601
and then it happens and it seems
obvious in retrospect.

977
00:44:05,601 --> 00:44:06,801
This is a huge fallacy.

978
00:44:06,801 --> 00:44:09,000
Uh, the practice of
counter-factual says,

979
00:44:09,000 --> 00:44:11,934
"Let's take all of our smarts,
all of the research and rigor

980
00:44:11,934 --> 00:44:13,267
"that we apply to history

981
00:44:13,267 --> 00:44:14,968
"and use it to think
about all the things

982
00:44:14,968 --> 00:44:16,367
that could have happened."

983
00:44:16,367 --> 00:44:18,400
Uh, why is this
the Google IO Conference?

984
00:44:18,400 --> 00:44:20,434
Why isn't it the Yahoo
IO Conference?

985
00:44:20,434 --> 00:44:22,367
Why isn't it
the Googlezon IO Conference?

986
00:44:22,367 --> 00:44:25,033
Why isn't it the 
New York Times IO Conference?

987
00:44:25,033 --> 00:44:28,200
Um, all of these sort of carry
interesting things.

988
00:44:28,200 --> 00:44:29,868
If we can understand those
possible futures,

989
00:44:29,868 --> 00:44:31,834
we can understand ourselves
better.

990
00:44:31,834 --> 00:44:34,000
This begins to sound a lot like
science fiction,

991
00:44:34,000 --> 00:44:37,000
and this is tip number 3.
Read science fiction.

992
00:44:37,000 --> 00:44:38,801
Now you're not going to read it
because it's right, no, 

993
00:44:38,801 --> 00:44:41,267
science fiction is totally
written by hedgehogs.

994
00:44:41,267 --> 00:44:42,567
But, the important thing

995
00:44:42,567 --> 00:44:45,400
is that lots of people
also read science fiction.

996
00:44:45,400 --> 00:44:47,400
Uh, designers, developers,
inventors, 

997
00:44:47,400 --> 00:44:49,634
entrepreneurs, the people who
are going to make the future,

998
00:44:49,634 --> 00:44:50,901
are reading this stuff.

999
00:44:50,901 --> 00:44:52,934
It's like
a slow-ticking time bomb.

1000
00:44:52,934 --> 00:44:54,033
Uh, here's two books

1001
00:44:54,033 --> 00:44:55,434
that I recommend
you should read right now.

1002
00:44:55,434 --> 00:44:59,634
"Daemon" by Daniel Suarez
and "Feed" by M.T. Anderson.

1003
00:44:59,634 --> 00:45:03,067
Now I have a confession to make.
Going back to "Epic 2014,"

1004
00:45:03,067 --> 00:45:05,701
uh, Matt Thompson and I did not
make a movie in the first place.

1005
00:45:05,701 --> 00:45:08,467
We made a slide show, and it was
very rigorous.

1006
00:45:08,467 --> 00:45:10,767
Um, it had, you know, numbers
and charts and graphs

1007
00:45:10,767 --> 00:45:12,501
and it sort of made
this argument.

1008
00:45:12,501 --> 00:45:14,067
It was the same argument,
it was the same prediction

1009
00:45:14,067 --> 00:45:16,767
about the future,
but it was totally boring.

1010
00:45:16,767 --> 00:45:17,901
People couldn't
get through it.

1011
00:45:17,901 --> 00:45:19,667
It definitely was not going to
go viral.

1012
00:45:19,667 --> 00:45:21,167
This is an important insight.

1013
00:45:21,167 --> 00:45:23,167
Stories are powerful,
and I actually think

1014
00:45:23,167 --> 00:45:25,501
this is an important theme
for a group like this.

1015
00:45:25,501 --> 00:45:28,501
Uh, you know, people who prize
numbers, who like rigor,

1016
00:45:28,501 --> 00:45:30,767
who like quantitative stuff,
tend to be really bad

1017
00:45:30,767 --> 00:45:31,868
at telling stories.

1018
00:45:31,868 --> 00:45:33,467
Makes me think of somebody
like this.

1019
00:45:33,467 --> 00:45:35,167
This is Al Gore.
He's actually my boss.

1020
00:45:35,167 --> 00:45:37,234
He cofounded Current,
the company where I work.

1021
00:45:37,234 --> 00:45:39,367
He's been talking about
the future for a long time,

1022
00:45:39,367 --> 00:45:41,400
talking about the planet,
the environment,

1023
00:45:41,400 --> 00:45:43,901
what's going to happen, not
always the best results.

1024
00:45:43,901 --> 00:45:47,133
It wasn't until he wrapped those
predictions up in a story,

1025
00:45:47,133 --> 00:45:50,701
a really scary story about
what's going to happen

1026
00:45:50,701 --> 00:45:52,200
that things actually
started to change.

1027
00:45:52,200 --> 00:45:53,834
You could say that this was
really just the right prediction

1028
00:45:53,834 --> 00:45:55,200
at the right time,

1029
00:45:55,200 --> 00:45:56,901
I think the fact that
it's a story is important.

1030
00:45:56,901 --> 00:45:58,234
When you tell a good story,

1031
00:45:58,234 --> 00:46:00,334
history can sometimes bend
around it.

1032
00:46:00,334 --> 00:46:04,033
So coming back to finish up
the story of "Epic 2014,"

1033
00:46:04,033 --> 00:46:05,300
about a year
after we made it,

1034
00:46:05,300 --> 00:46:07,334
there was this article
in the "Financial Times."

1035
00:46:07,334 --> 00:46:08,334
Um, it was
about Rupert Murdoch

1036
00:46:08,334 --> 00:46:09,801
and how Rupert Murdoch

1037
00:46:09,801 --> 00:46:12,534
was completely changing the
strategy at News Corporation,

1038
00:46:12,534 --> 00:46:14,501
because they realized they had
missed the boat on the internet.

1039
00:46:14,501 --> 00:46:16,501
Couple 'graphs
down there is this line,

1040
00:46:16,501 --> 00:46:19,367
"Mr. Murdoch is understood to
have seen the film

1041
00:46:19,367 --> 00:46:22,133
and taken note."

1042
00:46:22,133 --> 00:46:27,100
We were like "What?" So, to sum
up, number one, when you're

1043
00:46:27,100 --> 00:46:30,501
thinking about the future,
listen to foxes, not hedgehogs.

1044
00:46:30,501 --> 00:46:33,734
Um, you should prize specifics
over grand theories.

1045
00:46:33,734 --> 00:46:35,534
Number two,
think counterfactually.

1046
00:46:35,534 --> 00:46:39,968
Keep alive that question "How
else might things have been?"

1047
00:46:39,968 --> 00:46:42,934
Number three, read science
fiction, not because it's right,

1048
00:46:42,934 --> 00:46:44,868
but because everybody else
is reading it too,

1049
00:46:44,868 --> 00:46:46,200
and here's the trick,

1050
00:46:46,200 --> 00:46:48,534
I actually think the best way
to predict the future

1051
00:46:48,534 --> 00:46:51,467
is to predict the future
and tell a story about it.

1052
00:46:51,467 --> 00:46:54,734
A really compelling, convincing,
passionate, scary,

1053
00:46:54,734 --> 00:46:57,868
exciting story, other people
will have to pay attention,

1054
00:46:57,868 --> 00:46:59,200
and then, who knows?

1055
00:46:59,200 --> 00:47:00,667
That might become the future
because,

1056
00:47:00,667 --> 00:47:03,634
you never know
who's paying attention.

1057
00:47:08,734 --> 00:47:11,734
- Forrest:
Thank you very much, Robin.

1058
00:47:11,734 --> 00:47:13,834
And we've got
just one more talk,

1059
00:47:13,834 --> 00:47:16,467
and she's going to tell you
the story of how to be awesome.

1060
00:47:16,467 --> 00:47:19,501
Please welcome Kathy Sierra.

1061
00:47:21,567 --> 00:47:25,434
- Sierra: So, if we want to
create passionate users,

1062
00:47:25,434 --> 00:47:27,334
we have to help them
get better.

1063
00:47:27,334 --> 00:47:31,334
So nobody's passionate
about things they suck at,

1064
00:47:31,334 --> 00:47:33,501
and if we can help them
have more resolution,

1065
00:47:33,501 --> 00:47:36,400
richer, deeper, better
experiences, we have a chance

1066
00:47:36,400 --> 00:47:37,634
of getting them passionate.

1067
00:47:37,634 --> 00:47:39,300
But I know there are a whole
bunch of you here

1068
00:47:39,300 --> 00:47:43,000
that still have your cameras
set to automatic program mode,

1069
00:47:43,000 --> 00:47:46,100
even though you have shutter
speed and aperture control,

1070
00:47:46,100 --> 00:47:49,767
so if we could unlock that door
for our users,

1071
00:47:49,767 --> 00:47:53,133
and help them be awesome,
what would that mean to them?

1072
00:47:53,133 --> 00:47:55,534
Well, uh, if you read "Outliers"
by Malcolm Gladwell,

1073
00:47:55,534 --> 00:47:57,334
you've seen that 10,000 hours
number,

1074
00:47:57,334 --> 00:48:00,367
it takes 10,000 hours to get
really good at something,

1075
00:48:00,367 --> 00:48:02,400
that's really depressing.

1076
00:48:02,400 --> 00:48:04,367
So one way we can minimize that

1077
00:48:04,367 --> 00:48:07,200
is to be practicing
all of the time.

1078
00:48:07,200 --> 00:48:08,868
So I'm trying to get
really good at horses.

1079
00:48:08,868 --> 00:48:11,267
That's my desk chair.

1080
00:48:11,267 --> 00:48:13,167
That's an actual saddle,
so I'm practicing.

1081
00:48:13,167 --> 00:48:17,734
I'm getting in my 10,000 hours
while working on the computer.

1082
00:48:17,734 --> 00:48:20,133
Uh, I know, some people are kind
of creeped out by that,

1083
00:48:20,133 --> 00:48:23,100
but it, it's actually awesome.

1084
00:48:23,100 --> 00:48:25,033
Another way
we can help our users

1085
00:48:25,033 --> 00:48:27,434
to cut down
that 10,000-hour time frame

1086
00:48:27,434 --> 00:48:29,634
is to give them patterns.

1087
00:48:29,634 --> 00:48:31,767
Experts, people who are awesome
at something,

1088
00:48:31,767 --> 00:48:35,334
have patterns, they use rules,
they have an 80/20.

1089
00:48:35,334 --> 00:48:38,534
Give people what's the one thing
you can do to be amazing.

1090
00:48:38,534 --> 00:48:41,667
Another one is get better gear.
Spend the money.

1091
00:48:41,667 --> 00:48:43,133
And offer better gear

1092
00:48:43,133 --> 00:48:44,567
and higher-end equipment
to your users,

1093
00:48:44,567 --> 00:48:46,834
it just works, so you think
that if you get a big monitor

1094
00:48:46,834 --> 00:48:50,267
and a bunch of displays, you
think you'll be a hacker god,

1095
00:48:50,267 --> 00:48:51,467
if you do that.

1096
00:48:51,467 --> 00:48:54,267
The problem is,
when we have better equipment,

1097
00:48:54,267 --> 00:48:57,234
everyone else who has to pay for
it, this is what they see

1098
00:48:57,234 --> 00:48:58,868
and someone at Google has to
calculate the odds

1099
00:48:58,868 --> 00:49:01,200
because this slide was in the
last person's presentation,

1100
00:49:01,200 --> 00:49:04,734
but anyway, you will see more
pixels so give people away

1101
00:49:04,734 --> 00:49:08,334
to justify the better gear
that you're offering them.

1102
00:49:08,334 --> 00:49:11,968
Now, motivation is
also really important.

1103
00:49:11,968 --> 00:49:14,267
I mean, I think now today's
competitive advantage

1104
00:49:14,267 --> 00:49:18,701
is just making the product that
people will actually use.

1105
00:49:18,701 --> 00:49:20,534
Your treadmill is not in the
corner gathering dust

1106
00:49:20,534 --> 00:49:21,801
because you don't use it.

1107
00:49:21,801 --> 00:49:24,501
You don't use it
because it's in the corner.

1108
00:49:24,501 --> 00:49:26,734
So, you know, make the right
thing easy for people

1109
00:49:26,734 --> 00:49:28,467
and the wrong thing hard.

1110
00:49:28,467 --> 00:49:30,767
So now let's look
at the anti-patterns,

1111
00:49:30,767 --> 00:49:33,734
things that we do that, that
really help create our users

1112
00:49:33,734 --> 00:49:36,601
sucking as opposed
to getting better.

1113
00:49:36,601 --> 00:49:38,767
And, uh, I don't know
why that's a bunny bath.

1114
00:49:38,767 --> 00:49:40,767
Anyway, this is the single
biggest problem

1115
00:49:40,767 --> 00:49:42,133
that most of us have is,

1116
00:49:42,133 --> 00:49:44,434
we focus on the tool,
not the thing

1117
00:49:44,434 --> 00:49:46,300
our users
want to do with the tool.

1118
00:49:46,300 --> 00:49:48,767
That's the biggest block to
getting people interested

1119
00:49:48,767 --> 00:49:51,067
and passionate
and engaged and,

1120
00:49:51,067 --> 00:49:52,400
especially in this case,
you know,

1121
00:49:52,400 --> 00:49:54,734
we treat people really well
before they buy

1122
00:49:54,734 --> 00:49:56,834
and then afterwards,
we treat them poorly.

1123
00:49:56,834 --> 00:50:00,501
This is also the reason people
don't want to upgrade.

1124
00:50:00,501 --> 00:50:03,567
If we really want to help people
upgrade, which they're going to

1125
00:50:03,567 --> 00:50:04,834
need to do to go forward,

1126
00:50:04,834 --> 00:50:07,501
we have to accept
that it's a loss for them,

1127
00:50:07,501 --> 00:50:10,234
it's a hit to their self-esteem
every time they upgrade

1128
00:50:10,234 --> 00:50:11,834
and we just
tell them to get over it.

1129
00:50:11,834 --> 00:50:14,834
This is the other reason that
people don't want to upgrade

1130
00:50:14,834 --> 00:50:15,968
and move forward.

1131
00:50:15,968 --> 00:50:18,567
Because we write the FAQs
and the help

1132
00:50:18,567 --> 00:50:22,367
and the manuals as though they
were intellectually curious,

1133
00:50:22,367 --> 00:50:23,701
and using a tablet PC.

1134
00:50:23,701 --> 00:50:27,067
But, the real reason is because
they're consulting help

1135
00:50:27,067 --> 00:50:29,067
because they are having
a horrible experience.

1136
00:50:29,067 --> 00:50:31,100
But this is not the
right answer either.

1137
00:50:31,100 --> 00:50:33,367
You don't feel awesome because
you're not awesome

1138
00:50:33,367 --> 00:50:34,634
if you master something

1139
00:50:34,634 --> 00:50:36,534
because a three-year-old
could master it.

1140
00:50:36,534 --> 00:50:39,334
So don't let the ease-of-use
police step in

1141
00:50:39,334 --> 00:50:41,601
and dumb something down,
that's not an answer.

1142
00:50:41,601 --> 00:50:45,000
This is also a really,
really bad solution,

1143
00:50:45,000 --> 00:50:48,367
which is to hire
a social media consultant,

1144
00:50:48,367 --> 00:50:50,667
and some of my best friends are
social media consultants,

1145
00:50:50,667 --> 00:50:53,200
but it is out of control
because it's

1146
00:50:53,200 --> 00:50:55,534
completely focusing
in the wrong direction.

1147
00:50:55,534 --> 00:50:59,133
We are, well, this is the social
media consultant fantasy.

1148
00:50:59,133 --> 00:51:02,801
The goal is to get users
to love us.

1149
00:51:02,801 --> 00:51:04,501
That's such
a ridiculously bad goal.

1150
00:51:04,501 --> 00:51:06,300
Nobody is awesome because
they love you

1151
00:51:06,300 --> 00:51:07,634
because you are nice.

1152
00:51:07,634 --> 00:51:10,501
So, you know, someone tweeted,
uh, that, you know,

1153
00:51:10,501 --> 00:51:13,901
the holy grail is if your users
want to party with you.

1154
00:51:13,901 --> 00:51:16,100
That's a bad idea. You want your
users to party

1155
00:51:16,100 --> 00:51:19,133
because of you
without you.

1156
00:51:19,133 --> 00:51:21,601
So, put users with other users,

1157
00:51:21,601 --> 00:51:23,667
not connecting
users to the company.

1158
00:51:23,667 --> 00:51:27,300
This is a fantasy also.
This is not going to happen.

1159
00:51:27,300 --> 00:51:31,934
Great use of social media is to
find out what role we play

1160
00:51:31,934 --> 00:51:35,300
in our users' lives and what
role our competitors play

1161
00:51:35,300 --> 00:51:36,567
in our users' lives.

1162
00:51:36,567 --> 00:51:38,634
Use social media to look
for pain and pleasure

1163
00:51:38,634 --> 00:51:41,000
and those are the things
that we can tweak and exploit

1164
00:51:41,000 --> 00:51:42,367
to help them be awesome.

1165
00:51:42,367 --> 00:51:43,901
Another thing we can do,
well,

1166
00:51:43,901 --> 00:51:46,200
another anti-pattern is that,

1167
00:51:46,200 --> 00:51:48,901
by trying
to be really competitive

1168
00:51:48,901 --> 00:51:52,567
and focusing on our competitors,
we end up being uncompetitive

1169
00:51:52,567 --> 00:51:55,067
because we end up with
things like featuritis.

1170
00:51:55,067 --> 00:51:57,968
We start building the very
things that harm users.

1171
00:51:57,968 --> 00:51:59,234
The best thing we can do,

1172
00:51:59,234 --> 00:52:01,133
and this is the greatness
of social media,

1173
00:52:01,133 --> 00:52:05,000
look at what the bigger,
cooler thing is, the world

1174
00:52:05,000 --> 00:52:07,000
that our product
and our competitor's products

1175
00:52:07,000 --> 00:52:09,634
exist in, that bigger,
cooler thing,

1176
00:52:09,634 --> 00:52:11,467
that's what people want
to kick ass at.

1177
00:52:11,467 --> 00:52:13,801
Not your tool.
So blog about that.

1178
00:52:13,801 --> 00:52:17,100
You know, Tweet about that.
Use social media about that.

1179
00:52:17,100 --> 00:52:21,067
Uh, in the social marketing
world, you hear the word WOM.

1180
00:52:21,067 --> 00:52:24,367
Word Of Mouth. That's supposed
to be the holy grail.

1181
00:52:24,367 --> 00:52:27,000
But really there's something
much better than that,

1182
00:52:27,000 --> 00:52:30,200
that most of us are able
to do, and that's WOFO.

1183
00:52:30,200 --> 00:52:35,400
If your users are so good,
you get Word Of F-ing Obvious.

1184
00:52:35,400 --> 00:52:39,601
And you all have the chance to
do that. Thank you.

1185
00:52:47,000 --> 00:52:48,200
- Forrest:
Thank you very much, Kathy.

1186
00:52:48,200 --> 00:52:50,634
That concludes Ignite.
Thanks for joining.

1187
00:52:50,634 --> 00:52:52,033
All the speakers,

1188
00:52:52,033 --> 00:52:53,834
want to just stand up and get
another round of applause?

1189
00:52:53,834 --> 00:52:56,033
Soak it up?

1190
00:53:02,501 --> 00:53:03,934
And I'm Brady Forrest.

1191
00:53:03,934 --> 00:53:06,567
If you want to start an Ignite
in your town, it's easy.

1192
00:53:06,567 --> 00:53:09,501
And just ping me,
and I'll tell you how.

